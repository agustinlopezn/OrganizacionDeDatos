{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = pd.read_csv('processed_train.csv')\n",
    "test = pd.read_csv('processed_test.csv')\n",
    "train_features = pd.read_csv('train_complete.csv')\n",
    "test_features = pd.read_csv('test_complete.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = \\\n",
    "train_test_split(tweets[['text', 'keyword']], tweets['target'], test_size = 0.25, random_state = 123)\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "vectorizer = CountVectorizer(ngram_range=(1,2), lowercase=True, stop_words='english', max_features=5000)\n",
    "train_vectors = vectorizer.fit_transform(x_train['text'])\n",
    "test_vectors = vectorizer.transform(x_test['text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LIGTH GBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "matrix_final = train_vectors.astype('float32')\n",
    "d_train = lgb.Dataset(matrix_final, label=y_train)\n",
    "\n",
    "params = {\n",
    "    'learning_rate' : 0.02,\n",
    "    'boosting_type' : 'gbdt',\n",
    "    'objective' : 'binary',\n",
    "    'metric' : 'binary_logloss',\n",
    "    'num_leaves' : 50,\n",
    "    'max_depth' : 3\n",
    "}\n",
    "\n",
    "gbm = lgb.train(params, d_train, 5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7880580957504034\n"
     ]
    }
   ],
   "source": [
    "test_final = test_vectors.astype('float32')\n",
    "y_pred = gbm.predict(test_final)\n",
    "\n",
    "for i in range (0, len(y_pred)):\n",
    "    if y_pred[i] >= 0.5:       \n",
    "        y_pred[i] = 1\n",
    "    else:  \n",
    "        y_pred[i] = 0\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "accuracy = accuracy_score(y_pred, y_test)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.87      0.82      1055\n",
      "           1       0.80      0.69      0.74       804\n",
      "\n",
      "    accuracy                           0.79      1859\n",
      "   macro avg       0.79      0.78      0.78      1859\n",
      "weighted avg       0.79      0.79      0.79      1859\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "def algorithm_pipeline(X_train_data, X_test_data, y_train_data, y_test_data, \n",
    "                       model, param_grid, cv=10, scoring_fit='neg_mean_squared_error',\n",
    "                       do_probabilities = False):\n",
    "    \n",
    "    gs = RandomizedSearchCV(\n",
    "        estimator=model,\n",
    "        param_distributions=param_grid, \n",
    "        cv=cv, \n",
    "        n_jobs=-1, \n",
    "        scoring=scoring_fit,\n",
    "        verbose=2\n",
    "    )\n",
    "    fitted_model = gs.fit(X_train_data, y_train_data)\n",
    "    \n",
    "    if do_probabilities:\n",
    "      pred = fitted_model.predict_proba(X_test_data)\n",
    "    else:\n",
    "      pred = fitted_model.predict(X_test_data)\n",
    "    \n",
    "    return fitted_model, pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:    7.7s\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:   11.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7522869955156951\n",
      "{'subsample_freq': 20, 'subsample': 0.9, 'reg_lambda': 1.3, 'reg_alpha': 1.2, 'num_leaves': 200, 'n_estimators': 1000, 'min_split_gain': 0.4, 'max_depth': 15, 'colsample_bytree': 0.7}\n"
     ]
    }
   ],
   "source": [
    "model = lgb.LGBMClassifier()\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [400, 700, 1000],\n",
    "    'colsample_bytree': [0.7, 0.8],\n",
    "    'max_depth': [15,20,25],\n",
    "    'num_leaves': [50, 100, 200],\n",
    "    'reg_alpha': [1.1, 1.2, 1.3],\n",
    "    'reg_lambda': [1.1, 1.2, 1.3],\n",
    "    'min_split_gain': [0.3, 0.4],\n",
    "    'subsample': [0.7, 0.8, 0.9],\n",
    "    'subsample_freq': [20]\n",
    "}\n",
    "\n",
    "model, pred = algorithm_pipeline(matrix_final, test_final, y_train, y_test, model, param_grid, cv=5, scoring_fit='accuracy')\n",
    "\n",
    "print(model.best_score_)\n",
    "print(model.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>length</th>\n",
       "      <th>avg_word_length</th>\n",
       "      <th>amount_of_words</th>\n",
       "      <th>amount_of_unique_words</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>stopwords_count</th>\n",
       "      <th>punctuation_count</th>\n",
       "      <th>...</th>\n",
       "      <th>l90</th>\n",
       "      <th>l91</th>\n",
       "      <th>l92</th>\n",
       "      <th>l93</th>\n",
       "      <th>l94</th>\n",
       "      <th>l95</th>\n",
       "      <th>l96</th>\n",
       "      <th>l97</th>\n",
       "      <th>l98</th>\n",
       "      <th>l99</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>our deeds are the reason of this  earthquake m...</td>\n",
       "      <td>1</td>\n",
       "      <td>69</td>\n",
       "      <td>4.384615</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>0.2732</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.2123</td>\n",
       "      <td>0.51573</td>\n",
       "      <td>0.16573</td>\n",
       "      <td>0.67943</td>\n",
       "      <td>0.35327</td>\n",
       "      <td>0.17672</td>\n",
       "      <td>0.25803</td>\n",
       "      <td>0.068445</td>\n",
       "      <td>-1.2016</td>\n",
       "      <td>-0.20168</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows Ã— 220 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                               text  target  length  \\\n",
       "0   1  our deeds are the reason of this  earthquake m...       1      69   \n",
       "\n",
       "   avg_word_length  amount_of_words  amount_of_unique_words  sentiment  \\\n",
       "0         4.384615               13                      13     0.2732   \n",
       "\n",
       "   stopwords_count  punctuation_count  ...     l90      l91      l92      l93  \\\n",
       "0                6                  1  ... -1.2123  0.51573  0.16573  0.67943   \n",
       "\n",
       "       l94      l95      l96       l97     l98      l99  \n",
       "0  0.35327  0.17672  0.25803  0.068445 -1.2016 -0.20168  \n",
       "\n",
       "[1 rows x 220 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data = tweets.merge(train_features)\n",
    "all_data.drop(columns=['keyword', 'location'], inplace=True)\n",
    "all_data.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = \\\n",
    "train_test_split(all_data, tweets['target'], test_size = 0.25, random_state = 123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "vectorizer = CountVectorizer(ngram_range=(1,2), lowercase=True, stop_words='english', max_features=5000)\n",
    "train_vectors = vectorizer.fit_transform(x_train['text'])\n",
    "test_vectors = vectorizer.transform(x_test['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_array = train_vectors.todense()\n",
    "train_matrix = pd.DataFrame(train_array)\n",
    "x_train.reset_index(inplace=True, drop=True)\n",
    "train_matrix['id'] = x_train['id']\n",
    "X_train = x_train.merge(train_matrix).drop(columns=['id', 'text', 'target'])\n",
    "\n",
    "test_array = test_vectors.todense()\n",
    "test_matrix = pd.DataFrame(test_array)\n",
    "x_test.reset_index(inplace=True, drop=True)\n",
    "test_matrix['id'] = x_test['id']\n",
    "X_test = x_test.merge(test_matrix).drop(columns=['id', 'text', 'target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_train = lgb.Dataset(X_train, y_train)\n",
    "\n",
    "params : {\n",
    "    'learning_rate' : 0.02,\n",
    "    'boosting_type' : 'gbdt',\n",
    "    'objective' : 'binary',\n",
    "    'metric' : 'binary_logloss',\n",
    "    'num_leaves' : 500,\n",
    "    'max_depth' : 2,\n",
    "    'max_bin': 1000\n",
    "}\n",
    "\n",
    "gbm = lgb.train(params, d_train, 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7945131791285638\n"
     ]
    }
   ],
   "source": [
    "y_pred = gbm.predict(X_test)\n",
    "\n",
    "for i in range (0, len(y_pred)):\n",
    "    if y_pred[i] > 0.5:       \n",
    "        y_pred[i] = 1\n",
    "    else:  \n",
    "        y_pred[i] = 0\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "accuracy = accuracy_score(y_pred, y_test)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:   50.1s\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:  1.3min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7800896860986548\n",
      "{'subsample_freq': 20, 'subsample': 0.9, 'reg_lambda': 1.1, 'reg_alpha': 1.3, 'num_leaves': 100, 'n_estimators': 1000, 'min_split_gain': 0.4, 'max_depth': 2, 'colsample_bytree': 0.8}\n"
     ]
    }
   ],
   "source": [
    "model = lgb.LGBMClassifier()\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [400, 700, 1000],\n",
    "    'colsample_bytree': [0.7, 0.8],\n",
    "    'max_depth': [2, 5, 7],\n",
    "    'num_leaves': [50, 100, 200],\n",
    "    'reg_alpha': [1.1, 1.2, 1.3],\n",
    "    'reg_lambda': [1.1, 1.2, 1.3],\n",
    "    'min_split_gain': [0.3, 0.4],\n",
    "    'subsample': [0.7, 0.8, 0.9],\n",
    "    'subsample_freq': [20]\n",
    "}\n",
    "\n",
    "model, pred = algorithm_pipeline(X_train, X_test, y_train, y_test, model, param_grid, cv=5, scoring_fit='accuracy')\n",
    "\n",
    "print(model.best_score_)\n",
    "print(model.best_params_)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
