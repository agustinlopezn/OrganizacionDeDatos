{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TensorFlow + Glove Twitter\n",
    "\n",
    "Embedding:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 517,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = pd.read_csv('train.csv') \n",
    "tests = pd.read_csv('test.csv') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 518,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 7434 entries, 0 to 7612\n",
      "Data columns (total 5 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   id        7434 non-null   int64 \n",
      " 1   keyword   7378 non-null   object\n",
      " 2   location  4982 non-null   object\n",
      " 3   text      7434 non-null   object\n",
      " 4   target    7434 non-null   int64 \n",
      "dtypes: int64(2), object(3)\n",
      "memory usage: 348.5+ KB\n"
     ]
    }
   ],
   "source": [
    "tweets.drop_duplicates(subset = 'text', keep = False, inplace = True)\n",
    "tweets.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 519,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22586\n"
     ]
    }
   ],
   "source": [
    "t = Tokenizer()\n",
    "t.fit_on_texts(tweets['text'])\n",
    "vocab_size = len(t.word_index) + 1\n",
    "print(vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "# integer encode the documents\n",
    "encoded_docs = t.texts_to_sequences(tweets['text'])\n",
    "enconded_test = t.texts_to_sequences(tests['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 116 4534   25 ...    0    0    0]\n",
      " [ 182   46  242 ...    0    0    0]\n",
      " [  40 1705 1572 ...    0    0    0]\n",
      " ...\n",
      " [ 106  225  453 ...    0    0    0]\n",
      " [ 121  837 1338 ...    0    0    0]\n",
      " [   4  201   53 ...    0    0    0]]\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "max_length = 31 # Maxima cantidad de palabras en los tweets\n",
    "padded_docs = pad_sequences(encoded_docs, maxlen=max_length, padding='post')\n",
    "padded_tests = pad_sequences(enconded_test, maxlen=max_length, padding='post')\n",
    "print(padded_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 1193514 word vectors.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "embeddings_index = dict()\n",
    "f = open('glove.twitter.27B.100d.txt') # Vectores entrenados de 100 dimensiones\n",
    "for line in f:\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    coefs = np.asarray(values[1:], dtype='float32')\n",
    "    embeddings_index[word] = coefs\n",
    "f.close()\n",
    "print('Loaded %s word vectors.' % len(embeddings_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_matrix = np.zeros((vocab_size, 100))\n",
    "for word, i in t.word_index.items():\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None: # Si la palabra no esta queda llena de 0s\n",
    "        embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 662,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>length</th>\n",
       "      <th>avg_word_length</th>\n",
       "      <th>amount_of_words</th>\n",
       "      <th>amount_of_unique_words</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>stopwords_count</th>\n",
       "      <th>punctuation_count</th>\n",
       "      <th>mentions_count</th>\n",
       "      <th>hashtags_count</th>\n",
       "      <th>longest_word_length_without_stopwords</th>\n",
       "      <th>stopword_word_ratio</th>\n",
       "      <th>adjectives_count</th>\n",
       "      <th>nouns_count</th>\n",
       "      <th>verbs_count</th>\n",
       "      <th>adverbs_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>69</td>\n",
       "      <td>4.384615</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>0.2732</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0.461538</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>38</td>\n",
       "      <td>4.571429</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>-0.3400</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>133</td>\n",
       "      <td>5.090909</td>\n",
       "      <td>22</td>\n",
       "      <td>20</td>\n",
       "      <td>-0.2960</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>65</td>\n",
       "      <td>7.125000</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>88</td>\n",
       "      <td>4.500000</td>\n",
       "      <td>16</td>\n",
       "      <td>15</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>0.437500</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7429</th>\n",
       "      <td>136</td>\n",
       "      <td>6.210526</td>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "      <td>-0.6841</td>\n",
       "      <td>6</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>0.315789</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7430</th>\n",
       "      <td>114</td>\n",
       "      <td>3.423077</td>\n",
       "      <td>26</td>\n",
       "      <td>25</td>\n",
       "      <td>-0.4939</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0.615385</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7431</th>\n",
       "      <td>121</td>\n",
       "      <td>5.100000</td>\n",
       "      <td>20</td>\n",
       "      <td>18</td>\n",
       "      <td>-0.7650</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7432</th>\n",
       "      <td>83</td>\n",
       "      <td>6.636364</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>-0.4939</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7433</th>\n",
       "      <td>94</td>\n",
       "      <td>6.307692</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0.230769</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7434 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      length  avg_word_length  amount_of_words  amount_of_unique_words  \\\n",
       "0         69         4.384615               13                      13   \n",
       "1         38         4.571429                7                       7   \n",
       "2        133         5.090909               22                      20   \n",
       "3         65         7.125000                8                       8   \n",
       "4         88         4.500000               16                      15   \n",
       "...      ...              ...              ...                     ...   \n",
       "7429     136         6.210526               19                      19   \n",
       "7430     114         3.423077               26                      25   \n",
       "7431     121         5.100000               20                      18   \n",
       "7432      83         6.636364               11                      11   \n",
       "7433      94         6.307692               13                      13   \n",
       "\n",
       "      sentiment  stopwords_count  punctuation_count  mentions_count  \\\n",
       "0        0.2732                6                  1               0   \n",
       "1       -0.3400                0                  1               0   \n",
       "2       -0.2960               11                  3               0   \n",
       "3        0.0000                1                  2               0   \n",
       "4        0.0000                7                  2               0   \n",
       "...         ...              ...                ...             ...   \n",
       "7429    -0.6841                6                 12               0   \n",
       "7430    -0.4939               16                  1               0   \n",
       "7431    -0.7650                1                 11               0   \n",
       "7432    -0.4939                2                  5               0   \n",
       "7433     0.0000                3                  7               0   \n",
       "\n",
       "      hashtags_count  longest_word_length_without_stopwords  \\\n",
       "0                  1                                      7   \n",
       "1                  0                                      6   \n",
       "2                  0                                     10   \n",
       "3                  1                                     10   \n",
       "4                  2                                      6   \n",
       "...              ...                                    ...   \n",
       "7429               1                                     10   \n",
       "7430               0                                      8   \n",
       "7431               0                                      8   \n",
       "7432               0                                      8   \n",
       "7433               0                                     10   \n",
       "\n",
       "      stopword_word_ratio  adjectives_count  nouns_count  verbs_count  \\\n",
       "0                0.461538                 0            6            1   \n",
       "1                0.000000                 0            6            0   \n",
       "2                0.500000                 1            7            7   \n",
       "3                0.125000                 1            4            1   \n",
       "4                0.437500                 0            6            3   \n",
       "...                   ...               ...          ...          ...   \n",
       "7429             0.315789                 0           13            3   \n",
       "7430             0.615385                 2            4            5   \n",
       "7431             0.050000                 0           14            0   \n",
       "7432             0.181818                 2            6            1   \n",
       "7433             0.230769                 2            8            1   \n",
       "\n",
       "      adverbs_count  \n",
       "0                 0  \n",
       "1                 0  \n",
       "2                 0  \n",
       "3                 0  \n",
       "4                 1  \n",
       "...             ...  \n",
       "7429              0  \n",
       "7430              3  \n",
       "7431              0  \n",
       "7432              0  \n",
       "7433              0  \n",
       "\n",
       "[7434 rows x 15 columns]"
      ]
     },
     "execution_count": 662,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_features.loc[:,'length':]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_3 (Embedding)      (None, 31, 100)           2258600   \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 25, 256)           179456    \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 6400)              0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 6401      \n",
      "=================================================================\n",
      "Total params: 2,444,457\n",
      "Trainable params: 185,857\n",
      "Non-trainable params: 2,258,600\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding, Flatten, Dense\n",
    "from keras import layers\n",
    "\n",
    "model1 = Sequential()\n",
    "e = Embedding(vocab_size, 100, weights=[embedding_matrix], input_length=31, trainable=False)\n",
    "model1.add(e)\n",
    "model1.add(layers.Conv1D(256, 7, activation='relu'))\n",
    "model1.add(Flatten())\n",
    "model1.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model1.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "print(model1.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_test, y_train, y_test = \\\n",
    "train_test_split(padded_docs, tweets['target'], test_size = 0.25, random_state = 123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "44/44 - 1s - loss: 0.5262 - accuracy: 0.7444 - val_loss: 0.4449 - val_accuracy: 0.7983\n",
      "Epoch 2/50\n",
      "44/44 - 1s - loss: 0.3909 - accuracy: 0.8335 - val_loss: 0.4308 - val_accuracy: 0.8133\n",
      "Epoch 3/50\n",
      "44/44 - 1s - loss: 0.3256 - accuracy: 0.8687 - val_loss: 0.4464 - val_accuracy: 0.8144\n",
      "Epoch 00003: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x152fee190>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.callbacks import EarlyStopping\n",
    "callback = EarlyStopping(monitor = 'val_loss', patience = 1, verbose=1)\n",
    "callbacks = [callback]\n",
    "\n",
    "model1.fit(x_train, y_train,\n",
    "          validation_data=(x_test, y_test),\n",
    "          batch_size=128,\n",
    "          epochs=50,\n",
    "          verbose=2,\n",
    "          callbacks=callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_5 (Embedding)      (None, 31, 100)           2258600   \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (None, 25, 256)           179456    \n",
      "_________________________________________________________________\n",
      "flatten_5 (Flatten)          (None, 6400)              0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 6401      \n",
      "=================================================================\n",
      "Total params: 2,444,457\n",
      "Trainable params: 185,857\n",
      "Non-trainable params: 2,258,600\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding, Flatten, Dense\n",
    "from keras import layers\n",
    "\n",
    "model1 = Sequential()\n",
    "e = Embedding(vocab_size, 100, weights=[embedding_matrix], input_length=31, trainable=False)\n",
    "model1.add(e)\n",
    "model1.add(layers.Conv1D(256, 7, activation='relu'))\n",
    "model1.add(Flatten())\n",
    "model1.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model1.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "print(model1.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "59/59 - 1s - loss: 0.5096 - accuracy: 0.7612\n",
      "Epoch 2/5\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "59/59 - 1s - loss: 0.3848 - accuracy: 0.8366\n",
      "Epoch 3/5\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "59/59 - 1s - loss: 0.3255 - accuracy: 0.8680\n",
      "Epoch 4/5\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "59/59 - 1s - loss: 0.2696 - accuracy: 0.8932\n",
      "Epoch 5/5\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "59/59 - 1s - loss: 0.2180 - accuracy: 0.9257\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x155cb0950>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.callbacks import EarlyStopping\n",
    "callback = EarlyStopping(monitor = 'val_loss', patience = 1, verbose=1)\n",
    "callbacks = [callback]\n",
    "\n",
    "model1.fit(padded_docs, tweets['target'],\n",
    "          batch_size=128,\n",
    "          epochs=5,\n",
    "          verbose=2,\n",
    "          callbacks=callback)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_result = model1.predict(padded_tests)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.4535236 ],\n",
       "       [0.6374486 ],\n",
       "       [0.51281166],\n",
       "       ...,\n",
       "       [0.7867126 ],\n",
       "       [0.6981692 ],\n",
       "       [0.24020772]], dtype=float32)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " ...]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submit = []\n",
    "\n",
    "for i in test_result:\n",
    "    if i >= 0.5 :\n",
    "        submit.append(1)\n",
    "    else:\n",
    "        submit.append(0)\n",
    "\n",
    "submit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just happened a terrible car crash</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Heard about #earthquake is different cities, s...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>there is a forest fire at spot pond, geese are...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Apocalypse lighting. #Spokane #wildfires</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Typhoon Soudelor kills 28 in China and Taiwan</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3258</th>\n",
       "      <td>10861</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>EARTHQUAKE SAFETY LOS ANGELES ÛÒ SAFETY FASTE...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3259</th>\n",
       "      <td>10865</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Storm in RI worse than last hurricane. My city...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3260</th>\n",
       "      <td>10868</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Green Line derailment in Chicago http://t.co/U...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3261</th>\n",
       "      <td>10874</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MEG issues Hazardous Weather Outlook (HWO) htt...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3262</th>\n",
       "      <td>10875</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>#CityofCalgary has activated its Municipal Eme...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3263 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id keyword location  \\\n",
       "0         0     NaN      NaN   \n",
       "1         2     NaN      NaN   \n",
       "2         3     NaN      NaN   \n",
       "3         9     NaN      NaN   \n",
       "4        11     NaN      NaN   \n",
       "...     ...     ...      ...   \n",
       "3258  10861     NaN      NaN   \n",
       "3259  10865     NaN      NaN   \n",
       "3260  10868     NaN      NaN   \n",
       "3261  10874     NaN      NaN   \n",
       "3262  10875     NaN      NaN   \n",
       "\n",
       "                                                   text  target  \n",
       "0                    Just happened a terrible car crash       0  \n",
       "1     Heard about #earthquake is different cities, s...       1  \n",
       "2     there is a forest fire at spot pond, geese are...       1  \n",
       "3              Apocalypse lighting. #Spokane #wildfires       1  \n",
       "4         Typhoon Soudelor kills 28 in China and Taiwan       1  \n",
       "...                                                 ...     ...  \n",
       "3258  EARTHQUAKE SAFETY LOS ANGELES ÛÒ SAFETY FASTE...       1  \n",
       "3259  Storm in RI worse than last hurricane. My city...       1  \n",
       "3260  Green Line derailment in Chicago http://t.co/U...       1  \n",
       "3261  MEG issues Hazardous Weather Outlook (HWO) htt...       1  \n",
       "3262  #CityofCalgary has activated its Municipal Eme...       0  \n",
       "\n",
       "[3263 rows x 5 columns]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit_df = tests[['id', 'target']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3258</th>\n",
       "      <td>10861</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3259</th>\n",
       "      <td>10865</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3260</th>\n",
       "      <td>10868</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3261</th>\n",
       "      <td>10874</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3262</th>\n",
       "      <td>10875</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3263 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id  target\n",
       "0         0       0\n",
       "1         2       1\n",
       "2         3       1\n",
       "3         9       1\n",
       "4        11       1\n",
       "...     ...     ...\n",
       "3258  10861       1\n",
       "3259  10865       1\n",
       "3260  10868       1\n",
       "3261  10874       1\n",
       "3262  10875       0\n",
       "\n",
       "[3263 rows x 2 columns]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submit_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit_df.to_csv('submit_prueba_36.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_6 (Embedding)      (None, 31, 100)           2258600   \n",
      "_________________________________________________________________\n",
      "conv1d_4 (Conv1D)            (None, 25, 256)           179456    \n",
      "_________________________________________________________________\n",
      "flatten_6 (Flatten)          (None, 6400)              0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 10)                64010     \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 2,502,077\n",
      "Trainable params: 243,477\n",
      "Non-trainable params: 2,258,600\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding, Flatten, Dense\n",
    "from keras import layers\n",
    "\n",
    "model1 = Sequential()\n",
    "e = Embedding(vocab_size, 100, weights=[embedding_matrix], input_length=31, trainable=False)\n",
    "model1.add(e)\n",
    "model1.add(layers.Conv1D(256, 7, activation='relu'))\n",
    "model1.add(Flatten())\n",
    "model1.add(Dense(10, activation='sigmoid'))\n",
    "model1.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model1.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "print(model1.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "44/44 - 1s - loss: 0.5305 - accuracy: 0.7365 - val_loss: 0.4629 - val_accuracy: 0.8010\n",
      "Epoch 2/50\n",
      "44/44 - 1s - loss: 0.4246 - accuracy: 0.8240 - val_loss: 0.4222 - val_accuracy: 0.8144\n",
      "Epoch 3/50\n",
      "44/44 - 1s - loss: 0.3736 - accuracy: 0.8560 - val_loss: 0.4243 - val_accuracy: 0.8112\n",
      "Epoch 00003: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1536348d0>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.callbacks import EarlyStopping\n",
    "callback = EarlyStopping(monitor = 'val_loss', patience = 1, verbose=1)\n",
    "callbacks = [callback]\n",
    "\n",
    "model1.fit(x_train, y_train,\n",
    "          validation_data=(x_test, y_test),\n",
    "          batch_size=128,\n",
    "          epochs=50,\n",
    "          verbose=2,\n",
    "          callbacks=callback)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GRID SEARCH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding, Flatten, Dense\n",
    "from keras import layers\n",
    "\n",
    "from keras.callbacks import EarlyStopping\n",
    "callback = EarlyStopping(monitor = 'val_loss', patience = 1, verbose=1)\n",
    "callbacks = [callback]\n",
    "\n",
    "def build_model(fully_conected, num_filters, kern_size):\n",
    "    model1 = Sequential()\n",
    "    e = Embedding(vocab_size, 100, weights=[embedding_matrix], input_length=31, trainable=True)\n",
    "    model1.add(e)\n",
    "    model1.add(layers.Conv1D(num_filters, kern_size, activation='relu'))\n",
    "    model1.add(Flatten())\n",
    "    model1.add(Dense(fully_conected, activation='sigmoid'))\n",
    "    model1.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    model1.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    return model1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 folds for each of 5 candidates, totalling 20 fits\n",
      "[CV] num_filters=128, kern_size=7, fully_conected=800, epochs=15, batch_size=88 \n",
      "Epoch 1/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43/43 [==============================] - 1s 35ms/step - loss: 0.6060 - accuracy: 0.7068 - val_loss: 0.4906 - val_accuracy: 0.7661\n",
      "Epoch 2/15\n",
      "43/43 [==============================] - 1s 32ms/step - loss: 0.3714 - accuracy: 0.8437 - val_loss: 0.4632 - val_accuracy: 0.7804\n",
      "Epoch 3/15\n",
      "43/43 [==============================] - 1s 32ms/step - loss: 0.2524 - accuracy: 0.9003 - val_loss: 0.5939 - val_accuracy: 0.7637\n",
      "Epoch 00003: early stopping\n",
      "WARNING:tensorflow:From /Users/matiascano/.pyenv/versions/3.7.7/lib/python3.7/site-packages/tensorflow/python/keras/wrappers/scikit_learn.py:241: Sequential.predict_classes (from tensorflow.python.keras.engine.sequential) is deprecated and will be removed after 2021-01-01.\n",
      "Instructions for updating:\n",
      "Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "16/16 [==============================] - 0s 5ms/step\n",
      "[CV]  num_filters=128, kern_size=7, fully_conected=800, epochs=15, batch_size=88, total=   5.1s\n",
      "[CV] num_filters=128, kern_size=7, fully_conected=800, epochs=15, batch_size=88 \n",
      "Epoch 1/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    5.1s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43/43 [==============================] - 1s 34ms/step - loss: 0.5289 - accuracy: 0.7443 - val_loss: 0.4674 - val_accuracy: 0.7852\n",
      "Epoch 2/15\n",
      "43/43 [==============================] - 1s 33ms/step - loss: 0.3331 - accuracy: 0.8623 - val_loss: 0.5105 - val_accuracy: 0.7804\n",
      "Epoch 00002: early stopping\n",
      "16/16 [==============================] - 0s 7ms/step\n",
      "[CV]  num_filters=128, kern_size=7, fully_conected=800, epochs=15, batch_size=88, total=   3.7s\n",
      "[CV] num_filters=128, kern_size=7, fully_conected=800, epochs=15, batch_size=88 \n",
      "Epoch 1/15\n",
      "43/43 [==============================] - 2s 35ms/step - loss: 0.5728 - accuracy: 0.7275 - val_loss: 0.4700 - val_accuracy: 0.7828\n",
      "Epoch 2/15\n",
      "43/43 [==============================] - 1s 32ms/step - loss: 0.3554 - accuracy: 0.8472 - val_loss: 0.4664 - val_accuracy: 0.7852\n",
      "Epoch 3/15\n",
      "43/43 [==============================] - 1s 34ms/step - loss: 0.2232 - accuracy: 0.9133 - val_loss: 0.4796 - val_accuracy: 0.7804\n",
      "Epoch 00003: early stopping\n",
      "16/16 [==============================] - 0s 6ms/step\n",
      "[CV]  num_filters=128, kern_size=7, fully_conected=800, epochs=15, batch_size=88, total=   5.2s\n",
      "[CV] num_filters=128, kern_size=7, fully_conected=800, epochs=15, batch_size=88 \n",
      "Epoch 1/15\n",
      "43/43 [==============================] - 2s 37ms/step - loss: 0.5991 - accuracy: 0.6960 - val_loss: 0.5099 - val_accuracy: 0.7661\n",
      "Epoch 2/15\n",
      "43/43 [==============================] - 1s 34ms/step - loss: 0.3688 - accuracy: 0.8368 - val_loss: 0.5209 - val_accuracy: 0.7733\n",
      "Epoch 00002: early stopping\n",
      "16/16 [==============================] - 0s 7ms/step\n",
      "[CV]  num_filters=128, kern_size=7, fully_conected=800, epochs=15, batch_size=88, total=   3.9s\n",
      "[CV] num_filters=144, kern_size=3, fully_conected=800, epochs=15, batch_size=88 \n",
      "Epoch 1/15\n",
      "43/43 [==============================] - 2s 41ms/step - loss: 0.5429 - accuracy: 0.7243 - val_loss: 0.5043 - val_accuracy: 0.7446\n",
      "Epoch 2/15\n",
      "43/43 [==============================] - 2s 45ms/step - loss: 0.3482 - accuracy: 0.8543 - val_loss: 0.5300 - val_accuracy: 0.7589\n",
      "Epoch 00002: early stopping\n",
      "16/16 [==============================] - 0s 5ms/step\n",
      "[CV]  num_filters=144, kern_size=3, fully_conected=800, epochs=15, batch_size=88, total=   4.5s\n",
      "[CV] num_filters=144, kern_size=3, fully_conected=800, epochs=15, batch_size=88 \n",
      "Epoch 1/15\n",
      "43/43 [==============================] - 2s 43ms/step - loss: 0.5613 - accuracy: 0.7246 - val_loss: 0.4735 - val_accuracy: 0.7852\n",
      "Epoch 2/15\n",
      "43/43 [==============================] - 2s 37ms/step - loss: 0.3483 - accuracy: 0.8549 - val_loss: 0.4806 - val_accuracy: 0.7685\n",
      "Epoch 00002: early stopping\n",
      "16/16 [==============================] - 0s 6ms/step\n",
      "[CV]  num_filters=144, kern_size=3, fully_conected=800, epochs=15, batch_size=88, total=   4.3s\n",
      "[CV] num_filters=144, kern_size=3, fully_conected=800, epochs=15, batch_size=88 \n",
      "Epoch 1/15\n",
      "43/43 [==============================] - 2s 40ms/step - loss: 0.5496 - accuracy: 0.7331 - val_loss: 0.4903 - val_accuracy: 0.7733\n",
      "Epoch 2/15\n",
      "43/43 [==============================] - 2s 38ms/step - loss: 0.3372 - accuracy: 0.8565 - val_loss: 0.5085 - val_accuracy: 0.7852\n",
      "Epoch 00002: early stopping\n",
      "16/16 [==============================] - 0s 6ms/step\n",
      "[CV]  num_filters=144, kern_size=3, fully_conected=800, epochs=15, batch_size=88, total=   4.2s\n",
      "[CV] num_filters=144, kern_size=3, fully_conected=800, epochs=15, batch_size=88 \n",
      "Epoch 1/15\n",
      "43/43 [==============================] - 2s 39ms/step - loss: 0.6071 - accuracy: 0.7048 - val_loss: 0.4979 - val_accuracy: 0.7733\n",
      "Epoch 2/15\n",
      "43/43 [==============================] - 2s 37ms/step - loss: 0.3622 - accuracy: 0.8390 - val_loss: 0.5194 - val_accuracy: 0.7733\n",
      "Epoch 00002: early stopping\n",
      "16/16 [==============================] - 0s 6ms/step\n",
      "[CV]  num_filters=144, kern_size=3, fully_conected=800, epochs=15, batch_size=88, total=   4.1s\n",
      "[CV] num_filters=144, kern_size=3, fully_conected=30, epochs=15, batch_size=65 \n",
      "Epoch 1/15\n",
      "58/58 [==============================] - 1s 25ms/step - loss: 0.5295 - accuracy: 0.7379 - val_loss: 0.5360 - val_accuracy: 0.7613\n",
      "Epoch 2/15\n",
      "58/58 [==============================] - 1s 23ms/step - loss: 0.3855 - accuracy: 0.8379 - val_loss: 0.4804 - val_accuracy: 0.7757\n",
      "Epoch 3/15\n",
      "58/58 [==============================] - 1s 25ms/step - loss: 0.2974 - accuracy: 0.8884 - val_loss: 0.4832 - val_accuracy: 0.7757\n",
      "Epoch 00003: early stopping\n",
      "22/22 [==============================] - 0s 3ms/step\n",
      "[CV]  num_filters=144, kern_size=3, fully_conected=30, epochs=15, batch_size=65, total=   5.2s\n",
      "[CV] num_filters=144, kern_size=3, fully_conected=30, epochs=15, batch_size=65 \n",
      "Epoch 1/15\n",
      "58/58 [==============================] - 1s 21ms/step - loss: 0.5336 - accuracy: 0.7347 - val_loss: 0.4843 - val_accuracy: 0.7780\n",
      "Epoch 2/15\n",
      "58/58 [==============================] - 1s 22ms/step - loss: 0.3812 - accuracy: 0.8384 - val_loss: 0.4817 - val_accuracy: 0.7757\n",
      "Epoch 3/15\n",
      "58/58 [==============================] - 1s 21ms/step - loss: 0.2957 - accuracy: 0.8844 - val_loss: 0.4697 - val_accuracy: 0.7828\n",
      "Epoch 4/15\n",
      "58/58 [==============================] - 1s 23ms/step - loss: 0.2031 - accuracy: 0.9322 - val_loss: 0.4872 - val_accuracy: 0.7947\n",
      "Epoch 00004: early stopping\n",
      "22/22 [==============================] - 0s 2ms/step\n",
      "[CV]  num_filters=144, kern_size=3, fully_conected=30, epochs=15, batch_size=65, total=   6.4s\n",
      "[CV] num_filters=144, kern_size=3, fully_conected=30, epochs=15, batch_size=65 \n",
      "Epoch 1/15\n",
      "58/58 [==============================] - 1s 21ms/step - loss: 0.5360 - accuracy: 0.7265 - val_loss: 0.5276 - val_accuracy: 0.7685\n",
      "Epoch 2/15\n",
      "58/58 [==============================] - 1s 20ms/step - loss: 0.3797 - accuracy: 0.8448 - val_loss: 0.4672 - val_accuracy: 0.7971\n",
      "Epoch 3/15\n",
      "58/58 [==============================] - 1s 21ms/step - loss: 0.2813 - accuracy: 0.8900 - val_loss: 0.4783 - val_accuracy: 0.7995\n",
      "Epoch 00003: early stopping\n",
      "22/22 [==============================] - 0s 2ms/step\n",
      "[CV]  num_filters=144, kern_size=3, fully_conected=30, epochs=15, batch_size=65, total=   4.4s\n",
      "[CV] num_filters=144, kern_size=3, fully_conected=30, epochs=15, batch_size=65 \n",
      "Epoch 1/15\n",
      "58/58 [==============================] - 1s 21ms/step - loss: 0.5250 - accuracy: 0.7388 - val_loss: 0.5000 - val_accuracy: 0.7613\n",
      "Epoch 2/15\n",
      "58/58 [==============================] - 1s 21ms/step - loss: 0.3853 - accuracy: 0.8366 - val_loss: 0.4928 - val_accuracy: 0.7900\n",
      "Epoch 3/15\n",
      "58/58 [==============================] - 1s 21ms/step - loss: 0.2975 - accuracy: 0.8876 - val_loss: 0.5177 - val_accuracy: 0.7924\n",
      "Epoch 00003: early stopping\n",
      "22/22 [==============================] - 0s 2ms/step\n",
      "[CV]  num_filters=144, kern_size=3, fully_conected=30, epochs=15, batch_size=65, total=   4.4s\n",
      "[CV] num_filters=128, kern_size=3, fully_conected=30, epochs=15, batch_size=76 \n",
      "Epoch 1/15\n",
      "50/50 [==============================] - 1s 22ms/step - loss: 0.5467 - accuracy: 0.7251 - val_loss: 0.5045 - val_accuracy: 0.7637\n",
      "Epoch 2/15\n",
      "50/50 [==============================] - 1s 21ms/step - loss: 0.3947 - accuracy: 0.8296 - val_loss: 0.4684 - val_accuracy: 0.7852\n",
      "Epoch 3/15\n",
      "50/50 [==============================] - 1s 26ms/step - loss: 0.3144 - accuracy: 0.8772 - val_loss: 0.4765 - val_accuracy: 0.7685\n",
      "Epoch 00003: early stopping\n",
      "19/19 [==============================] - 0s 2ms/step\n",
      "[CV]  num_filters=128, kern_size=3, fully_conected=30, epochs=15, batch_size=76, total=   4.2s\n",
      "[CV] num_filters=128, kern_size=3, fully_conected=30, epochs=15, batch_size=76 \n",
      "Epoch 1/15\n",
      "50/50 [==============================] - 1s 24ms/step - loss: 0.6402 - accuracy: 0.6478 - val_loss: 0.5580 - val_accuracy: 0.7232\n",
      "Epoch 2/15\n",
      "50/50 [==============================] - 1s 22ms/step - loss: 0.4614 - accuracy: 0.8020 - val_loss: 0.4832 - val_accuracy: 0.7757\n",
      "Epoch 3/15\n",
      "50/50 [==============================] - 1s 24ms/step - loss: 0.3732 - accuracy: 0.8501 - val_loss: 0.4463 - val_accuracy: 0.8019\n",
      "Epoch 4/15\n",
      "50/50 [==============================] - 1s 25ms/step - loss: 0.2930 - accuracy: 0.8945 - val_loss: 0.4382 - val_accuracy: 0.7947\n",
      "Epoch 5/15\n",
      "50/50 [==============================] - 1s 25ms/step - loss: 0.2180 - accuracy: 0.9314 - val_loss: 0.4482 - val_accuracy: 0.7947\n",
      "Epoch 00005: early stopping\n",
      "19/19 [==============================] - 0s 2ms/step\n",
      "[CV]  num_filters=128, kern_size=3, fully_conected=30, epochs=15, batch_size=76, total=   6.7s\n",
      "[CV] num_filters=128, kern_size=3, fully_conected=30, epochs=15, batch_size=76 \n",
      "Epoch 1/15\n",
      "50/50 [==============================] - 1s 23ms/step - loss: 0.5407 - accuracy: 0.7305 - val_loss: 0.5184 - val_accuracy: 0.7613\n",
      "Epoch 2/15\n",
      "50/50 [==============================] - 1s 24ms/step - loss: 0.3922 - accuracy: 0.8328 - val_loss: 0.4679 - val_accuracy: 0.7780\n",
      "Epoch 3/15\n",
      "50/50 [==============================] - 1s 26ms/step - loss: 0.3147 - accuracy: 0.8753 - val_loss: 0.4599 - val_accuracy: 0.7924\n",
      "Epoch 4/15\n",
      "50/50 [==============================] - 1s 23ms/step - loss: 0.2365 - accuracy: 0.9213 - val_loss: 0.4797 - val_accuracy: 0.8043\n",
      "Epoch 00004: early stopping\n",
      "19/19 [==============================] - 0s 2ms/step\n",
      "[CV]  num_filters=128, kern_size=3, fully_conected=30, epochs=15, batch_size=76, total=   5.6s\n",
      "[CV] num_filters=128, kern_size=3, fully_conected=30, epochs=15, batch_size=76 \n",
      "Epoch 1/15\n",
      "50/50 [==============================] - 1s 24ms/step - loss: 0.5487 - accuracy: 0.7218 - val_loss: 0.5199 - val_accuracy: 0.7709\n",
      "Epoch 2/15\n",
      "50/50 [==============================] - 1s 21ms/step - loss: 0.3916 - accuracy: 0.8262 - val_loss: 0.5034 - val_accuracy: 0.7685\n",
      "Epoch 3/15\n",
      "50/50 [==============================] - 1s 21ms/step - loss: 0.3029 - accuracy: 0.8809 - val_loss: 0.5097 - val_accuracy: 0.7780\n",
      "Epoch 00003: early stopping\n",
      "19/19 [==============================] - 0s 2ms/step\n",
      "[CV]  num_filters=128, kern_size=3, fully_conected=30, epochs=15, batch_size=76, total=   4.1s\n",
      "[CV] num_filters=128, kern_size=3, fully_conected=60, epochs=15, batch_size=76 \n",
      "Epoch 1/15\n",
      "50/50 [==============================] - 1s 23ms/step - loss: 0.5502 - accuracy: 0.7180 - val_loss: 0.5194 - val_accuracy: 0.7542\n",
      "Epoch 2/15\n",
      "50/50 [==============================] - 1s 22ms/step - loss: 0.3925 - accuracy: 0.8344 - val_loss: 0.4670 - val_accuracy: 0.7780\n",
      "Epoch 3/15\n",
      "50/50 [==============================] - 1s 22ms/step - loss: 0.3030 - accuracy: 0.8801 - val_loss: 0.5135 - val_accuracy: 0.7685\n",
      "Epoch 00003: early stopping\n",
      "19/19 [==============================] - 0s 2ms/step\n",
      "[CV]  num_filters=128, kern_size=3, fully_conected=60, epochs=15, batch_size=76, total=   4.1s\n",
      "[CV] num_filters=128, kern_size=3, fully_conected=60, epochs=15, batch_size=76 \n",
      "Epoch 1/15\n",
      "50/50 [==============================] - 1s 23ms/step - loss: 0.5398 - accuracy: 0.7254 - val_loss: 0.5168 - val_accuracy: 0.7613\n",
      "Epoch 2/15\n",
      "50/50 [==============================] - 1s 22ms/step - loss: 0.3804 - accuracy: 0.8442 - val_loss: 0.4922 - val_accuracy: 0.7900\n",
      "Epoch 3/15\n",
      "50/50 [==============================] - 1s 23ms/step - loss: 0.2933 - accuracy: 0.8793 - val_loss: 0.4809 - val_accuracy: 0.7733\n",
      "Epoch 4/15\n",
      "50/50 [==============================] - 1s 23ms/step - loss: 0.1969 - accuracy: 0.9335 - val_loss: 0.5221 - val_accuracy: 0.7733\n",
      "Epoch 00004: early stopping\n",
      "19/19 [==============================] - 0s 2ms/step\n",
      "[CV]  num_filters=128, kern_size=3, fully_conected=60, epochs=15, batch_size=76, total=   5.3s\n",
      "[CV] num_filters=128, kern_size=3, fully_conected=60, epochs=15, batch_size=76 \n",
      "Epoch 1/15\n",
      "50/50 [==============================] - 1s 24ms/step - loss: 0.5211 - accuracy: 0.7432 - val_loss: 0.5137 - val_accuracy: 0.7709\n",
      "Epoch 2/15\n",
      "50/50 [==============================] - 1s 23ms/step - loss: 0.3728 - accuracy: 0.8376 - val_loss: 0.4845 - val_accuracy: 0.7876\n",
      "Epoch 3/15\n",
      "50/50 [==============================] - 1s 24ms/step - loss: 0.2785 - accuracy: 0.8937 - val_loss: 0.4915 - val_accuracy: 0.7924\n",
      "Epoch 00003: early stopping\n",
      "19/19 [==============================] - 0s 2ms/step\n",
      "[CV]  num_filters=128, kern_size=3, fully_conected=60, epochs=15, batch_size=76, total=   4.2s\n",
      "[CV] num_filters=128, kern_size=3, fully_conected=60, epochs=15, batch_size=76 \n",
      "Epoch 1/15\n",
      "50/50 [==============================] - 1s 23ms/step - loss: 0.5331 - accuracy: 0.7449 - val_loss: 0.4998 - val_accuracy: 0.7733\n",
      "Epoch 2/15\n",
      "50/50 [==============================] - 1s 22ms/step - loss: 0.3773 - accuracy: 0.8363 - val_loss: 0.5006 - val_accuracy: 0.7852\n",
      "Epoch 00002: early stopping\n",
      "19/19 [==============================] - 0s 2ms/step\n",
      "[CV]  num_filters=128, kern_size=3, fully_conected=60, epochs=15, batch_size=76, total=   3.0s\n",
      "Epoch 1/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  20 out of  20 | elapsed:  1.5min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "67/67 [==============================] - 1s 21ms/step - loss: 0.5192 - accuracy: 0.7403 - val_loss: 0.4657 - val_accuracy: 0.7867\n",
      "Epoch 2/15\n",
      "67/67 [==============================] - 1s 21ms/step - loss: 0.3811 - accuracy: 0.8380 - val_loss: 0.4836 - val_accuracy: 0.7849\n",
      "Epoch 00002: early stopping\n",
      "25/25 [==============================] - 0s 2ms/step\n",
      "Best Accuracy : 0.8083\n",
      "{'num_filters': 128, 'kern_size': 3, 'fully_conected': 60, 'epochs': 15, 'batch_size': 76}\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "param_grid = dict(num_filters=[32, 128, 144, 256],\n",
    "                      kern_size=[3, 5, 7],\n",
    "                      batch_size = [45,65,76,88],\n",
    "                      fully_conected = [30, 60, 800], epochs = [15])\n",
    "\n",
    "model = KerasClassifier(build_fn=build_model, epochs=15, validation_split=0.1,verbose=1)\n",
    "\n",
    "grid = RandomizedSearchCV(estimator=model, param_distributions=param_grid,\n",
    "                              cv=4, verbose=2, n_iter=5, n_jobs=1,scoring = 'accuracy')\n",
    "\n",
    "grid_result = grid.fit(x_train, y_train, callbacks=[callback])\n",
    "\n",
    "\n",
    "test_accuracy = grid.score(x_test, y_test)\n",
    "\n",
    "# Save and evaluate results\n",
    "s = ('Best Accuracy : {:.4f}\\n{}\\n\\n\\n')\n",
    "output_string = s.format(\n",
    "            grid_result.best_score_,\n",
    "            grid_result.best_params_)\n",
    "            \n",
    "print(output_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "e = Embedding(vocab_size, 100, weights=[embedding_matrix], input_length=31, trainable=True)\n",
    "model.add(e)\n",
    "model.add(layers.Conv1D(128, 3, activation='relu'))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(60, activation='sigmoid'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "74/74 - 1s - loss: 0.5077 - accuracy: 0.7516 - val_loss: 0.4315 - val_accuracy: 0.8112\n",
      "Epoch 2/15\n",
      "74/74 - 1s - loss: 0.3732 - accuracy: 0.8348 - val_loss: 0.4110 - val_accuracy: 0.8289\n",
      "Epoch 3/15\n",
      "74/74 - 1s - loss: 0.2807 - accuracy: 0.8874 - val_loss: 0.4254 - val_accuracy: 0.8219\n",
      "Epoch 00003: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1e9752a50>"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = \\\n",
    "train_test_split(padded_docs, tweets['target'], test_size = 0.25, random_state = 123)\n",
    "callback = EarlyStopping(monitor = 'val_loss', patience = 1, verbose=1)\n",
    "callbacks = [callback]\n",
    "\n",
    "model.fit(x_train, y_train,\n",
    "          validation_data=(x_test, y_test),\n",
    "          batch_size=76,\n",
    "          epochs=15,\n",
    "          verbose=2,\n",
    "          callbacks=callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = Sequential()\n",
    "e = Embedding(vocab_size, 100, weights=[embedding_matrix], input_length=31, trainable=True)\n",
    "model2.add(e)\n",
    "model2.add(layers.Conv1D(128, 3, activation='relu'))\n",
    "model2.add(Flatten())\n",
    "model2.add(Dense(60, activation='sigmoid'))\n",
    "model2.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model2.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "98/98 - 2s - loss: 0.5198 - accuracy: 0.7441\n",
      "Epoch 2/2\n",
      "98/98 - 2s - loss: 0.3652 - accuracy: 0.8445\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x20498b590>"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.fit(padded_docs, tweets['target'],\n",
    "          batch_size=76,\n",
    "          epochs=2,\n",
    "          verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_result = model1.predict(padded_tests)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.674353  ],\n",
       "       [0.80772024],\n",
       "       [0.6589092 ],\n",
       "       ...,\n",
       "       [0.8821541 ],\n",
       "       [0.8534104 ],\n",
       "       [0.3019307 ]], dtype=float32)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " ...]"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submit = []\n",
    "\n",
    "for i in test_result:\n",
    "    if i >= 0.5 :\n",
    "        submit.append(1)\n",
    "    else:\n",
    "        submit.append(0)\n",
    "\n",
    "submit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "tests['target'] = submit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit_df = tests[['id', 'target']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3258</th>\n",
       "      <td>10861</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3259</th>\n",
       "      <td>10865</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3260</th>\n",
       "      <td>10868</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3261</th>\n",
       "      <td>10874</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3262</th>\n",
       "      <td>10875</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3263 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id  target\n",
       "0         0       1\n",
       "1         2       1\n",
       "2         3       1\n",
       "3         9       1\n",
       "4        11       1\n",
       "...     ...     ...\n",
       "3258  10861       1\n",
       "3259  10865       1\n",
       "3260  10868       1\n",
       "3261  10874       1\n",
       "3262  10875       0\n",
       "\n",
       "[3263 rows x 2 columns]"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submit_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit_df.to_csv('submit_prueba_37.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding, Flatten, Dense\n",
    "from keras import layers\n",
    "\n",
    "from keras.callbacks import EarlyStopping\n",
    "callback = EarlyStopping(monitor = 'val_loss', patience = 1, verbose=1)\n",
    "callbacks = [callback]\n",
    "\n",
    "def build_model(fully_conected, num_filters, kern_size):\n",
    "    model1 = Sequential()\n",
    "    e = Embedding(vocab_size, 100, weights=[embedding_matrix], input_length=31, trainable=True)\n",
    "    model1.add(e)\n",
    "    model1.add(layers.Conv1D(128, 3, activation='relu'))\n",
    "    model1.add(layers.Conv1D(num_filters, kern_size, activation='relu'))\n",
    "    model1.add(Flatten())\n",
    "    model1.add(Dense(fully_conected, activation='sigmoid'))\n",
    "    model1.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    model1.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    return model1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 folds for each of 5 candidates, totalling 20 fits\n",
      "[CV] num_filters=256, kern_size=3, fully_conected=60, epochs=15, batch_size=76 \n",
      "Epoch 1/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50/50 [==============================] - 1s 29ms/step - loss: 0.5217 - accuracy: 0.7584 - val_loss: 0.4831 - val_accuracy: 0.7757\n",
      "Epoch 2/15\n",
      "50/50 [==============================] - 1s 26ms/step - loss: 0.3787 - accuracy: 0.8394 - val_loss: 0.4705 - val_accuracy: 0.7757\n",
      "Epoch 3/15\n",
      "50/50 [==============================] - 1s 26ms/step - loss: 0.2869 - accuracy: 0.8844 - val_loss: 0.4811 - val_accuracy: 0.7924\n",
      "Epoch 00003: early stopping\n",
      "19/19 [==============================] - 0s 5ms/step\n",
      "[CV]  num_filters=256, kern_size=3, fully_conected=60, epochs=15, batch_size=76, total=   4.9s\n",
      "[CV] num_filters=256, kern_size=3, fully_conected=60, epochs=15, batch_size=76 \n",
      "Epoch 1/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    4.9s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50/50 [==============================] - 1s 29ms/step - loss: 0.5228 - accuracy: 0.7414 - val_loss: 0.4945 - val_accuracy: 0.7733\n",
      "Epoch 2/15\n",
      "50/50 [==============================] - 1s 27ms/step - loss: 0.3801 - accuracy: 0.8357 - val_loss: 0.4576 - val_accuracy: 0.7828\n",
      "Epoch 3/15\n",
      "50/50 [==============================] - 1s 27ms/step - loss: 0.2757 - accuracy: 0.8966 - val_loss: 0.4897 - val_accuracy: 0.7852\n",
      "Epoch 00003: early stopping\n",
      "19/19 [==============================] - 0s 5ms/step\n",
      "[CV]  num_filters=256, kern_size=3, fully_conected=60, epochs=15, batch_size=76, total=   5.0s\n",
      "[CV] num_filters=256, kern_size=3, fully_conected=60, epochs=15, batch_size=76 \n",
      "Epoch 1/15\n",
      "50/50 [==============================] - 1s 29ms/step - loss: 0.5473 - accuracy: 0.7289 - val_loss: 0.4920 - val_accuracy: 0.7828\n",
      "Epoch 2/15\n",
      "50/50 [==============================] - 1s 27ms/step - loss: 0.3826 - accuracy: 0.8315 - val_loss: 0.4769 - val_accuracy: 0.7804\n",
      "Epoch 3/15\n",
      "50/50 [==============================] - 1s 28ms/step - loss: 0.2980 - accuracy: 0.8838 - val_loss: 0.4799 - val_accuracy: 0.7613\n",
      "Epoch 00003: early stopping\n",
      "19/19 [==============================] - 0s 5ms/step\n",
      "[CV]  num_filters=256, kern_size=3, fully_conected=60, epochs=15, batch_size=76, total=   5.1s\n",
      "[CV] num_filters=256, kern_size=3, fully_conected=60, epochs=15, batch_size=76 \n",
      "Epoch 1/15\n",
      "50/50 [==============================] - 1s 29ms/step - loss: 0.5439 - accuracy: 0.7186 - val_loss: 0.5089 - val_accuracy: 0.7661\n",
      "Epoch 2/15\n",
      "50/50 [==============================] - 1s 27ms/step - loss: 0.3994 - accuracy: 0.8246 - val_loss: 0.5309 - val_accuracy: 0.7733\n",
      "Epoch 00002: early stopping\n",
      "19/19 [==============================] - 0s 5ms/step\n",
      "[CV]  num_filters=256, kern_size=3, fully_conected=60, epochs=15, batch_size=76, total=   3.7s\n",
      "[CV] num_filters=144, kern_size=7, fully_conected=60, epochs=15, batch_size=88 \n",
      "Epoch 1/15\n",
      "43/43 [==============================] - 1s 33ms/step - loss: 0.5387 - accuracy: 0.7307 - val_loss: 0.5175 - val_accuracy: 0.7542\n",
      "Epoch 2/15\n",
      "43/43 [==============================] - 1s 32ms/step - loss: 0.4048 - accuracy: 0.8232 - val_loss: 0.4650 - val_accuracy: 0.7780\n",
      "Epoch 3/15\n",
      "43/43 [==============================] - 2s 40ms/step - loss: 0.3115 - accuracy: 0.8751 - val_loss: 0.4826 - val_accuracy: 0.7804\n",
      "Epoch 00003: early stopping\n",
      "16/16 [==============================] - 0s 6ms/step\n",
      "[CV]  num_filters=144, kern_size=7, fully_conected=60, epochs=15, batch_size=88, total=   5.4s\n",
      "[CV] num_filters=144, kern_size=7, fully_conected=60, epochs=15, batch_size=88 \n",
      "Epoch 1/15\n",
      "43/43 [==============================] - 2s 36ms/step - loss: 0.5309 - accuracy: 0.7387 - val_loss: 0.4724 - val_accuracy: 0.7876\n",
      "Epoch 2/15\n",
      "43/43 [==============================] - 2s 35ms/step - loss: 0.3887 - accuracy: 0.8291 - val_loss: 0.4607 - val_accuracy: 0.7780\n",
      "Epoch 3/15\n",
      "43/43 [==============================] - 2s 36ms/step - loss: 0.2895 - accuracy: 0.8878 - val_loss: 0.5192 - val_accuracy: 0.7494\n",
      "Epoch 00003: early stopping\n",
      "16/16 [==============================] - 0s 6ms/step\n",
      "[CV]  num_filters=144, kern_size=7, fully_conected=60, epochs=15, batch_size=88, total=   5.5s\n",
      "[CV] num_filters=144, kern_size=7, fully_conected=60, epochs=15, batch_size=88 \n",
      "Epoch 1/15\n",
      "43/43 [==============================] - 2s 37ms/step - loss: 0.5541 - accuracy: 0.7166 - val_loss: 0.5059 - val_accuracy: 0.7542\n",
      "Epoch 2/15\n",
      "43/43 [==============================] - 2s 36ms/step - loss: 0.3916 - accuracy: 0.8344 - val_loss: 0.4795 - val_accuracy: 0.7852\n",
      "Epoch 3/15\n",
      "43/43 [==============================] - 2s 40ms/step - loss: 0.2990 - accuracy: 0.8799 - val_loss: 0.4682 - val_accuracy: 0.7900\n",
      "Epoch 4/15\n",
      "43/43 [==============================] - 2s 39ms/step - loss: 0.1840 - accuracy: 0.9367 - val_loss: 0.5397 - val_accuracy: 0.7780\n",
      "Epoch 00004: early stopping\n",
      "16/16 [==============================] - 0s 11ms/step\n",
      "[CV]  num_filters=144, kern_size=7, fully_conected=60, epochs=15, batch_size=88, total=   7.6s\n",
      "[CV] num_filters=144, kern_size=7, fully_conected=60, epochs=15, batch_size=88 \n",
      "Epoch 1/15\n",
      "43/43 [==============================] - 2s 48ms/step - loss: 0.5446 - accuracy: 0.7260 - val_loss: 0.5065 - val_accuracy: 0.7542\n",
      "Epoch 2/15\n",
      "43/43 [==============================] - 2s 43ms/step - loss: 0.3939 - accuracy: 0.8275 - val_loss: 0.5027 - val_accuracy: 0.7804\n",
      "Epoch 3/15\n",
      "43/43 [==============================] - 2s 42ms/step - loss: 0.3008 - accuracy: 0.8815 - val_loss: 0.5439 - val_accuracy: 0.7661\n",
      "Epoch 00003: early stopping\n",
      "16/16 [==============================] - 0s 6ms/step\n",
      "[CV]  num_filters=144, kern_size=7, fully_conected=60, epochs=15, batch_size=88, total=   6.7s\n",
      "[CV] num_filters=256, kern_size=5, fully_conected=800, epochs=15, batch_size=76 \n",
      "Epoch 1/15\n",
      "50/50 [==============================] - 4s 75ms/step - loss: 0.6425 - accuracy: 0.6571 - val_loss: 0.5169 - val_accuracy: 0.7542\n",
      "Epoch 2/15\n",
      "50/50 [==============================] - 5s 93ms/step - loss: 0.4203 - accuracy: 0.8190 - val_loss: 0.4655 - val_accuracy: 0.7661\n",
      "Epoch 3/15\n",
      "50/50 [==============================] - 3s 67ms/step - loss: 0.3321 - accuracy: 0.8650 - val_loss: 0.4704 - val_accuracy: 0.7757\n",
      "Epoch 00003: early stopping\n",
      "19/19 [==============================] - 0s 10ms/step\n",
      "[CV]  num_filters=256, kern_size=5, fully_conected=800, epochs=15, batch_size=76, total=  13.1s\n",
      "[CV] num_filters=256, kern_size=5, fully_conected=800, epochs=15, batch_size=76 \n",
      "Epoch 1/15\n",
      "50/50 [==============================] - 3s 69ms/step - loss: 0.6040 - accuracy: 0.7041 - val_loss: 0.4901 - val_accuracy: 0.7661\n",
      "Epoch 2/15\n",
      "50/50 [==============================] - 3s 67ms/step - loss: 0.4036 - accuracy: 0.8235 - val_loss: 0.4441 - val_accuracy: 0.7971\n",
      "Epoch 3/15\n",
      "50/50 [==============================] - 3s 67ms/step - loss: 0.3031 - accuracy: 0.8732 - val_loss: 0.4731 - val_accuracy: 0.7828\n",
      "Epoch 00003: early stopping\n",
      "19/19 [==============================] - 0s 10ms/step\n",
      "[CV]  num_filters=256, kern_size=5, fully_conected=800, epochs=15, batch_size=76, total=  11.7s\n",
      "[CV] num_filters=256, kern_size=5, fully_conected=800, epochs=15, batch_size=76 \n",
      "Epoch 1/15\n",
      "50/50 [==============================] - 4s 70ms/step - loss: 0.6233 - accuracy: 0.6685 - val_loss: 0.6068 - val_accuracy: 0.7064\n",
      "Epoch 2/15\n",
      "50/50 [==============================] - 3s 66ms/step - loss: 0.4126 - accuracy: 0.8203 - val_loss: 0.4594 - val_accuracy: 0.7757\n",
      "Epoch 3/15\n",
      "50/50 [==============================] - 3s 67ms/step - loss: 0.3081 - accuracy: 0.8745 - val_loss: 0.4639 - val_accuracy: 0.7852\n",
      "Epoch 00003: early stopping\n",
      "19/19 [==============================] - 0s 11ms/step\n",
      "[CV]  num_filters=256, kern_size=5, fully_conected=800, epochs=15, batch_size=76, total=  11.3s\n",
      "[CV] num_filters=256, kern_size=5, fully_conected=800, epochs=15, batch_size=76 \n",
      "Epoch 1/15\n",
      "50/50 [==============================] - 4s 72ms/step - loss: 0.6523 - accuracy: 0.6407 - val_loss: 0.5299 - val_accuracy: 0.7494\n",
      "Epoch 2/15\n",
      "50/50 [==============================] - 3s 69ms/step - loss: 0.4306 - accuracy: 0.8049 - val_loss: 0.5029 - val_accuracy: 0.7685\n",
      "Epoch 3/15\n",
      "50/50 [==============================] - 4s 73ms/step - loss: 0.3237 - accuracy: 0.8605 - val_loss: 0.5240 - val_accuracy: 0.7757\n",
      "Epoch 00003: early stopping\n",
      "19/19 [==============================] - 0s 10ms/step\n",
      "[CV]  num_filters=256, kern_size=5, fully_conected=800, epochs=15, batch_size=76, total=  11.8s\n",
      "[CV] num_filters=144, kern_size=7, fully_conected=60, epochs=15, batch_size=76 \n",
      "Epoch 1/15\n",
      "50/50 [==============================] - 2s 44ms/step - loss: 0.5202 - accuracy: 0.7430 - val_loss: 0.4927 - val_accuracy: 0.7494\n",
      "Epoch 2/15\n",
      "50/50 [==============================] - 2s 39ms/step - loss: 0.3919 - accuracy: 0.8328 - val_loss: 0.4552 - val_accuracy: 0.7780\n",
      "Epoch 3/15\n",
      "50/50 [==============================] - 2s 36ms/step - loss: 0.3095 - accuracy: 0.8799 - val_loss: 0.4657 - val_accuracy: 0.7852\n",
      "Epoch 00003: early stopping\n",
      "19/19 [==============================] - 0s 6ms/step\n",
      "[CV]  num_filters=144, kern_size=7, fully_conected=60, epochs=15, batch_size=76, total=   7.0s\n",
      "[CV] num_filters=144, kern_size=7, fully_conected=60, epochs=15, batch_size=76 \n",
      "Epoch 1/15\n",
      "50/50 [==============================] - 2s 37ms/step - loss: 0.5484 - accuracy: 0.7259 - val_loss: 0.5159 - val_accuracy: 0.7613\n",
      "Epoch 2/15\n",
      "50/50 [==============================] - 2s 38ms/step - loss: 0.3952 - accuracy: 0.8251 - val_loss: 0.4746 - val_accuracy: 0.7733\n",
      "Epoch 3/15\n",
      "50/50 [==============================] - 2s 32ms/step - loss: 0.3010 - accuracy: 0.8759 - val_loss: 0.4566 - val_accuracy: 0.7900\n",
      "Epoch 4/15\n",
      "50/50 [==============================] - 2s 32ms/step - loss: 0.2074 - accuracy: 0.9224 - val_loss: 0.5796 - val_accuracy: 0.7661\n",
      "Epoch 00004: early stopping\n",
      "19/19 [==============================] - 0s 4ms/step\n",
      "[CV]  num_filters=144, kern_size=7, fully_conected=60, epochs=15, batch_size=76, total=   7.9s\n",
      "[CV] num_filters=144, kern_size=7, fully_conected=60, epochs=15, batch_size=76 \n",
      "Epoch 1/15\n",
      "50/50 [==============================] - 2s 34ms/step - loss: 0.5541 - accuracy: 0.7166 - val_loss: 0.4849 - val_accuracy: 0.7780\n",
      "Epoch 2/15\n",
      "50/50 [==============================] - 2s 32ms/step - loss: 0.3894 - accuracy: 0.8299 - val_loss: 0.4534 - val_accuracy: 0.7947\n",
      "Epoch 3/15\n",
      "50/50 [==============================] - 2s 33ms/step - loss: 0.2826 - accuracy: 0.8868 - val_loss: 0.4985 - val_accuracy: 0.7995\n",
      "Epoch 00003: early stopping\n",
      "19/19 [==============================] - 0s 5ms/step\n",
      "[CV]  num_filters=144, kern_size=7, fully_conected=60, epochs=15, batch_size=76, total=   6.0s\n",
      "[CV] num_filters=144, kern_size=7, fully_conected=60, epochs=15, batch_size=76 \n",
      "Epoch 1/15\n",
      "50/50 [==============================] - 2s 35ms/step - loss: 0.5524 - accuracy: 0.7279 - val_loss: 0.5069 - val_accuracy: 0.7685\n",
      "Epoch 2/15\n",
      "50/50 [==============================] - 2s 32ms/step - loss: 0.3915 - accuracy: 0.8318 - val_loss: 0.5026 - val_accuracy: 0.7828\n",
      "Epoch 3/15\n",
      "50/50 [==============================] - 2s 33ms/step - loss: 0.3070 - accuracy: 0.8783 - val_loss: 0.5097 - val_accuracy: 0.7709\n",
      "Epoch 00003: early stopping\n",
      "19/19 [==============================] - 0s 6ms/step\n",
      "[CV]  num_filters=144, kern_size=7, fully_conected=60, epochs=15, batch_size=76, total=   6.1s\n",
      "[CV] num_filters=256, kern_size=7, fully_conected=60, epochs=15, batch_size=76 \n",
      "Epoch 1/15\n",
      "50/50 [==============================] - 2s 38ms/step - loss: 0.6182 - accuracy: 0.6494 - val_loss: 0.5431 - val_accuracy: 0.7422\n",
      "Epoch 2/15\n",
      "50/50 [==============================] - 2s 37ms/step - loss: 0.4298 - accuracy: 0.8126 - val_loss: 0.4742 - val_accuracy: 0.7780\n",
      "Epoch 3/15\n",
      "50/50 [==============================] - 2s 38ms/step - loss: 0.3396 - accuracy: 0.8570 - val_loss: 0.5040 - val_accuracy: 0.7900\n",
      "Epoch 00003: early stopping\n",
      "19/19 [==============================] - 0s 7ms/step\n",
      "[CV]  num_filters=256, kern_size=7, fully_conected=60, epochs=15, batch_size=76, total=   7.6s\n",
      "[CV] num_filters=256, kern_size=7, fully_conected=60, epochs=15, batch_size=76 \n",
      "Epoch 1/15\n",
      "50/50 [==============================] - 2s 39ms/step - loss: 0.5728 - accuracy: 0.6847 - val_loss: 0.5118 - val_accuracy: 0.7589\n",
      "Epoch 2/15\n",
      "50/50 [==============================] - 2s 37ms/step - loss: 0.4087 - accuracy: 0.8248 - val_loss: 0.4735 - val_accuracy: 0.7733\n",
      "Epoch 3/15\n",
      "50/50 [==============================] - 2s 39ms/step - loss: 0.3029 - accuracy: 0.8761 - val_loss: 0.4604 - val_accuracy: 0.7757\n",
      "Epoch 4/15\n",
      "50/50 [==============================] - 2s 40ms/step - loss: 0.1856 - accuracy: 0.9333 - val_loss: 0.5249 - val_accuracy: 0.7709\n",
      "Epoch 00004: early stopping\n",
      "19/19 [==============================] - 0s 7ms/step\n",
      "[CV]  num_filters=256, kern_size=7, fully_conected=60, epochs=15, batch_size=76, total=   8.9s\n",
      "[CV] num_filters=256, kern_size=7, fully_conected=60, epochs=15, batch_size=76 \n",
      "Epoch 1/15\n",
      "50/50 [==============================] - 2s 39ms/step - loss: 0.5081 - accuracy: 0.7562 - val_loss: 0.5167 - val_accuracy: 0.7566\n",
      "Epoch 2/15\n",
      "50/50 [==============================] - 2s 38ms/step - loss: 0.3932 - accuracy: 0.8325 - val_loss: 0.4733 - val_accuracy: 0.7900\n",
      "Epoch 3/15\n",
      "50/50 [==============================] - 2s 38ms/step - loss: 0.3071 - accuracy: 0.8751 - val_loss: 0.4597 - val_accuracy: 0.7947\n",
      "Epoch 4/15\n",
      "50/50 [==============================] - 2s 40ms/step - loss: 0.2137 - accuracy: 0.9219 - val_loss: 0.4847 - val_accuracy: 0.7733\n",
      "Epoch 00004: early stopping\n",
      "19/19 [==============================] - 0s 7ms/step\n",
      "[CV]  num_filters=256, kern_size=7, fully_conected=60, epochs=15, batch_size=76, total=   9.0s\n",
      "[CV] num_filters=256, kern_size=7, fully_conected=60, epochs=15, batch_size=76 \n",
      "Epoch 1/15\n",
      "50/50 [==============================] - 2s 39ms/step - loss: 0.5264 - accuracy: 0.7414 - val_loss: 0.5002 - val_accuracy: 0.7733\n",
      "Epoch 2/15\n",
      "50/50 [==============================] - 2s 37ms/step - loss: 0.3835 - accuracy: 0.8339 - val_loss: 0.5111 - val_accuracy: 0.7852\n",
      "Epoch 00002: early stopping\n",
      "19/19 [==============================] - 0s 6ms/step\n",
      "[CV]  num_filters=256, kern_size=7, fully_conected=60, epochs=15, batch_size=76, total=   4.9s\n",
      "Epoch 1/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  20 out of  20 | elapsed:  2.5min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "67/67 [==============================] - 4s 66ms/step - loss: 0.5179 - accuracy: 0.7491 - val_loss: 0.4539 - val_accuracy: 0.7939\n",
      "Epoch 2/15\n",
      "67/67 [==============================] - 5s 68ms/step - loss: 0.3825 - accuracy: 0.8342 - val_loss: 0.4434 - val_accuracy: 0.7921\n",
      "Epoch 3/15\n",
      "67/67 [==============================] - 4s 66ms/step - loss: 0.3046 - accuracy: 0.8728 - val_loss: 0.4469 - val_accuracy: 0.8047\n",
      "Epoch 00003: early stopping\n",
      "25/25 [==============================] - 0s 10ms/step\n",
      "Best Accuracy : 0.8074\n",
      "{'num_filters': 256, 'kern_size': 5, 'fully_conected': 800, 'epochs': 15, 'batch_size': 76}\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "param_grid = dict(num_filters=[ 144, 256],\n",
    "                      kern_size=[3, 5, 7],\n",
    "                      batch_size = [76,88],\n",
    "                      fully_conected = [60, 800], epochs = [15])\n",
    "\n",
    "model = KerasClassifier(build_fn=build_model, epochs=15, validation_split=0.1,verbose=1)\n",
    "\n",
    "grid = RandomizedSearchCV(estimator=model, param_distributions=param_grid,\n",
    "                              cv=4, verbose=2, n_iter=5, n_jobs=1,scoring = 'accuracy')\n",
    "\n",
    "grid_result = grid.fit(x_train, y_train, callbacks=[callback])\n",
    "\n",
    "\n",
    "test_accuracy = grid.score(x_test, y_test)\n",
    "\n",
    "# Save and evaluate results\n",
    "s = ('Best Accuracy : {:.4f}\\n{}\\n\\n\\n')\n",
    "output_string = s.format(\n",
    "            grid_result.best_score_,\n",
    "            grid_result.best_params_)\n",
    "            \n",
    "print(output_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "para submitear"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding, Flatten, Dense\n",
    "from keras import layers\n",
    "\n",
    "from keras.callbacks import EarlyStopping\n",
    "callback = EarlyStopping(monitor = 'val_loss', patience = 1, verbose=1)\n",
    "callbacks = [callback]\n",
    "\n",
    "def build_model(fully_conected, num_filters, kern_size):\n",
    "    model1 = Sequential()\n",
    "    e = Embedding(vocab_size, 100, weights=[embedding_matrix], input_length=31, trainable=True)\n",
    "    model1.add(e)\n",
    "    model1.add(layers.Conv1D(num_filters, kern_size, activation='relu'))\n",
    "    model1.add(layers.Conv1D(128, 3, activation='relu'))\n",
    "    model1.add(Flatten())\n",
    "    model1.add(Dense(fully_conected, activation='sigmoid'))\n",
    "    model1.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    model1.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    return model1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 folds for each of 5 candidates, totalling 20 fits\n",
      "[CV] num_filters=144, kern_size=3, fully_conected=60, epochs=15, batch_size=88 \n",
      "Epoch 1/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43/43 [==============================] - 1s 32ms/step - loss: 0.5438 - accuracy: 0.7228 - val_loss: 0.4972 - val_accuracy: 0.7637\n",
      "Epoch 2/15\n",
      "43/43 [==============================] - 1s 27ms/step - loss: 0.4022 - accuracy: 0.8307 - val_loss: 0.4736 - val_accuracy: 0.7804\n",
      "Epoch 3/15\n",
      "43/43 [==============================] - 1s 26ms/step - loss: 0.3255 - accuracy: 0.8655 - val_loss: 0.4943 - val_accuracy: 0.7804\n",
      "Epoch 00003: early stopping\n",
      "16/16 [==============================] - 0s 3ms/step\n",
      "[CV]  num_filters=144, kern_size=3, fully_conected=60, epochs=15, batch_size=88, total=   4.5s\n",
      "[CV] num_filters=144, kern_size=3, fully_conected=60, epochs=15, batch_size=88 \n",
      "Epoch 1/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    4.5s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43/43 [==============================] - 1s 30ms/step - loss: 0.5856 - accuracy: 0.6853 - val_loss: 0.5365 - val_accuracy: 0.7470\n",
      "Epoch 2/15\n",
      "43/43 [==============================] - 1s 27ms/step - loss: 0.4085 - accuracy: 0.8267 - val_loss: 0.4537 - val_accuracy: 0.7900\n",
      "Epoch 3/15\n",
      "43/43 [==============================] - 1s 27ms/step - loss: 0.3208 - accuracy: 0.8737 - val_loss: 0.4892 - val_accuracy: 0.7924\n",
      "Epoch 00003: early stopping\n",
      "16/16 [==============================] - 0s 5ms/step\n",
      "[CV]  num_filters=144, kern_size=3, fully_conected=60, epochs=15, batch_size=88, total=   4.4s\n",
      "[CV] num_filters=144, kern_size=3, fully_conected=60, epochs=15, batch_size=88 \n",
      "Epoch 1/15\n",
      "43/43 [==============================] - 1s 29ms/step - loss: 0.5471 - accuracy: 0.7246 - val_loss: 0.5032 - val_accuracy: 0.7637\n",
      "Epoch 2/15\n",
      "43/43 [==============================] - 1s 27ms/step - loss: 0.4042 - accuracy: 0.8206 - val_loss: 0.4665 - val_accuracy: 0.7900\n",
      "Epoch 3/15\n",
      "43/43 [==============================] - 1s 29ms/step - loss: 0.3127 - accuracy: 0.8748 - val_loss: 0.4611 - val_accuracy: 0.7924\n",
      "Epoch 4/15\n",
      "43/43 [==============================] - 1s 27ms/step - loss: 0.2132 - accuracy: 0.9242 - val_loss: 0.5156 - val_accuracy: 0.7924\n",
      "Epoch 00004: early stopping\n",
      "16/16 [==============================] - 0s 4ms/step\n",
      "[CV]  num_filters=144, kern_size=3, fully_conected=60, epochs=15, batch_size=88, total=   5.7s\n",
      "[CV] num_filters=144, kern_size=3, fully_conected=60, epochs=15, batch_size=88 \n",
      "Epoch 1/15\n",
      "43/43 [==============================] - 1s 29ms/step - loss: 0.5452 - accuracy: 0.7382 - val_loss: 0.5138 - val_accuracy: 0.7780\n",
      "Epoch 2/15\n",
      "43/43 [==============================] - 1s 26ms/step - loss: 0.3923 - accuracy: 0.8257 - val_loss: 0.5149 - val_accuracy: 0.7566\n",
      "Epoch 00002: early stopping\n",
      "16/16 [==============================] - 0s 4ms/step\n",
      "[CV]  num_filters=144, kern_size=3, fully_conected=60, epochs=15, batch_size=88, total=   3.2s\n",
      "[CV] num_filters=256, kern_size=7, fully_conected=60, epochs=15, batch_size=88 \n",
      "Epoch 1/15\n",
      "43/43 [==============================] - 2s 40ms/step - loss: 0.5374 - accuracy: 0.7278 - val_loss: 0.5012 - val_accuracy: 0.7661\n",
      "Epoch 2/15\n",
      "43/43 [==============================] - 2s 38ms/step - loss: 0.3984 - accuracy: 0.8264 - val_loss: 0.4659 - val_accuracy: 0.7757\n",
      "Epoch 3/15\n",
      "43/43 [==============================] - 2s 39ms/step - loss: 0.2966 - accuracy: 0.8801 - val_loss: 0.4938 - val_accuracy: 0.7852\n",
      "Epoch 00003: early stopping\n",
      "16/16 [==============================] - 0s 9ms/step\n",
      "[CV]  num_filters=256, kern_size=7, fully_conected=60, epochs=15, batch_size=88, total=   6.0s\n",
      "[CV] num_filters=256, kern_size=7, fully_conected=60, epochs=15, batch_size=88 \n",
      "Epoch 1/15\n",
      "43/43 [==============================] - 2s 42ms/step - loss: 0.5400 - accuracy: 0.7291 - val_loss: 0.5068 - val_accuracy: 0.7589\n",
      "Epoch 2/15\n",
      "43/43 [==============================] - 2s 41ms/step - loss: 0.3898 - accuracy: 0.8355 - val_loss: 0.4590 - val_accuracy: 0.7947\n",
      "Epoch 3/15\n",
      "43/43 [==============================] - 2s 41ms/step - loss: 0.2779 - accuracy: 0.8945 - val_loss: 0.5050 - val_accuracy: 0.7876\n",
      "Epoch 00003: early stopping\n",
      "16/16 [==============================] - 0s 8ms/step\n",
      "[CV]  num_filters=256, kern_size=7, fully_conected=60, epochs=15, batch_size=88, total=   6.3s\n",
      "[CV] num_filters=256, kern_size=7, fully_conected=60, epochs=15, batch_size=88 \n",
      "Epoch 1/15\n",
      "43/43 [==============================] - 2s 43ms/step - loss: 0.5483 - accuracy: 0.7217 - val_loss: 0.5444 - val_accuracy: 0.7446\n",
      "Epoch 2/15\n",
      "43/43 [==============================] - 2s 43ms/step - loss: 0.3852 - accuracy: 0.8339 - val_loss: 0.4654 - val_accuracy: 0.7924\n",
      "Epoch 3/15\n",
      "43/43 [==============================] - 2s 43ms/step - loss: 0.2770 - accuracy: 0.8931 - val_loss: 0.4874 - val_accuracy: 0.7900\n",
      "Epoch 00003: early stopping\n",
      "16/16 [==============================] - 0s 9ms/step\n",
      "[CV]  num_filters=256, kern_size=7, fully_conected=60, epochs=15, batch_size=88, total=   6.5s\n",
      "[CV] num_filters=256, kern_size=7, fully_conected=60, epochs=15, batch_size=88 \n",
      "Epoch 1/15\n",
      "43/43 [==============================] - 2s 45ms/step - loss: 0.5244 - accuracy: 0.7366 - val_loss: 0.5083 - val_accuracy: 0.7566\n",
      "Epoch 2/15\n",
      "43/43 [==============================] - 2s 44ms/step - loss: 0.3857 - accuracy: 0.8360 - val_loss: 0.5043 - val_accuracy: 0.7876\n",
      "Epoch 3/15\n",
      "43/43 [==============================] - 2s 45ms/step - loss: 0.2636 - accuracy: 0.8934 - val_loss: 0.5983 - val_accuracy: 0.7375\n",
      "Epoch 00003: early stopping\n",
      "16/16 [==============================] - 0s 11ms/step\n",
      "[CV]  num_filters=256, kern_size=7, fully_conected=60, epochs=15, batch_size=88, total=   6.7s\n",
      "[CV] num_filters=144, kern_size=5, fully_conected=60, epochs=15, batch_size=88 \n",
      "Epoch 1/15\n",
      "43/43 [==============================] - 1s 34ms/step - loss: 0.5478 - accuracy: 0.7137 - val_loss: 0.5156 - val_accuracy: 0.7518\n",
      "Epoch 2/15\n",
      "43/43 [==============================] - 1s 31ms/step - loss: 0.3987 - accuracy: 0.8254 - val_loss: 0.4726 - val_accuracy: 0.7828\n",
      "Epoch 3/15\n",
      "43/43 [==============================] - 1s 32ms/step - loss: 0.3170 - accuracy: 0.8775 - val_loss: 0.4799 - val_accuracy: 0.7709\n",
      "Epoch 00003: early stopping\n",
      "16/16 [==============================] - 0s 6ms/step\n",
      "[CV]  num_filters=144, kern_size=5, fully_conected=60, epochs=15, batch_size=88, total=   5.0s\n",
      "[CV] num_filters=144, kern_size=5, fully_conected=60, epochs=15, batch_size=88 \n",
      "Epoch 1/15\n",
      "43/43 [==============================] - 1s 34ms/step - loss: 0.5692 - accuracy: 0.7007 - val_loss: 0.5231 - val_accuracy: 0.7446\n",
      "Epoch 2/15\n",
      "43/43 [==============================] - 1s 30ms/step - loss: 0.4059 - accuracy: 0.8264 - val_loss: 0.4539 - val_accuracy: 0.7995\n",
      "Epoch 3/15\n",
      "43/43 [==============================] - 1s 32ms/step - loss: 0.3222 - accuracy: 0.8708 - val_loss: 0.4876 - val_accuracy: 0.7757\n",
      "Epoch 00003: early stopping\n",
      "16/16 [==============================] - 0s 5ms/step\n",
      "[CV]  num_filters=144, kern_size=5, fully_conected=60, epochs=15, batch_size=88, total=   5.0s\n",
      "[CV] num_filters=144, kern_size=5, fully_conected=60, epochs=15, batch_size=88 \n",
      "Epoch 1/15\n",
      "43/43 [==============================] - 1s 33ms/step - loss: 0.5296 - accuracy: 0.7392 - val_loss: 0.4910 - val_accuracy: 0.7804\n",
      "Epoch 2/15\n",
      "43/43 [==============================] - 1s 32ms/step - loss: 0.3838 - accuracy: 0.8331 - val_loss: 0.4904 - val_accuracy: 0.7804\n",
      "Epoch 3/15\n",
      "43/43 [==============================] - 1s 32ms/step - loss: 0.2774 - accuracy: 0.8889 - val_loss: 0.5307 - val_accuracy: 0.7900\n",
      "Epoch 00003: early stopping\n",
      "16/16 [==============================] - 0s 5ms/step\n",
      "[CV]  num_filters=144, kern_size=5, fully_conected=60, epochs=15, batch_size=88, total=   5.0s\n",
      "[CV] num_filters=144, kern_size=5, fully_conected=60, epochs=15, batch_size=88 \n",
      "Epoch 1/15\n",
      "43/43 [==============================] - 2s 40ms/step - loss: 0.5563 - accuracy: 0.7109 - val_loss: 0.5161 - val_accuracy: 0.7518\n",
      "Epoch 2/15\n",
      "43/43 [==============================] - 1s 33ms/step - loss: 0.3890 - accuracy: 0.8342 - val_loss: 0.5103 - val_accuracy: 0.7876\n",
      "Epoch 3/15\n",
      "43/43 [==============================] - 2s 35ms/step - loss: 0.2986 - accuracy: 0.8791 - val_loss: 0.5548 - val_accuracy: 0.7542\n",
      "Epoch 00003: early stopping\n",
      "16/16 [==============================] - 0s 4ms/step\n",
      "[CV]  num_filters=144, kern_size=5, fully_conected=60, epochs=15, batch_size=88, total=   6.3s\n",
      "[CV] num_filters=256, kern_size=7, fully_conected=60, epochs=15, batch_size=76 \n",
      "Epoch 1/15\n",
      "50/50 [==============================] - 2s 42ms/step - loss: 0.5366 - accuracy: 0.7430 - val_loss: 0.5000 - val_accuracy: 0.7637\n",
      "Epoch 2/15\n",
      "50/50 [==============================] - 2s 40ms/step - loss: 0.4004 - accuracy: 0.8251 - val_loss: 0.4671 - val_accuracy: 0.7685\n",
      "Epoch 3/15\n",
      "50/50 [==============================] - 2s 40ms/step - loss: 0.3020 - accuracy: 0.8780 - val_loss: 0.4727 - val_accuracy: 0.7780\n",
      "Epoch 00003: early stopping\n",
      "19/19 [==============================] - 0s 7ms/step\n",
      "[CV]  num_filters=256, kern_size=7, fully_conected=60, epochs=15, batch_size=76, total=   7.1s\n",
      "[CV] num_filters=256, kern_size=7, fully_conected=60, epochs=15, batch_size=76 \n",
      "Epoch 1/15\n",
      "50/50 [==============================] - 2s 41ms/step - loss: 0.5332 - accuracy: 0.7363 - val_loss: 0.4817 - val_accuracy: 0.7804\n",
      "Epoch 2/15\n",
      "50/50 [==============================] - 2s 40ms/step - loss: 0.3841 - accuracy: 0.8392 - val_loss: 0.4505 - val_accuracy: 0.8091\n",
      "Epoch 3/15\n",
      "50/50 [==============================] - 2s 39ms/step - loss: 0.2698 - accuracy: 0.8945 - val_loss: 0.4940 - val_accuracy: 0.7804\n",
      "Epoch 00003: early stopping\n",
      "19/19 [==============================] - 0s 8ms/step\n",
      "[CV]  num_filters=256, kern_size=7, fully_conected=60, epochs=15, batch_size=76, total=   7.0s\n",
      "[CV] num_filters=256, kern_size=7, fully_conected=60, epochs=15, batch_size=76 \n",
      "Epoch 1/15\n",
      "50/50 [==============================] - 2s 40ms/step - loss: 0.5292 - accuracy: 0.7334 - val_loss: 0.4786 - val_accuracy: 0.7709\n",
      "Epoch 2/15\n",
      "50/50 [==============================] - 2s 38ms/step - loss: 0.3746 - accuracy: 0.8389 - val_loss: 0.4527 - val_accuracy: 0.7780\n",
      "Epoch 3/15\n",
      "50/50 [==============================] - 2s 39ms/step - loss: 0.2562 - accuracy: 0.9038 - val_loss: 0.5109 - val_accuracy: 0.7828\n",
      "Epoch 00003: early stopping\n",
      "19/19 [==============================] - 0s 7ms/step\n",
      "[CV]  num_filters=256, kern_size=7, fully_conected=60, epochs=15, batch_size=76, total=   6.8s\n",
      "[CV] num_filters=256, kern_size=7, fully_conected=60, epochs=15, batch_size=76 \n",
      "Epoch 1/15\n",
      "50/50 [==============================] - 2s 42ms/step - loss: 0.5214 - accuracy: 0.7385 - val_loss: 0.5681 - val_accuracy: 0.7255\n",
      "Epoch 2/15\n",
      "50/50 [==============================] - 2s 38ms/step - loss: 0.3854 - accuracy: 0.8326 - val_loss: 0.5212 - val_accuracy: 0.7709\n",
      "Epoch 3/15\n",
      "50/50 [==============================] - 2s 40ms/step - loss: 0.2749 - accuracy: 0.8889 - val_loss: 0.5625 - val_accuracy: 0.7685\n",
      "Epoch 00003: early stopping\n",
      "19/19 [==============================] - 0s 6ms/step\n",
      "[CV]  num_filters=256, kern_size=7, fully_conected=60, epochs=15, batch_size=76, total=   6.9s\n",
      "[CV] num_filters=144, kern_size=7, fully_conected=60, epochs=15, batch_size=76 \n",
      "Epoch 1/15\n",
      "50/50 [==============================] - 2s 32ms/step - loss: 0.5560 - accuracy: 0.7169 - val_loss: 0.5094 - val_accuracy: 0.7422\n",
      "Epoch 2/15\n",
      "50/50 [==============================] - 2s 31ms/step - loss: 0.3984 - accuracy: 0.8267 - val_loss: 0.5084 - val_accuracy: 0.7566\n",
      "Epoch 3/15\n",
      "50/50 [==============================] - 2s 31ms/step - loss: 0.3029 - accuracy: 0.8785 - val_loss: 0.4831 - val_accuracy: 0.7685\n",
      "Epoch 4/15\n",
      "50/50 [==============================] - 2s 31ms/step - loss: 0.1902 - accuracy: 0.9320 - val_loss: 0.5570 - val_accuracy: 0.7613\n",
      "Epoch 00004: early stopping\n",
      "19/19 [==============================] - 0s 5ms/step\n",
      "[CV]  num_filters=144, kern_size=7, fully_conected=60, epochs=15, batch_size=76, total=   7.2s\n",
      "[CV] num_filters=144, kern_size=7, fully_conected=60, epochs=15, batch_size=76 \n",
      "Epoch 1/15\n",
      "50/50 [==============================] - 2s 32ms/step - loss: 0.6260 - accuracy: 0.6616 - val_loss: 0.5217 - val_accuracy: 0.7494\n",
      "Epoch 2/15\n",
      "50/50 [==============================] - 2s 30ms/step - loss: 0.4296 - accuracy: 0.8107 - val_loss: 0.4577 - val_accuracy: 0.7900\n",
      "Epoch 3/15\n",
      "50/50 [==============================] - 2s 31ms/step - loss: 0.3242 - accuracy: 0.8735 - val_loss: 0.4479 - val_accuracy: 0.7971\n",
      "Epoch 4/15\n",
      "50/50 [==============================] - 2s 32ms/step - loss: 0.2197 - accuracy: 0.9205 - val_loss: 0.5027 - val_accuracy: 0.7876\n",
      "Epoch 00004: early stopping\n",
      "19/19 [==============================] - 0s 4ms/step\n",
      "[CV]  num_filters=144, kern_size=7, fully_conected=60, epochs=15, batch_size=76, total=   7.2s\n",
      "[CV] num_filters=144, kern_size=7, fully_conected=60, epochs=15, batch_size=76 \n",
      "Epoch 1/15\n",
      "50/50 [==============================] - 2s 31ms/step - loss: 0.5467 - accuracy: 0.7153 - val_loss: 0.4919 - val_accuracy: 0.7804\n",
      "Epoch 2/15\n",
      "50/50 [==============================] - 2s 31ms/step - loss: 0.3766 - accuracy: 0.8405 - val_loss: 0.4942 - val_accuracy: 0.7804\n",
      "Epoch 00002: early stopping\n",
      "19/19 [==============================] - 0s 4ms/step\n",
      "[CV]  num_filters=144, kern_size=7, fully_conected=60, epochs=15, batch_size=76, total=   4.0s\n",
      "[CV] num_filters=144, kern_size=7, fully_conected=60, epochs=15, batch_size=76 \n",
      "Epoch 1/15\n",
      "50/50 [==============================] - 2s 32ms/step - loss: 0.5256 - accuracy: 0.7430 - val_loss: 0.5036 - val_accuracy: 0.7637\n",
      "Epoch 2/15\n",
      "50/50 [==============================] - 2s 31ms/step - loss: 0.3915 - accuracy: 0.8254 - val_loss: 0.5252 - val_accuracy: 0.7542\n",
      "Epoch 00002: early stopping\n",
      "19/19 [==============================] - 0s 5ms/step\n",
      "[CV]  num_filters=144, kern_size=7, fully_conected=60, epochs=15, batch_size=76, total=   4.0s\n",
      "Epoch 1/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  20 out of  20 | elapsed:  1.9min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "58/58 [==============================] - 2s 31ms/step - loss: 0.5197 - accuracy: 0.7530 - val_loss: 0.5530 - val_accuracy: 0.7437\n",
      "Epoch 2/15\n",
      "58/58 [==============================] - 2s 29ms/step - loss: 0.3949 - accuracy: 0.8286 - val_loss: 0.4497 - val_accuracy: 0.7993\n",
      "Epoch 3/15\n",
      "58/58 [==============================] - 2s 30ms/step - loss: 0.3016 - accuracy: 0.8780 - val_loss: 0.4524 - val_accuracy: 0.8047\n",
      "Epoch 00003: early stopping\n",
      "22/22 [==============================] - 0s 4ms/step\n",
      "Best Accuracy : 0.8052\n",
      "{'num_filters': 144, 'kern_size': 3, 'fully_conected': 60, 'epochs': 15, 'batch_size': 88}\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "param_grid = dict(num_filters=[144, 256],\n",
    "                      kern_size=[3, 5, 7],\n",
    "                      batch_size = [76,88],\n",
    "                      fully_conected = [60, 800], epochs = [15])\n",
    "\n",
    "model = KerasClassifier(build_fn=build_model, epochs=15, validation_split=0.1,verbose=1)\n",
    "\n",
    "grid = RandomizedSearchCV(estimator=model, param_distributions=param_grid,\n",
    "                              cv=4, verbose=2, n_iter=5, n_jobs=1,scoring = 'accuracy')\n",
    "\n",
    "grid_result = grid.fit(x_train, y_train, callbacks=[callback])\n",
    "\n",
    "\n",
    "test_accuracy = grid.score(x_test, y_test)\n",
    "\n",
    "# Save and evaluate results\n",
    "s = ('Best Accuracy : {:.4f}\\n{}\\n\\n\\n')\n",
    "output_string = s.format(\n",
    "            grid_result.best_score_,\n",
    "            grid_result.best_params_)\n",
    "            \n",
    "print(output_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "submit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding, Flatten, Dense\n",
    "from keras import layers\n",
    "\n",
    "from keras.callbacks import EarlyStopping\n",
    "callback = EarlyStopping(monitor = 'val_loss', patience = 1, verbose=1)\n",
    "callbacks = [callback]\n",
    "\n",
    "def build_model(fully_conected, num_filters, kern_size):\n",
    "    model1 = Sequential()\n",
    "    e = Embedding(vocab_size, 100, weights=[embedding_matrix], input_length=31, trainable=True)\n",
    "    model1.add(e)\n",
    "    model1.add(layers.Conv1D(num_filters, kern_size, activation='relu'))\n",
    "    model1.add(Flatten())\n",
    "    model1.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    model1.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    return model1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 folds for each of 5 candidates, totalling 20 fits\n",
      "[CV] num_filters=256, kern_size=3, fully_conected=16, epochs=15, batch_size=76 \n",
      "Epoch 1/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50/50 [==============================] - 2s 38ms/step - loss: 0.5504 - accuracy: 0.7153 - val_loss: 0.5115 - val_accuracy: 0.7661\n",
      "Epoch 2/15\n",
      "50/50 [==============================] - 1s 19ms/step - loss: 0.3740 - accuracy: 0.8379 - val_loss: 0.5020 - val_accuracy: 0.7709\n",
      "Epoch 3/15\n",
      "50/50 [==============================] - 1s 19ms/step - loss: 0.2845 - accuracy: 0.8910 - val_loss: 0.4827 - val_accuracy: 0.7661\n",
      "Epoch 4/15\n",
      "50/50 [==============================] - 1s 18ms/step - loss: 0.1999 - accuracy: 0.9296 - val_loss: 0.5392 - val_accuracy: 0.7757\n",
      "Epoch 00004: early stopping\n",
      "19/19 [==============================] - 0s 3ms/step\n",
      "[CV]  num_filters=256, kern_size=3, fully_conected=16, epochs=15, batch_size=76, total=   5.4s\n",
      "[CV] num_filters=256, kern_size=3, fully_conected=16, epochs=15, batch_size=76 \n",
      "Epoch 1/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    5.4s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50/50 [==============================] - 1s 20ms/step - loss: 0.5394 - accuracy: 0.7299 - val_loss: 0.5007 - val_accuracy: 0.7613\n",
      "Epoch 2/15\n",
      "50/50 [==============================] - 1s 19ms/step - loss: 0.3678 - accuracy: 0.8458 - val_loss: 0.4799 - val_accuracy: 0.7828\n",
      "Epoch 3/15\n",
      "50/50 [==============================] - 1s 18ms/step - loss: 0.2846 - accuracy: 0.8881 - val_loss: 0.4757 - val_accuracy: 0.7947\n",
      "Epoch 4/15\n",
      "50/50 [==============================] - 1s 18ms/step - loss: 0.1982 - accuracy: 0.9296 - val_loss: 0.4925 - val_accuracy: 0.7900\n",
      "Epoch 00004: early stopping\n",
      "19/19 [==============================] - 0s 3ms/step\n",
      "[CV]  num_filters=256, kern_size=3, fully_conected=16, epochs=15, batch_size=76, total=   4.5s\n",
      "[CV] num_filters=256, kern_size=3, fully_conected=16, epochs=15, batch_size=76 \n",
      "Epoch 1/15\n",
      "50/50 [==============================] - 1s 20ms/step - loss: 0.5325 - accuracy: 0.7323 - val_loss: 0.5122 - val_accuracy: 0.7566\n",
      "Epoch 2/15\n",
      "50/50 [==============================] - 1s 19ms/step - loss: 0.3605 - accuracy: 0.8461 - val_loss: 0.5154 - val_accuracy: 0.7709\n",
      "Epoch 00002: early stopping\n",
      "19/19 [==============================] - 0s 3ms/step\n",
      "[CV]  num_filters=256, kern_size=3, fully_conected=16, epochs=15, batch_size=76, total=   2.7s\n",
      "[CV] num_filters=256, kern_size=3, fully_conected=16, epochs=15, batch_size=76 \n",
      "Epoch 1/15\n",
      "50/50 [==============================] - 1s 20ms/step - loss: 0.5349 - accuracy: 0.7321 - val_loss: 0.4924 - val_accuracy: 0.7685\n",
      "Epoch 2/15\n",
      "50/50 [==============================] - 1s 19ms/step - loss: 0.3704 - accuracy: 0.8379 - val_loss: 0.5004 - val_accuracy: 0.7685\n",
      "Epoch 00002: early stopping\n",
      "19/19 [==============================] - 0s 3ms/step\n",
      "[CV]  num_filters=256, kern_size=3, fully_conected=16, epochs=15, batch_size=76, total=   2.7s\n",
      "[CV] num_filters=256, kern_size=7, fully_conected=60, epochs=15, batch_size=88 \n",
      "Epoch 1/15\n",
      "43/43 [==============================] - 1s 26ms/step - loss: 0.5387 - accuracy: 0.7275 - val_loss: 0.5100 - val_accuracy: 0.7470\n",
      "Epoch 2/15\n",
      "43/43 [==============================] - 1s 25ms/step - loss: 0.3575 - accuracy: 0.8503 - val_loss: 0.4904 - val_accuracy: 0.7613\n",
      "Epoch 3/15\n",
      "43/43 [==============================] - 1s 26ms/step - loss: 0.2486 - accuracy: 0.9072 - val_loss: 0.5183 - val_accuracy: 0.7446\n",
      "Epoch 00003: early stopping\n",
      "16/16 [==============================] - 0s 5ms/step\n",
      "[CV]  num_filters=256, kern_size=7, fully_conected=60, epochs=15, batch_size=88, total=   4.1s\n",
      "[CV] num_filters=256, kern_size=7, fully_conected=60, epochs=15, batch_size=88 \n",
      "Epoch 1/15\n",
      "43/43 [==============================] - 1s 27ms/step - loss: 0.5222 - accuracy: 0.7547 - val_loss: 0.5067 - val_accuracy: 0.7589\n",
      "Epoch 2/15\n",
      "43/43 [==============================] - 1s 26ms/step - loss: 0.3469 - accuracy: 0.8573 - val_loss: 0.5040 - val_accuracy: 0.7780\n",
      "Epoch 3/15\n",
      "43/43 [==============================] - 1s 27ms/step - loss: 0.2358 - accuracy: 0.9181 - val_loss: 0.5105 - val_accuracy: 0.7685\n",
      "Epoch 00003: early stopping\n",
      "16/16 [==============================] - 0s 5ms/step\n",
      "[CV]  num_filters=256, kern_size=7, fully_conected=60, epochs=15, batch_size=88, total=   4.2s\n",
      "[CV] num_filters=256, kern_size=7, fully_conected=60, epochs=15, batch_size=88 \n",
      "Epoch 1/15\n",
      "43/43 [==============================] - 1s 27ms/step - loss: 0.5270 - accuracy: 0.7475 - val_loss: 0.4861 - val_accuracy: 0.7757\n",
      "Epoch 2/15\n",
      "43/43 [==============================] - 1s 29ms/step - loss: 0.3507 - accuracy: 0.8482 - val_loss: 0.4963 - val_accuracy: 0.7947\n",
      "Epoch 00002: early stopping\n",
      "16/16 [==============================] - 0s 5ms/step\n",
      "[CV]  num_filters=256, kern_size=7, fully_conected=60, epochs=15, batch_size=88, total=   3.1s\n",
      "[CV] num_filters=256, kern_size=7, fully_conected=60, epochs=15, batch_size=88 \n",
      "Epoch 1/15\n",
      "43/43 [==============================] - 1s 28ms/step - loss: 0.5328 - accuracy: 0.7297 - val_loss: 0.5321 - val_accuracy: 0.7470\n",
      "Epoch 2/15\n",
      "43/43 [==============================] - 1s 27ms/step - loss: 0.3442 - accuracy: 0.8562 - val_loss: 0.5262 - val_accuracy: 0.7876\n",
      "Epoch 3/15\n",
      "43/43 [==============================] - 1s 28ms/step - loss: 0.2343 - accuracy: 0.9152 - val_loss: 0.6192 - val_accuracy: 0.7685\n",
      "Epoch 00003: early stopping\n",
      "16/16 [==============================] - 0s 6ms/step\n",
      "[CV]  num_filters=256, kern_size=7, fully_conected=60, epochs=15, batch_size=88, total=   4.3s\n",
      "[CV] num_filters=128, kern_size=5, fully_conected=16, epochs=15, batch_size=76 \n",
      "Epoch 1/15\n",
      "50/50 [==============================] - 1s 20ms/step - loss: 0.5467 - accuracy: 0.7251 - val_loss: 0.5158 - val_accuracy: 0.7422\n",
      "Epoch 2/15\n",
      "50/50 [==============================] - 1s 20ms/step - loss: 0.3767 - accuracy: 0.8360 - val_loss: 0.5000 - val_accuracy: 0.7757\n",
      "Epoch 3/15\n",
      "50/50 [==============================] - 1s 20ms/step - loss: 0.2921 - accuracy: 0.8799 - val_loss: 0.5032 - val_accuracy: 0.7804\n",
      "Epoch 00003: early stopping\n",
      "19/19 [==============================] - 0s 3ms/step\n",
      "[CV]  num_filters=128, kern_size=5, fully_conected=16, epochs=15, batch_size=76, total=   3.7s\n",
      "[CV] num_filters=128, kern_size=5, fully_conected=16, epochs=15, batch_size=76 \n",
      "Epoch 1/15\n",
      "50/50 [==============================] - 1s 22ms/step - loss: 0.5379 - accuracy: 0.7331 - val_loss: 0.5016 - val_accuracy: 0.7446\n",
      "Epoch 2/15\n",
      "50/50 [==============================] - 1s 21ms/step - loss: 0.3740 - accuracy: 0.8402 - val_loss: 0.4698 - val_accuracy: 0.7709\n",
      "Epoch 3/15\n",
      "50/50 [==============================] - 1s 26ms/step - loss: 0.2792 - accuracy: 0.8926 - val_loss: 0.4913 - val_accuracy: 0.7804\n",
      "Epoch 00003: early stopping\n",
      "19/19 [==============================] - 0s 3ms/step\n",
      "[CV]  num_filters=128, kern_size=5, fully_conected=16, epochs=15, batch_size=76, total=   4.1s\n",
      "[CV] num_filters=128, kern_size=5, fully_conected=16, epochs=15, batch_size=76 \n",
      "Epoch 1/15\n",
      "50/50 [==============================] - 1s 21ms/step - loss: 0.5345 - accuracy: 0.7400 - val_loss: 0.5205 - val_accuracy: 0.7637\n",
      "Epoch 2/15\n",
      "50/50 [==============================] - 1s 20ms/step - loss: 0.3597 - accuracy: 0.8485 - val_loss: 0.4917 - val_accuracy: 0.7613\n",
      "Epoch 3/15\n",
      "50/50 [==============================] - 1s 20ms/step - loss: 0.2741 - accuracy: 0.8907 - val_loss: 0.4966 - val_accuracy: 0.7852\n",
      "Epoch 00003: early stopping\n",
      "19/19 [==============================] - 0s 2ms/step\n",
      "[CV]  num_filters=128, kern_size=5, fully_conected=16, epochs=15, batch_size=76, total=   3.7s\n",
      "[CV] num_filters=128, kern_size=5, fully_conected=16, epochs=15, batch_size=76 \n",
      "Epoch 1/15\n",
      "50/50 [==============================] - 1s 22ms/step - loss: 0.5275 - accuracy: 0.7499 - val_loss: 0.5085 - val_accuracy: 0.7709\n",
      "Epoch 2/15\n",
      "50/50 [==============================] - 1s 20ms/step - loss: 0.3643 - accuracy: 0.8395 - val_loss: 0.5303 - val_accuracy: 0.7685\n",
      "Epoch 00002: early stopping\n",
      "19/19 [==============================] - 0s 3ms/step\n",
      "[CV]  num_filters=128, kern_size=5, fully_conected=16, epochs=15, batch_size=76, total=   2.8s\n",
      "[CV] num_filters=256, kern_size=3, fully_conected=60, epochs=15, batch_size=88 \n",
      "Epoch 1/15\n",
      "43/43 [==============================] - 1s 24ms/step - loss: 0.5485 - accuracy: 0.7246 - val_loss: 0.5189 - val_accuracy: 0.7422\n",
      "Epoch 2/15\n",
      "43/43 [==============================] - 1s 24ms/step - loss: 0.3776 - accuracy: 0.8357 - val_loss: 0.4902 - val_accuracy: 0.7613\n",
      "Epoch 3/15\n",
      "43/43 [==============================] - 1s 26ms/step - loss: 0.2949 - accuracy: 0.8814 - val_loss: 0.5065 - val_accuracy: 0.7685\n",
      "Epoch 00003: early stopping\n",
      "16/16 [==============================] - 0s 3ms/step\n",
      "[CV]  num_filters=256, kern_size=3, fully_conected=60, epochs=15, batch_size=88, total=   3.9s\n",
      "[CV] num_filters=256, kern_size=3, fully_conected=60, epochs=15, batch_size=88 \n",
      "Epoch 1/15\n",
      "43/43 [==============================] - 1s 25ms/step - loss: 0.5384 - accuracy: 0.7294 - val_loss: 0.5158 - val_accuracy: 0.7637\n",
      "Epoch 2/15\n",
      "43/43 [==============================] - 1s 23ms/step - loss: 0.3697 - accuracy: 0.8432 - val_loss: 0.4888 - val_accuracy: 0.7685\n",
      "Epoch 3/15\n",
      "43/43 [==============================] - 1s 24ms/step - loss: 0.2790 - accuracy: 0.8913 - val_loss: 0.4781 - val_accuracy: 0.7828\n",
      "Epoch 4/15\n",
      "43/43 [==============================] - 1s 25ms/step - loss: 0.2003 - accuracy: 0.9333 - val_loss: 0.5076 - val_accuracy: 0.7876\n",
      "Epoch 00004: early stopping\n",
      "16/16 [==============================] - 0s 3ms/step\n",
      "[CV]  num_filters=256, kern_size=3, fully_conected=60, epochs=15, batch_size=88, total=   4.9s\n",
      "[CV] num_filters=256, kern_size=3, fully_conected=60, epochs=15, batch_size=88 \n",
      "Epoch 1/15\n",
      "43/43 [==============================] - 1s 24ms/step - loss: 0.5506 - accuracy: 0.7217 - val_loss: 0.5116 - val_accuracy: 0.7828\n",
      "Epoch 2/15\n",
      "43/43 [==============================] - 1s 22ms/step - loss: 0.3739 - accuracy: 0.8448 - val_loss: 0.4989 - val_accuracy: 0.7828\n",
      "Epoch 3/15\n",
      "43/43 [==============================] - 1s 22ms/step - loss: 0.2827 - accuracy: 0.8873 - val_loss: 0.4705 - val_accuracy: 0.7924\n",
      "Epoch 4/15\n",
      "43/43 [==============================] - 1s 23ms/step - loss: 0.2040 - accuracy: 0.9285 - val_loss: 0.5013 - val_accuracy: 0.7804\n",
      "Epoch 00004: early stopping\n",
      "16/16 [==============================] - 0s 3ms/step\n",
      "[CV]  num_filters=256, kern_size=3, fully_conected=60, epochs=15, batch_size=88, total=   4.6s\n",
      "[CV] num_filters=256, kern_size=3, fully_conected=60, epochs=15, batch_size=88 \n",
      "Epoch 1/15\n",
      "43/43 [==============================] - 1s 24ms/step - loss: 0.5648 - accuracy: 0.7093 - val_loss: 0.5070 - val_accuracy: 0.7589\n",
      "Epoch 2/15\n",
      "43/43 [==============================] - 1s 23ms/step - loss: 0.3838 - accuracy: 0.8323 - val_loss: 0.4992 - val_accuracy: 0.7804\n",
      "Epoch 3/15\n",
      "43/43 [==============================] - 1s 23ms/step - loss: 0.2950 - accuracy: 0.8807 - val_loss: 0.5277 - val_accuracy: 0.7828\n",
      "Epoch 00003: early stopping\n",
      "16/16 [==============================] - 0s 4ms/step\n",
      "[CV]  num_filters=256, kern_size=3, fully_conected=60, epochs=15, batch_size=88, total=   3.7s\n",
      "[CV] num_filters=128, kern_size=7, fully_conected=16, epochs=15, batch_size=88 \n",
      "Epoch 1/15\n",
      "43/43 [==============================] - 1s 27ms/step - loss: 0.5490 - accuracy: 0.7246 - val_loss: 0.5278 - val_accuracy: 0.7661\n",
      "Epoch 2/15\n",
      "43/43 [==============================] - 1s 25ms/step - loss: 0.3715 - accuracy: 0.8440 - val_loss: 0.5141 - val_accuracy: 0.7613\n",
      "Epoch 3/15\n",
      "43/43 [==============================] - 1s 22ms/step - loss: 0.2826 - accuracy: 0.8934 - val_loss: 0.4996 - val_accuracy: 0.7661\n",
      "Epoch 4/15\n",
      "43/43 [==============================] - 1s 24ms/step - loss: 0.1985 - accuracy: 0.9343 - val_loss: 0.5235 - val_accuracy: 0.7637\n",
      "Epoch 00004: early stopping\n",
      "16/16 [==============================] - 0s 3ms/step\n",
      "[CV]  num_filters=128, kern_size=7, fully_conected=16, epochs=15, batch_size=88, total=   5.0s\n",
      "[CV] num_filters=128, kern_size=7, fully_conected=16, epochs=15, batch_size=88 \n",
      "Epoch 1/15\n",
      "43/43 [==============================] - 1s 29ms/step - loss: 0.5691 - accuracy: 0.7002 - val_loss: 0.5358 - val_accuracy: 0.7351\n",
      "Epoch 2/15\n",
      "43/43 [==============================] - 1s 22ms/step - loss: 0.3756 - accuracy: 0.8389 - val_loss: 0.4935 - val_accuracy: 0.7733\n",
      "Epoch 3/15\n",
      "43/43 [==============================] - 1s 26ms/step - loss: 0.2812 - accuracy: 0.8910 - val_loss: 0.4957 - val_accuracy: 0.7709\n",
      "Epoch 00003: early stopping\n",
      "16/16 [==============================] - 0s 4ms/step\n",
      "[CV]  num_filters=128, kern_size=7, fully_conected=16, epochs=15, batch_size=88, total=   4.1s\n",
      "[CV] num_filters=128, kern_size=7, fully_conected=16, epochs=15, batch_size=88 \n",
      "Epoch 1/15\n",
      "43/43 [==============================] - 1s 23ms/step - loss: 0.5343 - accuracy: 0.7355 - val_loss: 0.5229 - val_accuracy: 0.7542\n",
      "Epoch 2/15\n",
      "43/43 [==============================] - 1s 22ms/step - loss: 0.3612 - accuracy: 0.8442 - val_loss: 0.5583 - val_accuracy: 0.7470\n",
      "Epoch 00002: early stopping\n",
      "16/16 [==============================] - 0s 4ms/step\n",
      "[CV]  num_filters=128, kern_size=7, fully_conected=16, epochs=15, batch_size=88, total=   2.6s\n",
      "[CV] num_filters=128, kern_size=7, fully_conected=16, epochs=15, batch_size=88 \n",
      "Epoch 1/15\n",
      "43/43 [==============================] - 1s 24ms/step - loss: 0.5407 - accuracy: 0.7263 - val_loss: 0.5121 - val_accuracy: 0.7709\n",
      "Epoch 2/15\n",
      "43/43 [==============================] - 1s 22ms/step - loss: 0.3663 - accuracy: 0.8432 - val_loss: 0.5080 - val_accuracy: 0.7876\n",
      "Epoch 3/15\n",
      "43/43 [==============================] - 1s 23ms/step - loss: 0.2642 - accuracy: 0.8980 - val_loss: 0.5549 - val_accuracy: 0.7780\n",
      "Epoch 00003: early stopping\n",
      "16/16 [==============================] - 0s 4ms/step\n",
      "[CV]  num_filters=128, kern_size=7, fully_conected=16, epochs=15, batch_size=88, total=   3.7s\n",
      "Epoch 1/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  20 out of  20 | elapsed:  1.3min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "58/58 [==============================] - 1s 24ms/step - loss: 0.5176 - accuracy: 0.7459 - val_loss: 0.4745 - val_accuracy: 0.7939\n",
      "Epoch 2/15\n",
      "58/58 [==============================] - 1s 22ms/step - loss: 0.3697 - accuracy: 0.8399 - val_loss: 0.4713 - val_accuracy: 0.7957\n",
      "Epoch 3/15\n",
      "58/58 [==============================] - 1s 25ms/step - loss: 0.2749 - accuracy: 0.8902 - val_loss: 0.4740 - val_accuracy: 0.7975\n",
      "Epoch 00003: early stopping\n",
      "22/22 [==============================] - 0s 3ms/step\n",
      "Best Accuracy : 0.8031\n",
      "{'num_filters': 256, 'kern_size': 3, 'fully_conected': 60, 'epochs': 15, 'batch_size': 88}\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "param_grid = dict(num_filters=[128, 256],\n",
    "                      kern_size=[3, 5, 7],\n",
    "                      batch_size = [76,88],\n",
    "                      fully_conected = [16, 60], epochs = [15])\n",
    "\n",
    "model = KerasClassifier(build_fn=build_model, epochs=15, validation_split=0.1,verbose=1)\n",
    "\n",
    "grid = RandomizedSearchCV(estimator=model, param_distributions=param_grid,\n",
    "                              cv=4, verbose=2, n_iter=5, n_jobs=1,scoring = 'accuracy')\n",
    "\n",
    "grid_result = grid.fit(x_train, y_train, callbacks=[callback])\n",
    "\n",
    "\n",
    "test_accuracy = grid.score(x_test, y_test)\n",
    "\n",
    "# Save and evaluate results\n",
    "s = ('Best Accuracy : {:.4f}\\n{}\\n\\n\\n')\n",
    "output_string = s.format(\n",
    "            grid_result.best_score_,\n",
    "            grid_result.best_params_)\n",
    "            \n",
    "print(output_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding, Flatten, Dense\n",
    "from keras import layers\n",
    "from keras import activations\n",
    "\n",
    "from keras.callbacks import EarlyStopping\n",
    "callback = EarlyStopping(monitor = 'val_loss', patience = 1, verbose=1)\n",
    "callbacks = [callback]\n",
    "\n",
    "def build_model(fully_conected, num_filters, kern_size):\n",
    "    model1 = Sequential()\n",
    "    e = Embedding(vocab_size, 100, weights=[embedding_matrix], input_length=31, trainable=True)\n",
    "    model1.add(e)\n",
    "    model1.add(layers.Conv1D(num_filters, kern_size, activation='relu'))\n",
    "    model1.add(layers.Activation(activations.relu))\n",
    "    model1.add(Flatten())\n",
    "    model1.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    model1.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    return model1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 5 candidates, totalling 50 fits\n",
      "[CV] num_filters=256, kern_size=5, fully_conected=16, epochs=15, batch_size=88 \n",
      "Epoch 1/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52/52 [==============================] - 1s 26ms/step - loss: 0.5156 - accuracy: 0.7513 - val_loss: 0.4814 - val_accuracy: 0.7769\n",
      "Epoch 2/15\n",
      "52/52 [==============================] - 1s 23ms/step - loss: 0.3523 - accuracy: 0.8523 - val_loss: 0.4989 - val_accuracy: 0.7829\n",
      "Epoch 00002: early stopping\n",
      "7/7 [==============================] - 0s 4ms/step\n",
      "[CV]  num_filters=256, kern_size=5, fully_conected=16, epochs=15, batch_size=88, total=   4.2s\n",
      "[CV] num_filters=256, kern_size=5, fully_conected=16, epochs=15, batch_size=88 \n",
      "Epoch 1/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    4.2s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52/52 [==============================] - 1s 24ms/step - loss: 0.5135 - accuracy: 0.7473 - val_loss: 0.4839 - val_accuracy: 0.7470\n",
      "Epoch 2/15\n",
      "52/52 [==============================] - 1s 24ms/step - loss: 0.3518 - accuracy: 0.8487 - val_loss: 0.4918 - val_accuracy: 0.7789\n",
      "Epoch 00002: early stopping\n",
      "7/7 [==============================] - 0s 4ms/step\n",
      "[CV]  num_filters=256, kern_size=5, fully_conected=16, epochs=15, batch_size=88, total=   3.2s\n",
      "[CV] num_filters=256, kern_size=5, fully_conected=16, epochs=15, batch_size=88 \n",
      "Epoch 1/15\n",
      "52/52 [==============================] - 1s 25ms/step - loss: 0.5273 - accuracy: 0.7415 - val_loss: 0.4999 - val_accuracy: 0.7530\n",
      "Epoch 2/15\n",
      "52/52 [==============================] - 1s 23ms/step - loss: 0.3563 - accuracy: 0.8470 - val_loss: 0.4809 - val_accuracy: 0.7809\n",
      "Epoch 3/15\n",
      "52/52 [==============================] - 1s 23ms/step - loss: 0.2522 - accuracy: 0.9032 - val_loss: 0.4997 - val_accuracy: 0.7948\n",
      "Epoch 00003: early stopping\n",
      "7/7 [==============================] - 0s 5ms/step\n",
      "[CV]  num_filters=256, kern_size=5, fully_conected=16, epochs=15, batch_size=88, total=   4.4s\n",
      "[CV] num_filters=256, kern_size=5, fully_conected=16, epochs=15, batch_size=88 \n",
      "Epoch 1/15\n",
      "52/52 [==============================] - 1s 25ms/step - loss: 0.5183 - accuracy: 0.7433 - val_loss: 0.4847 - val_accuracy: 0.7649\n",
      "Epoch 2/15\n",
      "52/52 [==============================] - 1s 24ms/step - loss: 0.3521 - accuracy: 0.8518 - val_loss: 0.5074 - val_accuracy: 0.7709\n",
      "Epoch 00002: early stopping\n",
      "7/7 [==============================] - 0s 5ms/step\n",
      "[CV]  num_filters=256, kern_size=5, fully_conected=16, epochs=15, batch_size=88, total=   3.2s\n",
      "[CV] num_filters=256, kern_size=5, fully_conected=16, epochs=15, batch_size=88 \n",
      "Epoch 1/15\n",
      "52/52 [==============================] - 1s 29ms/step - loss: 0.5223 - accuracy: 0.7446 - val_loss: 0.5029 - val_accuracy: 0.7729\n",
      "Epoch 2/15\n",
      "52/52 [==============================] - 1s 28ms/step - loss: 0.3524 - accuracy: 0.8507 - val_loss: 0.4917 - val_accuracy: 0.7809\n",
      "Epoch 3/15\n",
      "52/52 [==============================] - 2s 34ms/step - loss: 0.2566 - accuracy: 0.9008 - val_loss: 0.5083 - val_accuracy: 0.7749\n",
      "Epoch 00003: early stopping\n",
      "7/7 [==============================] - 0s 4ms/step\n",
      "[CV]  num_filters=256, kern_size=5, fully_conected=16, epochs=15, batch_size=88, total=   5.4s\n",
      "[CV] num_filters=256, kern_size=5, fully_conected=16, epochs=15, batch_size=88 \n",
      "Epoch 1/15\n",
      "52/52 [==============================] - 2s 31ms/step - loss: 0.5207 - accuracy: 0.7411 - val_loss: 0.5005 - val_accuracy: 0.7649\n",
      "Epoch 2/15\n",
      "52/52 [==============================] - 1s 27ms/step - loss: 0.3522 - accuracy: 0.8525 - val_loss: 0.4821 - val_accuracy: 0.7789\n",
      "Epoch 3/15\n",
      "52/52 [==============================] - 2s 31ms/step - loss: 0.2529 - accuracy: 0.8995 - val_loss: 0.5044 - val_accuracy: 0.7869\n",
      "Epoch 00003: early stopping\n",
      "7/7 [==============================] - 0s 5ms/step\n",
      "[CV]  num_filters=256, kern_size=5, fully_conected=16, epochs=15, batch_size=88, total=   5.3s\n",
      "[CV] num_filters=256, kern_size=5, fully_conected=16, epochs=15, batch_size=88 \n",
      "Epoch 1/15\n",
      "52/52 [==============================] - 2s 32ms/step - loss: 0.5165 - accuracy: 0.7518 - val_loss: 0.4837 - val_accuracy: 0.7789\n",
      "Epoch 2/15\n",
      "52/52 [==============================] - 2s 33ms/step - loss: 0.3504 - accuracy: 0.8468 - val_loss: 0.4698 - val_accuracy: 0.7849\n",
      "Epoch 3/15\n",
      "52/52 [==============================] - 2s 32ms/step - loss: 0.2578 - accuracy: 0.8964 - val_loss: 0.5164 - val_accuracy: 0.7928\n",
      "Epoch 00003: early stopping\n",
      "7/7 [==============================] - 0s 5ms/step\n",
      "[CV]  num_filters=256, kern_size=5, fully_conected=16, epochs=15, batch_size=88, total=   5.9s\n",
      "[CV] num_filters=256, kern_size=5, fully_conected=16, epochs=15, batch_size=88 \n",
      "Epoch 1/15\n",
      "52/52 [==============================] - 2s 33ms/step - loss: 0.5054 - accuracy: 0.7544 - val_loss: 0.5098 - val_accuracy: 0.7550\n",
      "Epoch 2/15\n",
      "52/52 [==============================] - 2s 34ms/step - loss: 0.3430 - accuracy: 0.8563 - val_loss: 0.4695 - val_accuracy: 0.7908\n",
      "Epoch 3/15\n",
      "52/52 [==============================] - 2s 34ms/step - loss: 0.2450 - accuracy: 0.9085 - val_loss: 0.4910 - val_accuracy: 0.7968\n",
      "Epoch 00003: early stopping\n",
      "7/7 [==============================] - 0s 5ms/step\n",
      "[CV]  num_filters=256, kern_size=5, fully_conected=16, epochs=15, batch_size=88, total=   6.0s\n",
      "[CV] num_filters=256, kern_size=5, fully_conected=16, epochs=15, batch_size=88 \n",
      "Epoch 1/15\n",
      "52/52 [==============================] - 2s 35ms/step - loss: 0.5230 - accuracy: 0.7471 - val_loss: 0.4976 - val_accuracy: 0.7610\n",
      "Epoch 2/15\n",
      "52/52 [==============================] - 2s 32ms/step - loss: 0.3602 - accuracy: 0.8454 - val_loss: 0.4980 - val_accuracy: 0.7789\n",
      "Epoch 00002: early stopping\n",
      "7/7 [==============================] - 0s 5ms/step\n",
      "[CV]  num_filters=256, kern_size=5, fully_conected=16, epochs=15, batch_size=88, total=   4.3s\n",
      "[CV] num_filters=256, kern_size=5, fully_conected=16, epochs=15, batch_size=88 \n",
      "Epoch 1/15\n",
      "52/52 [==============================] - 2s 30ms/step - loss: 0.5224 - accuracy: 0.7434 - val_loss: 0.4095 - val_accuracy: 0.8386\n",
      "Epoch 2/15\n",
      "52/52 [==============================] - 2s 30ms/step - loss: 0.3560 - accuracy: 0.8463 - val_loss: 0.3984 - val_accuracy: 0.8466\n",
      "Epoch 3/15\n",
      "52/52 [==============================] - 2s 31ms/step - loss: 0.2613 - accuracy: 0.8977 - val_loss: 0.4018 - val_accuracy: 0.8546\n",
      "Epoch 00003: early stopping\n",
      "7/7 [==============================] - 0s 5ms/step\n",
      "[CV]  num_filters=256, kern_size=5, fully_conected=16, epochs=15, batch_size=88, total=   5.5s\n",
      "[CV] num_filters=128, kern_size=3, fully_conected=16, epochs=15, batch_size=76 \n",
      "Epoch 1/15\n",
      "60/60 [==============================] - 1s 24ms/step - loss: 0.5381 - accuracy: 0.7291 - val_loss: 0.5182 - val_accuracy: 0.7550\n",
      "Epoch 2/15\n",
      "60/60 [==============================] - 1s 23ms/step - loss: 0.3852 - accuracy: 0.8330 - val_loss: 0.4860 - val_accuracy: 0.7769\n",
      "Epoch 3/15\n",
      "60/60 [==============================] - 1s 25ms/step - loss: 0.3002 - accuracy: 0.8802 - val_loss: 0.4984 - val_accuracy: 0.7749\n",
      "Epoch 00003: early stopping\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "[CV]  num_filters=128, kern_size=3, fully_conected=16, epochs=15, batch_size=76, total=   5.0s\n",
      "[CV] num_filters=128, kern_size=3, fully_conected=16, epochs=15, batch_size=76 \n",
      "Epoch 1/15\n",
      "60/60 [==============================] - 1s 24ms/step - loss: 0.5415 - accuracy: 0.7298 - val_loss: 0.5368 - val_accuracy: 0.7450\n",
      "Epoch 2/15\n",
      "60/60 [==============================] - 1s 23ms/step - loss: 0.3864 - accuracy: 0.8341 - val_loss: 0.4760 - val_accuracy: 0.7809\n",
      "Epoch 3/15\n",
      "60/60 [==============================] - 1s 22ms/step - loss: 0.3017 - accuracy: 0.8722 - val_loss: 0.4701 - val_accuracy: 0.7689\n",
      "Epoch 4/15\n",
      "60/60 [==============================] - 1s 24ms/step - loss: 0.2281 - accuracy: 0.9187 - val_loss: 0.5007 - val_accuracy: 0.7809\n",
      "Epoch 00004: early stopping\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "[CV]  num_filters=128, kern_size=3, fully_conected=16, epochs=15, batch_size=76, total=   6.3s\n",
      "[CV] num_filters=128, kern_size=3, fully_conected=16, epochs=15, batch_size=76 \n",
      "Epoch 1/15\n",
      "60/60 [==============================] - 2s 27ms/step - loss: 0.5349 - accuracy: 0.7422 - val_loss: 0.4967 - val_accuracy: 0.7649\n",
      "Epoch 2/15\n",
      "60/60 [==============================] - 1s 24ms/step - loss: 0.3777 - accuracy: 0.8365 - val_loss: 0.5041 - val_accuracy: 0.7849\n",
      "Epoch 00002: early stopping\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "[CV]  num_filters=128, kern_size=3, fully_conected=16, epochs=15, batch_size=76, total=   3.7s\n",
      "[CV] num_filters=128, kern_size=3, fully_conected=16, epochs=15, batch_size=76 \n",
      "Epoch 1/15\n",
      "60/60 [==============================] - 1s 24ms/step - loss: 0.5517 - accuracy: 0.7236 - val_loss: 0.5128 - val_accuracy: 0.7610\n",
      "Epoch 2/15\n",
      "60/60 [==============================] - 1s 25ms/step - loss: 0.3830 - accuracy: 0.8377 - val_loss: 0.4817 - val_accuracy: 0.7869\n",
      "Epoch 3/15\n",
      "60/60 [==============================] - 1s 23ms/step - loss: 0.2991 - accuracy: 0.8766 - val_loss: 0.4984 - val_accuracy: 0.7888\n",
      "Epoch 00003: early stopping\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "[CV]  num_filters=128, kern_size=3, fully_conected=16, epochs=15, batch_size=76, total=   5.0s\n",
      "[CV] num_filters=128, kern_size=3, fully_conected=16, epochs=15, batch_size=76 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "60/60 [==============================] - 1s 21ms/step - loss: 0.5399 - accuracy: 0.7305 - val_loss: 0.5041 - val_accuracy: 0.7749\n",
      "Epoch 2/15\n",
      "60/60 [==============================] - 1s 23ms/step - loss: 0.3818 - accuracy: 0.8350 - val_loss: 0.4951 - val_accuracy: 0.7908\n",
      "Epoch 3/15\n",
      "60/60 [==============================] - 1s 23ms/step - loss: 0.3025 - accuracy: 0.8762 - val_loss: 0.4710 - val_accuracy: 0.7849\n",
      "Epoch 4/15\n",
      "60/60 [==============================] - 1s 20ms/step - loss: 0.2212 - accuracy: 0.9203 - val_loss: 0.4879 - val_accuracy: 0.7849\n",
      "Epoch 00004: early stopping\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "[CV]  num_filters=128, kern_size=3, fully_conected=16, epochs=15, batch_size=76, total=   5.9s\n",
      "[CV] num_filters=128, kern_size=3, fully_conected=16, epochs=15, batch_size=76 \n",
      "Epoch 1/15\n",
      "60/60 [==============================] - 1s 24ms/step - loss: 0.5334 - accuracy: 0.7374 - val_loss: 0.5124 - val_accuracy: 0.7769\n",
      "Epoch 2/15\n",
      "60/60 [==============================] - 1s 24ms/step - loss: 0.3818 - accuracy: 0.8348 - val_loss: 0.4827 - val_accuracy: 0.7888\n",
      "Epoch 3/15\n",
      "60/60 [==============================] - 1s 23ms/step - loss: 0.2959 - accuracy: 0.8846 - val_loss: 0.4903 - val_accuracy: 0.7869\n",
      "Epoch 00003: early stopping\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "[CV]  num_filters=128, kern_size=3, fully_conected=16, epochs=15, batch_size=76, total=   4.9s\n",
      "[CV] num_filters=128, kern_size=3, fully_conected=16, epochs=15, batch_size=76 \n",
      "Epoch 1/15\n",
      "60/60 [==============================] - 1s 23ms/step - loss: 0.5503 - accuracy: 0.7217 - val_loss: 0.5097 - val_accuracy: 0.7869\n",
      "Epoch 2/15\n",
      "60/60 [==============================] - 1s 23ms/step - loss: 0.3814 - accuracy: 0.8341 - val_loss: 0.4642 - val_accuracy: 0.7928\n",
      "Epoch 3/15\n",
      "60/60 [==============================] - 1s 21ms/step - loss: 0.2949 - accuracy: 0.8804 - val_loss: 0.4697 - val_accuracy: 0.7988\n",
      "Epoch 00003: early stopping\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "[CV]  num_filters=128, kern_size=3, fully_conected=16, epochs=15, batch_size=76, total=   4.7s\n",
      "[CV] num_filters=128, kern_size=3, fully_conected=16, epochs=15, batch_size=76 \n",
      "Epoch 1/15\n",
      "60/60 [==============================] - 1s 23ms/step - loss: 0.5449 - accuracy: 0.7239 - val_loss: 0.5210 - val_accuracy: 0.7829\n",
      "Epoch 2/15\n",
      "60/60 [==============================] - 1s 21ms/step - loss: 0.3770 - accuracy: 0.8359 - val_loss: 0.4654 - val_accuracy: 0.7749\n",
      "Epoch 3/15\n",
      "60/60 [==============================] - 1s 23ms/step - loss: 0.2999 - accuracy: 0.8822 - val_loss: 0.4853 - val_accuracy: 0.7888\n",
      "Epoch 00003: early stopping\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "[CV]  num_filters=128, kern_size=3, fully_conected=16, epochs=15, batch_size=76, total=   4.6s\n",
      "[CV] num_filters=128, kern_size=3, fully_conected=16, epochs=15, batch_size=76 \n",
      "Epoch 1/15\n",
      "60/60 [==============================] - 1s 23ms/step - loss: 0.5421 - accuracy: 0.7356 - val_loss: 0.5107 - val_accuracy: 0.7749\n",
      "Epoch 2/15\n",
      "60/60 [==============================] - 1s 23ms/step - loss: 0.3866 - accuracy: 0.8346 - val_loss: 0.5075 - val_accuracy: 0.7769\n",
      "Epoch 3/15\n",
      "60/60 [==============================] - 1s 21ms/step - loss: 0.3042 - accuracy: 0.8762 - val_loss: 0.4809 - val_accuracy: 0.7908\n",
      "Epoch 4/15\n",
      "60/60 [==============================] - 1s 23ms/step - loss: 0.2262 - accuracy: 0.9167 - val_loss: 0.5139 - val_accuracy: 0.7948\n",
      "Epoch 00004: early stopping\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "[CV]  num_filters=128, kern_size=3, fully_conected=16, epochs=15, batch_size=76, total=   6.1s\n",
      "[CV] num_filters=128, kern_size=3, fully_conected=16, epochs=15, batch_size=76 \n",
      "Epoch 1/15\n",
      "60/60 [==============================] - 1s 22ms/step - loss: 0.5455 - accuracy: 0.7267 - val_loss: 0.4327 - val_accuracy: 0.8167\n",
      "Epoch 2/15\n",
      "60/60 [==============================] - 1s 21ms/step - loss: 0.3872 - accuracy: 0.8257 - val_loss: 0.3997 - val_accuracy: 0.8466\n",
      "Epoch 3/15\n",
      "60/60 [==============================] - 1s 24ms/step - loss: 0.3033 - accuracy: 0.8771 - val_loss: 0.3824 - val_accuracy: 0.8426\n",
      "Epoch 4/15\n",
      "60/60 [==============================] - 1s 24ms/step - loss: 0.2265 - accuracy: 0.9110 - val_loss: 0.4155 - val_accuracy: 0.8287\n",
      "Epoch 00004: early stopping\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "[CV]  num_filters=128, kern_size=3, fully_conected=16, epochs=15, batch_size=76, total=   6.1s\n",
      "[CV] num_filters=256, kern_size=5, fully_conected=16, epochs=15, batch_size=76 \n",
      "Epoch 1/15\n",
      "60/60 [==============================] - 2s 26ms/step - loss: 0.5200 - accuracy: 0.7480 - val_loss: 0.4940 - val_accuracy: 0.7888\n",
      "Epoch 2/15\n",
      "60/60 [==============================] - 2s 25ms/step - loss: 0.3501 - accuracy: 0.8520 - val_loss: 0.5153 - val_accuracy: 0.7649\n",
      "Epoch 00002: early stopping\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "[CV]  num_filters=256, kern_size=5, fully_conected=16, epochs=15, batch_size=76, total=   3.7s\n",
      "[CV] num_filters=256, kern_size=5, fully_conected=16, epochs=15, batch_size=76 \n",
      "Epoch 1/15\n",
      "60/60 [==============================] - 2s 28ms/step - loss: 0.5274 - accuracy: 0.7440 - val_loss: 0.5232 - val_accuracy: 0.7749\n",
      "Epoch 2/15\n",
      "60/60 [==============================] - 2s 28ms/step - loss: 0.3527 - accuracy: 0.8498 - val_loss: 0.4761 - val_accuracy: 0.7729\n",
      "Epoch 3/15\n",
      "60/60 [==============================] - 2s 25ms/step - loss: 0.2594 - accuracy: 0.9032 - val_loss: 0.5493 - val_accuracy: 0.7869\n",
      "Epoch 00003: early stopping\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "[CV]  num_filters=256, kern_size=5, fully_conected=16, epochs=15, batch_size=76, total=   5.6s\n",
      "[CV] num_filters=256, kern_size=5, fully_conected=16, epochs=15, batch_size=76 \n",
      "Epoch 1/15\n",
      "60/60 [==============================] - 2s 26ms/step - loss: 0.5216 - accuracy: 0.7455 - val_loss: 0.5002 - val_accuracy: 0.7689\n",
      "Epoch 2/15\n",
      "60/60 [==============================] - 2s 26ms/step - loss: 0.3472 - accuracy: 0.8571 - val_loss: 0.4799 - val_accuracy: 0.7888\n",
      "Epoch 3/15\n",
      "60/60 [==============================] - 2s 26ms/step - loss: 0.2450 - accuracy: 0.9085 - val_loss: 0.5129 - val_accuracy: 0.7809\n",
      "Epoch 00003: early stopping\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "[CV]  num_filters=256, kern_size=5, fully_conected=16, epochs=15, batch_size=76, total=   5.4s\n",
      "[CV] num_filters=256, kern_size=5, fully_conected=16, epochs=15, batch_size=76 \n",
      "Epoch 1/15\n",
      "60/60 [==============================] - 2s 28ms/step - loss: 0.5135 - accuracy: 0.7550 - val_loss: 0.4830 - val_accuracy: 0.7729\n",
      "Epoch 2/15\n",
      "60/60 [==============================] - 2s 26ms/step - loss: 0.3460 - accuracy: 0.8543 - val_loss: 0.4772 - val_accuracy: 0.7888\n",
      "Epoch 3/15\n",
      "60/60 [==============================] - 1s 25ms/step - loss: 0.2464 - accuracy: 0.9050 - val_loss: 0.4990 - val_accuracy: 0.7849\n",
      "Epoch 00003: early stopping\n",
      "8/8 [==============================] - 0s 4ms/step\n",
      "[CV]  num_filters=256, kern_size=5, fully_conected=16, epochs=15, batch_size=76, total=   6.4s\n",
      "[CV] num_filters=256, kern_size=5, fully_conected=16, epochs=15, batch_size=76 \n",
      "Epoch 1/15\n",
      "60/60 [==============================] - 1s 25ms/step - loss: 0.5131 - accuracy: 0.7530 - val_loss: 0.4931 - val_accuracy: 0.7669\n",
      "Epoch 2/15\n",
      "60/60 [==============================] - 2s 26ms/step - loss: 0.3442 - accuracy: 0.8569 - val_loss: 0.4789 - val_accuracy: 0.7849\n",
      "Epoch 3/15\n",
      "60/60 [==============================] - 2s 26ms/step - loss: 0.2437 - accuracy: 0.9083 - val_loss: 0.5176 - val_accuracy: 0.7689\n",
      "Epoch 00003: early stopping\n",
      "8/8 [==============================] - 0s 5ms/step\n",
      "[CV]  num_filters=256, kern_size=5, fully_conected=16, epochs=15, batch_size=76, total=   5.3s\n",
      "[CV] num_filters=256, kern_size=5, fully_conected=16, epochs=15, batch_size=76 \n",
      "Epoch 1/15\n",
      "60/60 [==============================] - 2s 27ms/step - loss: 0.5119 - accuracy: 0.7522 - val_loss: 0.5168 - val_accuracy: 0.7669\n",
      "Epoch 2/15\n",
      "60/60 [==============================] - 2s 28ms/step - loss: 0.3455 - accuracy: 0.8552 - val_loss: 0.5173 - val_accuracy: 0.7749\n",
      "Epoch 00002: early stopping\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "[CV]  num_filters=256, kern_size=5, fully_conected=16, epochs=15, batch_size=76, total=   4.0s\n",
      "[CV] num_filters=256, kern_size=5, fully_conected=16, epochs=15, batch_size=76 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "60/60 [==============================] - 2s 27ms/step - loss: 0.5147 - accuracy: 0.7533 - val_loss: 0.4786 - val_accuracy: 0.7709\n",
      "Epoch 2/15\n",
      "60/60 [==============================] - 2s 26ms/step - loss: 0.3409 - accuracy: 0.8572 - val_loss: 0.4818 - val_accuracy: 0.7948\n",
      "Epoch 00002: early stopping\n",
      "8/8 [==============================] - 0s 4ms/step\n",
      "[CV]  num_filters=256, kern_size=5, fully_conected=16, epochs=15, batch_size=76, total=   3.9s\n",
      "[CV] num_filters=256, kern_size=5, fully_conected=16, epochs=15, batch_size=76 \n",
      "Epoch 1/15\n",
      "60/60 [==============================] - 2s 27ms/step - loss: 0.4966 - accuracy: 0.7637 - val_loss: 0.5117 - val_accuracy: 0.7689\n",
      "Epoch 2/15\n",
      "60/60 [==============================] - 2s 31ms/step - loss: 0.3373 - accuracy: 0.8543 - val_loss: 0.4782 - val_accuracy: 0.7769\n",
      "Epoch 3/15\n",
      "60/60 [==============================] - 2s 29ms/step - loss: 0.2383 - accuracy: 0.9068 - val_loss: 0.5177 - val_accuracy: 0.7789\n",
      "Epoch 00003: early stopping\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "[CV]  num_filters=256, kern_size=5, fully_conected=16, epochs=15, batch_size=76, total=   6.0s\n",
      "[CV] num_filters=256, kern_size=5, fully_conected=16, epochs=15, batch_size=76 \n",
      "Epoch 1/15\n",
      "60/60 [==============================] - 2s 29ms/step - loss: 0.5133 - accuracy: 0.7504 - val_loss: 0.4998 - val_accuracy: 0.7829\n",
      "Epoch 2/15\n",
      "60/60 [==============================] - 1s 25ms/step - loss: 0.3496 - accuracy: 0.8472 - val_loss: 0.4878 - val_accuracy: 0.7689\n",
      "Epoch 3/15\n",
      "60/60 [==============================] - 2s 26ms/step - loss: 0.2487 - accuracy: 0.9012 - val_loss: 0.5024 - val_accuracy: 0.7789\n",
      "Epoch 00003: early stopping\n",
      "8/8 [==============================] - 0s 4ms/step\n",
      "[CV]  num_filters=256, kern_size=5, fully_conected=16, epochs=15, batch_size=76, total=   5.6s\n",
      "[CV] num_filters=256, kern_size=5, fully_conected=16, epochs=15, batch_size=76 \n",
      "Epoch 1/15\n",
      "60/60 [==============================] - 2s 27ms/step - loss: 0.5156 - accuracy: 0.7493 - val_loss: 0.4150 - val_accuracy: 0.8367\n",
      "Epoch 2/15\n",
      "60/60 [==============================] - 1s 25ms/step - loss: 0.3638 - accuracy: 0.8432 - val_loss: 0.4274 - val_accuracy: 0.8167\n",
      "Epoch 00002: early stopping\n",
      "8/8 [==============================] - 0s 4ms/step\n",
      "[CV]  num_filters=256, kern_size=5, fully_conected=16, epochs=15, batch_size=76, total=   3.9s\n",
      "[CV] num_filters=128, kern_size=3, fully_conected=60, epochs=15, batch_size=88 \n",
      "Epoch 1/15\n",
      "52/52 [==============================] - 1s 22ms/step - loss: 0.5478 - accuracy: 0.7249 - val_loss: 0.5059 - val_accuracy: 0.7629\n",
      "Epoch 2/15\n",
      "52/52 [==============================] - 1s 20ms/step - loss: 0.3832 - accuracy: 0.8343 - val_loss: 0.4812 - val_accuracy: 0.7649\n",
      "Epoch 3/15\n",
      "52/52 [==============================] - 1s 20ms/step - loss: 0.3046 - accuracy: 0.8775 - val_loss: 0.4740 - val_accuracy: 0.7849\n",
      "Epoch 4/15\n",
      "52/52 [==============================] - 1s 20ms/step - loss: 0.2367 - accuracy: 0.9085 - val_loss: 0.4976 - val_accuracy: 0.7769\n",
      "Epoch 00004: early stopping\n",
      "7/7 [==============================] - 0s 2ms/step\n",
      "[CV]  num_filters=128, kern_size=3, fully_conected=60, epochs=15, batch_size=88, total=   5.0s\n",
      "[CV] num_filters=128, kern_size=3, fully_conected=60, epochs=15, batch_size=88 \n",
      "Epoch 1/15\n",
      "52/52 [==============================] - 1s 23ms/step - loss: 0.5480 - accuracy: 0.7296 - val_loss: 0.5316 - val_accuracy: 0.7490\n",
      "Epoch 2/15\n",
      "52/52 [==============================] - 1s 21ms/step - loss: 0.3920 - accuracy: 0.8268 - val_loss: 0.4852 - val_accuracy: 0.7789\n",
      "Epoch 3/15\n",
      "52/52 [==============================] - 1s 21ms/step - loss: 0.3117 - accuracy: 0.8720 - val_loss: 0.4785 - val_accuracy: 0.7769\n",
      "Epoch 4/15\n",
      "52/52 [==============================] - 1s 21ms/step - loss: 0.2378 - accuracy: 0.9114 - val_loss: 0.4781 - val_accuracy: 0.7729\n",
      "Epoch 5/15\n",
      "52/52 [==============================] - 1s 21ms/step - loss: 0.1715 - accuracy: 0.9429 - val_loss: 0.5237 - val_accuracy: 0.7849\n",
      "Epoch 00005: early stopping\n",
      "7/7 [==============================] - 0s 2ms/step\n",
      "[CV]  num_filters=128, kern_size=3, fully_conected=60, epochs=15, batch_size=88, total=   6.5s\n",
      "[CV] num_filters=128, kern_size=3, fully_conected=60, epochs=15, batch_size=88 \n",
      "Epoch 1/15\n",
      "52/52 [==============================] - 1s 23ms/step - loss: 0.5395 - accuracy: 0.7380 - val_loss: 0.5139 - val_accuracy: 0.7769\n",
      "Epoch 2/15\n",
      "52/52 [==============================] - 1s 21ms/step - loss: 0.3903 - accuracy: 0.8337 - val_loss: 0.4800 - val_accuracy: 0.7829\n",
      "Epoch 3/15\n",
      "52/52 [==============================] - 1s 24ms/step - loss: 0.3100 - accuracy: 0.8753 - val_loss: 0.4802 - val_accuracy: 0.7948\n",
      "Epoch 00003: early stopping\n",
      "7/7 [==============================] - 0s 2ms/step\n",
      "[CV]  num_filters=128, kern_size=3, fully_conected=60, epochs=15, batch_size=88, total=   4.4s\n",
      "[CV] num_filters=128, kern_size=3, fully_conected=60, epochs=15, batch_size=88 \n",
      "Epoch 1/15\n",
      "52/52 [==============================] - 1s 25ms/step - loss: 0.5404 - accuracy: 0.7353 - val_loss: 0.5119 - val_accuracy: 0.7709\n",
      "Epoch 2/15\n",
      "52/52 [==============================] - 1s 20ms/step - loss: 0.3899 - accuracy: 0.8341 - val_loss: 0.4742 - val_accuracy: 0.7829\n",
      "Epoch 3/15\n",
      "52/52 [==============================] - 1s 20ms/step - loss: 0.3026 - accuracy: 0.8777 - val_loss: 0.4724 - val_accuracy: 0.7908\n",
      "Epoch 4/15\n",
      "52/52 [==============================] - 1s 20ms/step - loss: 0.2311 - accuracy: 0.9134 - val_loss: 0.5235 - val_accuracy: 0.7908\n",
      "Epoch 00004: early stopping\n",
      "7/7 [==============================] - 0s 2ms/step\n",
      "[CV]  num_filters=128, kern_size=3, fully_conected=60, epochs=15, batch_size=88, total=   5.2s\n",
      "[CV] num_filters=128, kern_size=3, fully_conected=60, epochs=15, batch_size=88 \n",
      "Epoch 1/15\n",
      "52/52 [==============================] - 1s 21ms/step - loss: 0.5450 - accuracy: 0.7254 - val_loss: 0.5094 - val_accuracy: 0.7629\n",
      "Epoch 2/15\n",
      "52/52 [==============================] - 1s 20ms/step - loss: 0.3860 - accuracy: 0.8319 - val_loss: 0.4722 - val_accuracy: 0.7849\n",
      "Epoch 3/15\n",
      "52/52 [==============================] - 1s 20ms/step - loss: 0.3073 - accuracy: 0.8771 - val_loss: 0.4718 - val_accuracy: 0.7888\n",
      "Epoch 4/15\n",
      "52/52 [==============================] - 1s 20ms/step - loss: 0.2340 - accuracy: 0.9123 - val_loss: 0.5021 - val_accuracy: 0.7928\n",
      "Epoch 00004: early stopping\n",
      "7/7 [==============================] - 0s 2ms/step\n",
      "[CV]  num_filters=128, kern_size=3, fully_conected=60, epochs=15, batch_size=88, total=   5.0s\n",
      "[CV] num_filters=128, kern_size=3, fully_conected=60, epochs=15, batch_size=88 \n",
      "Epoch 1/15\n",
      "52/52 [==============================] - 1s 22ms/step - loss: 0.5356 - accuracy: 0.7367 - val_loss: 0.5130 - val_accuracy: 0.7689\n",
      "Epoch 2/15\n",
      "52/52 [==============================] - 1s 20ms/step - loss: 0.3945 - accuracy: 0.8317 - val_loss: 0.5172 - val_accuracy: 0.7769\n",
      "Epoch 00002: early stopping\n",
      "7/7 [==============================] - 0s 2ms/step\n",
      "[CV]  num_filters=128, kern_size=3, fully_conected=60, epochs=15, batch_size=88, total=   2.9s\n",
      "[CV] num_filters=128, kern_size=3, fully_conected=60, epochs=15, batch_size=88 \n",
      "Epoch 1/15\n",
      "52/52 [==============================] - 1s 23ms/step - loss: 0.5547 - accuracy: 0.7112 - val_loss: 0.5098 - val_accuracy: 0.7649\n",
      "Epoch 2/15\n",
      "52/52 [==============================] - 1s 21ms/step - loss: 0.3919 - accuracy: 0.8297 - val_loss: 0.4766 - val_accuracy: 0.7928\n",
      "Epoch 3/15\n",
      "52/52 [==============================] - 1s 21ms/step - loss: 0.3200 - accuracy: 0.8674 - val_loss: 0.4594 - val_accuracy: 0.8048\n",
      "Epoch 4/15\n",
      "52/52 [==============================] - 1s 22ms/step - loss: 0.2344 - accuracy: 0.9141 - val_loss: 0.4790 - val_accuracy: 0.8048\n",
      "Epoch 00004: early stopping\n",
      "7/7 [==============================] - 0s 2ms/step\n",
      "[CV]  num_filters=128, kern_size=3, fully_conected=60, epochs=15, batch_size=88, total=   5.3s\n",
      "[CV] num_filters=128, kern_size=3, fully_conected=60, epochs=15, batch_size=88 \n",
      "Epoch 1/15\n",
      "52/52 [==============================] - 1s 24ms/step - loss: 0.5527 - accuracy: 0.7183 - val_loss: 0.5201 - val_accuracy: 0.7649\n",
      "Epoch 2/15\n",
      "52/52 [==============================] - 1s 23ms/step - loss: 0.3834 - accuracy: 0.8324 - val_loss: 0.4774 - val_accuracy: 0.7729\n",
      "Epoch 3/15\n",
      "52/52 [==============================] - 1s 21ms/step - loss: 0.3025 - accuracy: 0.8753 - val_loss: 0.4690 - val_accuracy: 0.7869\n",
      "Epoch 4/15\n",
      "52/52 [==============================] - 1s 20ms/step - loss: 0.2281 - accuracy: 0.9147 - val_loss: 0.4881 - val_accuracy: 0.7988\n",
      "Epoch 00004: early stopping\n",
      "7/7 [==============================] - 0s 2ms/step\n",
      "[CV]  num_filters=128, kern_size=3, fully_conected=60, epochs=15, batch_size=88, total=   5.4s\n",
      "[CV] num_filters=128, kern_size=3, fully_conected=60, epochs=15, batch_size=88 \n",
      "Epoch 1/15\n",
      "52/52 [==============================] - 1s 22ms/step - loss: 0.5555 - accuracy: 0.7139 - val_loss: 0.5233 - val_accuracy: 0.7510\n",
      "Epoch 2/15\n",
      "52/52 [==============================] - 1s 19ms/step - loss: 0.3967 - accuracy: 0.8224 - val_loss: 0.4832 - val_accuracy: 0.7769\n",
      "Epoch 3/15\n",
      "52/52 [==============================] - 1s 19ms/step - loss: 0.3162 - accuracy: 0.8709 - val_loss: 0.4809 - val_accuracy: 0.7849\n",
      "Epoch 4/15\n",
      "52/52 [==============================] - 1s 20ms/step - loss: 0.2398 - accuracy: 0.9121 - val_loss: 0.5075 - val_accuracy: 0.7769\n",
      "Epoch 00004: early stopping\n",
      "7/7 [==============================] - 0s 2ms/step\n",
      "[CV]  num_filters=128, kern_size=3, fully_conected=60, epochs=15, batch_size=88, total=   5.0s\n",
      "[CV] num_filters=128, kern_size=3, fully_conected=60, epochs=15, batch_size=88 \n",
      "Epoch 1/15\n",
      "52/52 [==============================] - 1s 20ms/step - loss: 0.5620 - accuracy: 0.7095 - val_loss: 0.4332 - val_accuracy: 0.8227\n",
      "Epoch 2/15\n",
      "52/52 [==============================] - 1s 18ms/step - loss: 0.3951 - accuracy: 0.8315 - val_loss: 0.3926 - val_accuracy: 0.8406\n",
      "Epoch 3/15\n",
      "52/52 [==============================] - 1s 19ms/step - loss: 0.3120 - accuracy: 0.8742 - val_loss: 0.3859 - val_accuracy: 0.8486\n",
      "Epoch 4/15\n",
      "52/52 [==============================] - 1s 19ms/step - loss: 0.2376 - accuracy: 0.9128 - val_loss: 0.4048 - val_accuracy: 0.8347\n",
      "Epoch 00004: early stopping\n",
      "7/7 [==============================] - 0s 2ms/step\n",
      "[CV]  num_filters=128, kern_size=3, fully_conected=60, epochs=15, batch_size=88, total=   4.7s\n",
      "[CV] num_filters=64, kern_size=5, fully_conected=16, epochs=15, batch_size=88 \n",
      "Epoch 1/15\n",
      "52/52 [==============================] - 1s 20ms/step - loss: 0.5597 - accuracy: 0.7083 - val_loss: 0.5512 - val_accuracy: 0.7430\n",
      "Epoch 2/15\n",
      "52/52 [==============================] - 1s 18ms/step - loss: 0.3980 - accuracy: 0.8259 - val_loss: 0.4851 - val_accuracy: 0.7829\n",
      "Epoch 3/15\n",
      "52/52 [==============================] - 1s 19ms/step - loss: 0.3119 - accuracy: 0.8715 - val_loss: 0.4894 - val_accuracy: 0.7928\n",
      "Epoch 00003: early stopping\n",
      "7/7 [==============================] - 0s 2ms/step\n",
      "[CV]  num_filters=64, kern_size=5, fully_conected=16, epochs=15, batch_size=88, total=   3.7s\n",
      "[CV] num_filters=64, kern_size=5, fully_conected=16, epochs=15, batch_size=88 \n",
      "Epoch 1/15\n",
      "52/52 [==============================] - 1s 20ms/step - loss: 0.5589 - accuracy: 0.7110 - val_loss: 0.5381 - val_accuracy: 0.7490\n",
      "Epoch 2/15\n",
      "52/52 [==============================] - 1s 18ms/step - loss: 0.3921 - accuracy: 0.8286 - val_loss: 0.4886 - val_accuracy: 0.7649\n",
      "Epoch 3/15\n",
      "52/52 [==============================] - 1s 19ms/step - loss: 0.3099 - accuracy: 0.8715 - val_loss: 0.4746 - val_accuracy: 0.7789\n",
      "Epoch 4/15\n",
      "52/52 [==============================] - 1s 19ms/step - loss: 0.2405 - accuracy: 0.9092 - val_loss: 0.4966 - val_accuracy: 0.7809\n",
      "Epoch 00004: early stopping\n",
      "7/7 [==============================] - 0s 2ms/step\n",
      "[CV]  num_filters=64, kern_size=5, fully_conected=16, epochs=15, batch_size=88, total=   4.7s\n",
      "[CV] num_filters=64, kern_size=5, fully_conected=16, epochs=15, batch_size=88 \n",
      "Epoch 1/15\n",
      "52/52 [==============================] - 1s 21ms/step - loss: 0.5386 - accuracy: 0.7355 - val_loss: 0.5034 - val_accuracy: 0.7530\n",
      "Epoch 2/15\n",
      "52/52 [==============================] - 1s 19ms/step - loss: 0.3926 - accuracy: 0.8270 - val_loss: 0.4845 - val_accuracy: 0.7888\n",
      "Epoch 3/15\n",
      "52/52 [==============================] - 1s 18ms/step - loss: 0.3164 - accuracy: 0.8678 - val_loss: 0.4785 - val_accuracy: 0.7948\n",
      "Epoch 4/15\n",
      "52/52 [==============================] - 1s 19ms/step - loss: 0.2405 - accuracy: 0.9163 - val_loss: 0.4909 - val_accuracy: 0.8028\n",
      "Epoch 00004: early stopping\n",
      "7/7 [==============================] - 0s 2ms/step\n",
      "[CV]  num_filters=64, kern_size=5, fully_conected=16, epochs=15, batch_size=88, total=   4.8s\n",
      "[CV] num_filters=64, kern_size=5, fully_conected=16, epochs=15, batch_size=88 \n",
      "Epoch 1/15\n",
      "52/52 [==============================] - 1s 21ms/step - loss: 0.5378 - accuracy: 0.7309 - val_loss: 0.5194 - val_accuracy: 0.7570\n",
      "Epoch 2/15\n",
      "52/52 [==============================] - 1s 18ms/step - loss: 0.3847 - accuracy: 0.8321 - val_loss: 0.4931 - val_accuracy: 0.7769\n",
      "Epoch 3/15\n",
      "52/52 [==============================] - 1s 19ms/step - loss: 0.3030 - accuracy: 0.8815 - val_loss: 0.4799 - val_accuracy: 0.7869\n",
      "Epoch 4/15\n",
      "52/52 [==============================] - 1s 19ms/step - loss: 0.2309 - accuracy: 0.9147 - val_loss: 0.4890 - val_accuracy: 0.7829\n",
      "Epoch 00004: early stopping\n",
      "7/7 [==============================] - 0s 2ms/step\n",
      "[CV]  num_filters=64, kern_size=5, fully_conected=16, epochs=15, batch_size=88, total=   4.7s\n",
      "[CV] num_filters=64, kern_size=5, fully_conected=16, epochs=15, batch_size=88 \n",
      "Epoch 1/15\n",
      "52/52 [==============================] - 1s 21ms/step - loss: 0.5692 - accuracy: 0.7121 - val_loss: 0.5443 - val_accuracy: 0.7251\n",
      "Epoch 2/15\n",
      "52/52 [==============================] - 1s 18ms/step - loss: 0.3977 - accuracy: 0.8213 - val_loss: 0.5227 - val_accuracy: 0.7570\n",
      "Epoch 3/15\n",
      "52/52 [==============================] - 1s 19ms/step - loss: 0.3154 - accuracy: 0.8738 - val_loss: 0.4899 - val_accuracy: 0.7749\n",
      "Epoch 4/15\n",
      "52/52 [==============================] - 1s 19ms/step - loss: 0.2393 - accuracy: 0.9136 - val_loss: 0.5080 - val_accuracy: 0.7629\n",
      "Epoch 00004: early stopping\n",
      "7/7 [==============================] - 0s 2ms/step\n",
      "[CV]  num_filters=64, kern_size=5, fully_conected=16, epochs=15, batch_size=88, total=   4.7s\n",
      "[CV] num_filters=64, kern_size=5, fully_conected=16, epochs=15, batch_size=88 \n",
      "Epoch 1/15\n",
      "52/52 [==============================] - 1s 20ms/step - loss: 0.5630 - accuracy: 0.7101 - val_loss: 0.5190 - val_accuracy: 0.7610\n",
      "Epoch 2/15\n",
      "52/52 [==============================] - 1s 19ms/step - loss: 0.3922 - accuracy: 0.8246 - val_loss: 0.4780 - val_accuracy: 0.7829\n",
      "Epoch 3/15\n",
      "52/52 [==============================] - 2s 38ms/step - loss: 0.3130 - accuracy: 0.8729 - val_loss: 0.4695 - val_accuracy: 0.7948\n",
      "Epoch 4/15\n",
      "52/52 [==============================] - 1s 17ms/step - loss: 0.2364 - accuracy: 0.9134 - val_loss: 0.4807 - val_accuracy: 0.7988\n",
      "Epoch 00004: early stopping\n",
      "7/7 [==============================] - 0s 2ms/step\n",
      "[CV]  num_filters=64, kern_size=5, fully_conected=16, epochs=15, batch_size=88, total=   5.7s\n",
      "[CV] num_filters=64, kern_size=5, fully_conected=16, epochs=15, batch_size=88 \n",
      "Epoch 1/15\n",
      "52/52 [==============================] - 1s 18ms/step - loss: 0.5478 - accuracy: 0.7168 - val_loss: 0.5105 - val_accuracy: 0.7490\n",
      "Epoch 2/15\n",
      "52/52 [==============================] - 1s 17ms/step - loss: 0.3887 - accuracy: 0.8302 - val_loss: 0.4753 - val_accuracy: 0.7869\n",
      "Epoch 3/15\n",
      "52/52 [==============================] - 1s 18ms/step - loss: 0.3057 - accuracy: 0.8773 - val_loss: 0.4744 - val_accuracy: 0.7809\n",
      "Epoch 4/15\n",
      "52/52 [==============================] - 1s 17ms/step - loss: 0.2337 - accuracy: 0.9128 - val_loss: 0.4896 - val_accuracy: 0.7928\n",
      "Epoch 00004: early stopping\n",
      "7/7 [==============================] - 0s 2ms/step\n",
      "[CV]  num_filters=64, kern_size=5, fully_conected=16, epochs=15, batch_size=88, total=   4.4s\n",
      "[CV] num_filters=64, kern_size=5, fully_conected=16, epochs=15, batch_size=88 \n",
      "Epoch 1/15\n",
      "52/52 [==============================] - 1s 20ms/step - loss: 0.5573 - accuracy: 0.7155 - val_loss: 0.5268 - val_accuracy: 0.7390\n",
      "Epoch 2/15\n",
      "52/52 [==============================] - 1s 17ms/step - loss: 0.3906 - accuracy: 0.8273 - val_loss: 0.4721 - val_accuracy: 0.7749\n",
      "Epoch 3/15\n",
      "52/52 [==============================] - 1s 18ms/step - loss: 0.3066 - accuracy: 0.8731 - val_loss: 0.4881 - val_accuracy: 0.7928\n",
      "Epoch 00003: early stopping\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 2ms/step\n",
      "[CV]  num_filters=64, kern_size=5, fully_conected=16, epochs=15, batch_size=88, total=   3.6s\n",
      "[CV] num_filters=64, kern_size=5, fully_conected=16, epochs=15, batch_size=88 \n",
      "Epoch 1/15\n",
      "52/52 [==============================] - 1s 20ms/step - loss: 0.5530 - accuracy: 0.7219 - val_loss: 0.5329 - val_accuracy: 0.7530\n",
      "Epoch 2/15\n",
      "52/52 [==============================] - 1s 18ms/step - loss: 0.3945 - accuracy: 0.8271 - val_loss: 0.4955 - val_accuracy: 0.7649\n",
      "Epoch 3/15\n",
      "52/52 [==============================] - 1s 19ms/step - loss: 0.3136 - accuracy: 0.8740 - val_loss: 0.4918 - val_accuracy: 0.7769\n",
      "Epoch 4/15\n",
      "52/52 [==============================] - 1s 19ms/step - loss: 0.2387 - accuracy: 0.9105 - val_loss: 0.5110 - val_accuracy: 0.7869\n",
      "Epoch 00004: early stopping\n",
      "7/7 [==============================] - 0s 3ms/step\n",
      "[CV]  num_filters=64, kern_size=5, fully_conected=16, epochs=15, batch_size=88, total=   4.7s\n",
      "[CV] num_filters=64, kern_size=5, fully_conected=16, epochs=15, batch_size=88 \n",
      "Epoch 1/15\n",
      "52/52 [==============================] - 1s 20ms/step - loss: 0.5477 - accuracy: 0.7267 - val_loss: 0.4366 - val_accuracy: 0.8088\n",
      "Epoch 2/15\n",
      "52/52 [==============================] - 1s 18ms/step - loss: 0.4047 - accuracy: 0.8206 - val_loss: 0.3988 - val_accuracy: 0.8327\n",
      "Epoch 3/15\n",
      "52/52 [==============================] - 1s 18ms/step - loss: 0.3153 - accuracy: 0.8713 - val_loss: 0.3980 - val_accuracy: 0.8426\n",
      "Epoch 4/15\n",
      "52/52 [==============================] - 1s 19ms/step - loss: 0.2418 - accuracy: 0.9114 - val_loss: 0.4415 - val_accuracy: 0.8187\n",
      "Epoch 00004: early stopping\n",
      "7/7 [==============================] - 0s 2ms/step\n",
      "[CV]  num_filters=64, kern_size=5, fully_conected=16, epochs=15, batch_size=88, total=   4.7s\n",
      "Epoch 1/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:  4.1min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "67/67 [==============================] - 1s 20ms/step - loss: 0.5288 - accuracy: 0.7421 - val_loss: 0.5232 - val_accuracy: 0.7760\n",
      "Epoch 2/15\n",
      "67/67 [==============================] - 1s 19ms/step - loss: 0.3781 - accuracy: 0.8312 - val_loss: 0.4720 - val_accuracy: 0.7975\n",
      "Epoch 3/15\n",
      "67/67 [==============================] - 1s 19ms/step - loss: 0.2957 - accuracy: 0.8764 - val_loss: 0.4823 - val_accuracy: 0.8029\n",
      "Epoch 00003: early stopping\n",
      "25/25 [==============================] - 0s 2ms/step\n",
      "Best Accuracy : 0.8045\n",
      "{'num_filters': 128, 'kern_size': 3, 'fully_conected': 16, 'epochs': 15, 'batch_size': 76}\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "param_grid = dict(num_filters=[64, 128, 256],\n",
    "                      kern_size=[3, 5, 7],\n",
    "                      batch_size = [76,88],\n",
    "                      fully_conected = [16, 60], epochs = [15])\n",
    "\n",
    "model = KerasClassifier(build_fn=build_model, epochs=15, validation_split=0.1,verbose=1)\n",
    "\n",
    "grid = RandomizedSearchCV(estimator=model, param_distributions=param_grid,\n",
    "                              cv=10, verbose=2, n_iter=5, n_jobs=1,scoring = 'accuracy')\n",
    "\n",
    "grid_result = grid.fit(x_train, y_train, callbacks=[callback])\n",
    "\n",
    "\n",
    "test_accuracy = grid.score(x_test, y_test)\n",
    "\n",
    "# Save and evaluate results\n",
    "s = ('Best Accuracy : {:.4f}\\n{}\\n\\n\\n')\n",
    "output_string = s.format(\n",
    "            grid_result.best_score_,\n",
    "            grid_result.best_params_)\n",
    "            \n",
    "print(output_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = Sequential()\n",
    "e = Embedding(vocab_size, 100, weights=[embedding_matrix], input_length=31, trainable=True)\n",
    "model1.add(e)\n",
    "model1.add(layers.Conv1D(256, 5, activation='relu'))\n",
    "model1.add(layers.Activation(activations.relu))\n",
    "model1.add(Flatten())\n",
    "model1.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model1.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "74/74 - 2s - loss: 0.5144 - accuracy: 0.7476 - val_loss: 0.4274 - val_accuracy: 0.8101\n",
      "Epoch 2/15\n",
      "74/74 - 2s - loss: 0.3513 - accuracy: 0.8502 - val_loss: 0.4149 - val_accuracy: 0.8219\n",
      "Epoch 3/15\n",
      "74/74 - 2s - loss: 0.2459 - accuracy: 0.9087 - val_loss: 0.4504 - val_accuracy: 0.8004\n",
      "Epoch 00003: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x247682b10>"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = \\\n",
    "train_test_split(padded_docs, tweets['target'], test_size = 0.25, random_state = 123)\n",
    "callback = EarlyStopping(monitor = 'val_loss', patience = 1, verbose=1)\n",
    "callbacks = [callback]\n",
    "\n",
    "model1.fit(x_train, y_train,\n",
    "          validation_data=(x_test, y_test),\n",
    "          batch_size=76,\n",
    "          epochs=2,\n",
    "          verbose=2,\n",
    "          callbacks=callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "98/98 - 2s - loss: 0.4884 - accuracy: 0.7702\n",
      "Epoch 2/2\n",
      "98/98 - 2s - loss: 0.3404 - accuracy: 0.8569\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x21b88e050>"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.fit(padded_docs, tweets['target'],\n",
    "          batch_size=76,\n",
    "          epochs=2,\n",
    "          verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_result = model1.predict(padded_tests)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.62312335],\n",
       "       [0.81232417],\n",
       "       [0.7813207 ],\n",
       "       ...,\n",
       "       [0.75635624],\n",
       "       [0.81779766],\n",
       "       [0.2327313 ]], dtype=float32)"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " ...]"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submit = []\n",
    "\n",
    "for i in test_result:\n",
    "    if i >= 0.5 :\n",
    "        submit.append(1)\n",
    "    else:\n",
    "        submit.append(0)\n",
    "\n",
    "submit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "tests['target'] = submit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit_df = tests[['id', 'target']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3258</th>\n",
       "      <td>10861</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3259</th>\n",
       "      <td>10865</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3260</th>\n",
       "      <td>10868</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3261</th>\n",
       "      <td>10874</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3262</th>\n",
       "      <td>10875</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3263 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id  target\n",
       "0         0       1\n",
       "1         2       1\n",
       "2         3       1\n",
       "3         9       1\n",
       "4        11       1\n",
       "...     ...     ...\n",
       "3258  10861       1\n",
       "3259  10865       1\n",
       "3260  10868       1\n",
       "3261  10874       1\n",
       "3262  10875       0\n",
       "\n",
       "[3263 rows x 2 columns]"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submit_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit_df.to_csv('submit_prueba_38.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_531\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_531 (Embedding)    (None, 31, 100)           2258600   \n",
      "_________________________________________________________________\n",
      "conv1d_696 (Conv1D)          (None, 25, 256)           179456    \n",
      "_________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D) (None, 12, 256)           0         \n",
      "_________________________________________________________________\n",
      "flatten_507 (Flatten)        (None, 3072)              0         \n",
      "_________________________________________________________________\n",
      "dense_871 (Dense)            (None, 1)                 3073      \n",
      "=================================================================\n",
      "Total params: 2,441,129\n",
      "Trainable params: 182,529\n",
      "Non-trainable params: 2,258,600\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding, Flatten, Dense\n",
    "from keras import layers\n",
    "\n",
    "model1 = Sequential()\n",
    "e = Embedding(vocab_size, 100, weights=[embedding_matrix], input_length=31, trainable=False)\n",
    "model1.add(e)\n",
    "model1.add(layers.Conv1D(256, 7, activation='relu'))\n",
    "model1.add(layers.MaxPooling1D(pool_size=2, padding=\"valid\"))\n",
    "model1.add(Flatten())\n",
    "model1.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model1.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "print(model1.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_test, y_train, y_test = \\\n",
    "train_test_split(padded_docs, tweets['target'], test_size = 0.25, random_state = 123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "44/44 - 1s - loss: 0.5158 - accuracy: 0.7525 - val_loss: 0.4399 - val_accuracy: 0.8031\n",
      "Epoch 2/50\n",
      "44/44 - 1s - loss: 0.3831 - accuracy: 0.8339 - val_loss: 0.4263 - val_accuracy: 0.8166\n",
      "Epoch 3/50\n",
      "44/44 - 1s - loss: 0.3178 - accuracy: 0.8732 - val_loss: 0.4314 - val_accuracy: 0.8085\n",
      "Epoch 00003: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x3092ba510>"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.callbacks import EarlyStopping\n",
    "callback = EarlyStopping(monitor = 'val_loss', patience = 1, verbose=1)\n",
    "callbacks = [callback]\n",
    "\n",
    "model1.fit(x_train, y_train,\n",
    "          validation_data=(x_test, y_test),\n",
    "          batch_size=128,\n",
    "          epochs=50,\n",
    "          verbose=2,\n",
    "          callbacks=callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding, Flatten, Dense\n",
    "from keras import layers\n",
    "from keras import activations\n",
    "\n",
    "from keras.callbacks import EarlyStopping\n",
    "callback = EarlyStopping(monitor = 'val_loss', patience = 1, verbose=1)\n",
    "callbacks = [callback]\n",
    "\n",
    "def build_model(num_filters, kern_size, pool_sizes):\n",
    "    model1 = Sequential()\n",
    "    e = Embedding(vocab_size, 100, weights=[embedding_matrix], input_length=31, trainable=True)\n",
    "    model1.add(e)\n",
    "    model1.add(layers.Conv1D(num_filters, kern_size, activation='relu'))\n",
    "    model1.add(layers.MaxPooling1D(pool_size=pool_sizes, padding=\"valid\"))\n",
    "    model1.add(Flatten())\n",
    "    model1.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    model1.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    return model1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 5 candidates, totalling 50 fits\n",
      "[CV] pool_sizes=10, num_filters=128, kern_size=7, epochs=15, batch_size=76 \n",
      "Epoch 1/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60/60 [==============================] - 1s 23ms/step - loss: 0.4917 - accuracy: 0.7668 - val_loss: 0.4757 - val_accuracy: 0.7888\n",
      "Epoch 2/15\n",
      "60/60 [==============================] - 1s 20ms/step - loss: 0.3296 - accuracy: 0.8667 - val_loss: 0.4595 - val_accuracy: 0.7789\n",
      "Epoch 3/15\n",
      "60/60 [==============================] - 1s 20ms/step - loss: 0.2402 - accuracy: 0.9138 - val_loss: 0.4631 - val_accuracy: 0.7849\n",
      "Epoch 00003: early stopping\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "[CV]  pool_sizes=10, num_filters=128, kern_size=7, epochs=15, batch_size=76, total=   4.6s\n",
      "[CV] pool_sizes=10, num_filters=128, kern_size=7, epochs=15, batch_size=76 \n",
      "Epoch 1/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    4.6s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60/60 [==============================] - 1s 23ms/step - loss: 0.4955 - accuracy: 0.7639 - val_loss: 0.4721 - val_accuracy: 0.7669\n",
      "Epoch 2/15\n",
      "60/60 [==============================] - 1s 19ms/step - loss: 0.3278 - accuracy: 0.8651 - val_loss: 0.4711 - val_accuracy: 0.7809\n",
      "Epoch 3/15\n",
      "60/60 [==============================] - 1s 20ms/step - loss: 0.2394 - accuracy: 0.9185 - val_loss: 0.4697 - val_accuracy: 0.7849\n",
      "Epoch 4/15\n",
      "60/60 [==============================] - 1s 19ms/step - loss: 0.1688 - accuracy: 0.9502 - val_loss: 0.4880 - val_accuracy: 0.7849\n",
      "Epoch 00004: early stopping\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "[CV]  pool_sizes=10, num_filters=128, kern_size=7, epochs=15, batch_size=76, total=   5.7s\n",
      "[CV] pool_sizes=10, num_filters=128, kern_size=7, epochs=15, batch_size=76 \n",
      "Epoch 1/15\n",
      "60/60 [==============================] - 1s 21ms/step - loss: 0.5022 - accuracy: 0.7610 - val_loss: 0.5122 - val_accuracy: 0.7590\n",
      "Epoch 2/15\n",
      "60/60 [==============================] - 1s 19ms/step - loss: 0.3374 - accuracy: 0.8589 - val_loss: 0.4575 - val_accuracy: 0.7869\n",
      "Epoch 3/15\n",
      "60/60 [==============================] - 1s 19ms/step - loss: 0.2423 - accuracy: 0.9150 - val_loss: 0.4643 - val_accuracy: 0.7789\n",
      "Epoch 00003: early stopping\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "[CV]  pool_sizes=10, num_filters=128, kern_size=7, epochs=15, batch_size=76, total=   4.3s\n",
      "[CV] pool_sizes=10, num_filters=128, kern_size=7, epochs=15, batch_size=76 \n",
      "Epoch 1/15\n",
      "60/60 [==============================] - 1s 21ms/step - loss: 0.5080 - accuracy: 0.7537 - val_loss: 0.5014 - val_accuracy: 0.7829\n",
      "Epoch 2/15\n",
      "60/60 [==============================] - 1s 19ms/step - loss: 0.3376 - accuracy: 0.8636 - val_loss: 0.4665 - val_accuracy: 0.7869\n",
      "Epoch 3/15\n",
      "60/60 [==============================] - 1s 19ms/step - loss: 0.2463 - accuracy: 0.9125 - val_loss: 0.4856 - val_accuracy: 0.7869\n",
      "Epoch 00003: early stopping\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "[CV]  pool_sizes=10, num_filters=128, kern_size=7, epochs=15, batch_size=76, total=   4.3s\n",
      "[CV] pool_sizes=10, num_filters=128, kern_size=7, epochs=15, batch_size=76 \n",
      "Epoch 1/15\n",
      "60/60 [==============================] - 1s 21ms/step - loss: 0.5094 - accuracy: 0.7511 - val_loss: 0.4662 - val_accuracy: 0.7849\n",
      "Epoch 2/15\n",
      "60/60 [==============================] - 1s 20ms/step - loss: 0.3307 - accuracy: 0.8616 - val_loss: 0.4593 - val_accuracy: 0.7928\n",
      "Epoch 3/15\n",
      "60/60 [==============================] - 1s 19ms/step - loss: 0.2406 - accuracy: 0.9176 - val_loss: 0.4485 - val_accuracy: 0.8048\n",
      "Epoch 4/15\n",
      "60/60 [==============================] - 1s 19ms/step - loss: 0.1699 - accuracy: 0.9526 - val_loss: 0.4597 - val_accuracy: 0.8028\n",
      "Epoch 00004: early stopping\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "[CV]  pool_sizes=10, num_filters=128, kern_size=7, epochs=15, batch_size=76, total=   5.5s\n",
      "[CV] pool_sizes=10, num_filters=128, kern_size=7, epochs=15, batch_size=76 \n",
      "Epoch 1/15\n",
      "60/60 [==============================] - 1s 21ms/step - loss: 0.5097 - accuracy: 0.7582 - val_loss: 0.4989 - val_accuracy: 0.7789\n",
      "Epoch 2/15\n",
      "60/60 [==============================] - 1s 19ms/step - loss: 0.3336 - accuracy: 0.8687 - val_loss: 0.4713 - val_accuracy: 0.7968\n",
      "Epoch 3/15\n",
      "60/60 [==============================] - 1s 19ms/step - loss: 0.2415 - accuracy: 0.9154 - val_loss: 0.4778 - val_accuracy: 0.7988\n",
      "Epoch 00003: early stopping\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "[CV]  pool_sizes=10, num_filters=128, kern_size=7, epochs=15, batch_size=76, total=   4.2s\n",
      "[CV] pool_sizes=10, num_filters=128, kern_size=7, epochs=15, batch_size=76 \n",
      "Epoch 1/15\n",
      "60/60 [==============================] - 1s 21ms/step - loss: 0.5079 - accuracy: 0.7500 - val_loss: 0.4729 - val_accuracy: 0.7849\n",
      "Epoch 2/15\n",
      "60/60 [==============================] - 1s 20ms/step - loss: 0.3345 - accuracy: 0.8587 - val_loss: 0.4588 - val_accuracy: 0.7849\n",
      "Epoch 3/15\n",
      "60/60 [==============================] - 1s 19ms/step - loss: 0.2432 - accuracy: 0.9183 - val_loss: 0.4680 - val_accuracy: 0.7968\n",
      "Epoch 00003: early stopping\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "[CV]  pool_sizes=10, num_filters=128, kern_size=7, epochs=15, batch_size=76, total=   4.2s\n",
      "[CV] pool_sizes=10, num_filters=128, kern_size=7, epochs=15, batch_size=76 \n",
      "Epoch 1/15\n",
      "60/60 [==============================] - 1s 21ms/step - loss: 0.4968 - accuracy: 0.7644 - val_loss: 0.4605 - val_accuracy: 0.7988\n",
      "Epoch 2/15\n",
      "60/60 [==============================] - 1s 19ms/step - loss: 0.3286 - accuracy: 0.8632 - val_loss: 0.4452 - val_accuracy: 0.8048\n",
      "Epoch 3/15\n",
      "60/60 [==============================] - 1s 19ms/step - loss: 0.2364 - accuracy: 0.9174 - val_loss: 0.4749 - val_accuracy: 0.7789\n",
      "Epoch 00003: early stopping\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "[CV]  pool_sizes=10, num_filters=128, kern_size=7, epochs=15, batch_size=76, total=   4.2s\n",
      "[CV] pool_sizes=10, num_filters=128, kern_size=7, epochs=15, batch_size=76 \n",
      "Epoch 1/15\n",
      "60/60 [==============================] - 1s 21ms/step - loss: 0.5060 - accuracy: 0.7522 - val_loss: 0.4716 - val_accuracy: 0.7869\n",
      "Epoch 2/15\n",
      "60/60 [==============================] - 1s 19ms/step - loss: 0.3369 - accuracy: 0.8636 - val_loss: 0.4575 - val_accuracy: 0.7829\n",
      "Epoch 3/15\n",
      "60/60 [==============================] - 1s 20ms/step - loss: 0.2456 - accuracy: 0.9097 - val_loss: 0.4608 - val_accuracy: 0.7869\n",
      "Epoch 00003: early stopping\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "[CV]  pool_sizes=10, num_filters=128, kern_size=7, epochs=15, batch_size=76, total=   4.3s\n",
      "[CV] pool_sizes=10, num_filters=128, kern_size=7, epochs=15, batch_size=76 \n",
      "Epoch 1/15\n",
      "60/60 [==============================] - 1s 21ms/step - loss: 0.4991 - accuracy: 0.7569 - val_loss: 0.4033 - val_accuracy: 0.8367\n",
      "Epoch 2/15\n",
      "60/60 [==============================] - 1s 20ms/step - loss: 0.3286 - accuracy: 0.8632 - val_loss: 0.3855 - val_accuracy: 0.8406\n",
      "Epoch 3/15\n",
      "60/60 [==============================] - 1s 20ms/step - loss: 0.2387 - accuracy: 0.9165 - val_loss: 0.3960 - val_accuracy: 0.8367\n",
      "Epoch 00003: early stopping\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "[CV]  pool_sizes=10, num_filters=128, kern_size=7, epochs=15, batch_size=76, total=   4.3s\n",
      "[CV] pool_sizes=10, num_filters=128, kern_size=3, epochs=15, batch_size=76 \n",
      "Epoch 1/15\n",
      "60/60 [==============================] - 1s 19ms/step - loss: 0.5115 - accuracy: 0.7511 - val_loss: 0.4963 - val_accuracy: 0.7709\n",
      "Epoch 2/15\n",
      "60/60 [==============================] - 1s 18ms/step - loss: 0.3768 - accuracy: 0.8403 - val_loss: 0.4617 - val_accuracy: 0.7968\n",
      "Epoch 3/15\n",
      "60/60 [==============================] - 1s 19ms/step - loss: 0.2960 - accuracy: 0.8828 - val_loss: 0.4437 - val_accuracy: 0.7869\n",
      "Epoch 4/15\n",
      "60/60 [==============================] - 1s 19ms/step - loss: 0.2306 - accuracy: 0.9207 - val_loss: 0.4477 - val_accuracy: 0.7869\n",
      "Epoch 00004: early stopping\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "[CV]  pool_sizes=10, num_filters=128, kern_size=3, epochs=15, batch_size=76, total=   5.1s\n",
      "[CV] pool_sizes=10, num_filters=128, kern_size=3, epochs=15, batch_size=76 \n",
      "Epoch 1/15\n",
      "60/60 [==============================] - 1s 19ms/step - loss: 0.5126 - accuracy: 0.7517 - val_loss: 0.4979 - val_accuracy: 0.7510\n",
      "Epoch 2/15\n",
      "60/60 [==============================] - 1s 18ms/step - loss: 0.3700 - accuracy: 0.8396 - val_loss: 0.4571 - val_accuracy: 0.7809\n",
      "Epoch 3/15\n",
      "60/60 [==============================] - 1s 19ms/step - loss: 0.2943 - accuracy: 0.8853 - val_loss: 0.4512 - val_accuracy: 0.7888\n",
      "Epoch 4/15\n",
      "60/60 [==============================] - 1s 19ms/step - loss: 0.2272 - accuracy: 0.9169 - val_loss: 0.4611 - val_accuracy: 0.7928\n",
      "Epoch 00004: early stopping\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "[CV]  pool_sizes=10, num_filters=128, kern_size=3, epochs=15, batch_size=76, total=   5.2s\n",
      "[CV] pool_sizes=10, num_filters=128, kern_size=3, epochs=15, batch_size=76 \n",
      "Epoch 1/15\n",
      "60/60 [==============================] - 1s 19ms/step - loss: 0.5801 - accuracy: 0.7085 - val_loss: 0.5022 - val_accuracy: 0.7610\n",
      "Epoch 2/15\n",
      "60/60 [==============================] - 1s 18ms/step - loss: 0.3847 - accuracy: 0.8365 - val_loss: 0.4718 - val_accuracy: 0.7849\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/15\n",
      "60/60 [==============================] - 1s 18ms/step - loss: 0.3063 - accuracy: 0.8850 - val_loss: 0.4657 - val_accuracy: 0.7908\n",
      "Epoch 4/15\n",
      "60/60 [==============================] - 1s 18ms/step - loss: 0.2423 - accuracy: 0.9112 - val_loss: 0.4574 - val_accuracy: 0.7948\n",
      "Epoch 5/15\n",
      "60/60 [==============================] - 1s 19ms/step - loss: 0.1822 - accuracy: 0.9449 - val_loss: 0.4769 - val_accuracy: 0.7988\n",
      "Epoch 00005: early stopping\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "[CV]  pool_sizes=10, num_filters=128, kern_size=3, epochs=15, batch_size=76, total=   6.2s\n",
      "[CV] pool_sizes=10, num_filters=128, kern_size=3, epochs=15, batch_size=76 \n",
      "Epoch 1/15\n",
      "60/60 [==============================] - 1s 20ms/step - loss: 0.5132 - accuracy: 0.7435 - val_loss: 0.4919 - val_accuracy: 0.7789\n",
      "Epoch 2/15\n",
      "60/60 [==============================] - 1s 18ms/step - loss: 0.3721 - accuracy: 0.8396 - val_loss: 0.4607 - val_accuracy: 0.8068\n",
      "Epoch 3/15\n",
      "60/60 [==============================] - 1s 18ms/step - loss: 0.2926 - accuracy: 0.8895 - val_loss: 0.4621 - val_accuracy: 0.8008\n",
      "Epoch 00003: early stopping\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "[CV]  pool_sizes=10, num_filters=128, kern_size=3, epochs=15, batch_size=76, total=   9.7s\n",
      "[CV] pool_sizes=10, num_filters=128, kern_size=3, epochs=15, batch_size=76 \n",
      "Epoch 1/15\n",
      "60/60 [==============================] - 1s 19ms/step - loss: 0.5286 - accuracy: 0.7247 - val_loss: 0.5142 - val_accuracy: 0.7610\n",
      "Epoch 2/15\n",
      "60/60 [==============================] - 1s 17ms/step - loss: 0.3748 - accuracy: 0.8414 - val_loss: 0.4552 - val_accuracy: 0.7988\n",
      "Epoch 3/15\n",
      "60/60 [==============================] - 1s 17ms/step - loss: 0.2947 - accuracy: 0.8855 - val_loss: 0.4447 - val_accuracy: 0.7968\n",
      "Epoch 4/15\n",
      "60/60 [==============================] - 1s 18ms/step - loss: 0.2284 - accuracy: 0.9203 - val_loss: 0.4633 - val_accuracy: 0.8008\n",
      "Epoch 00004: early stopping\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "[CV]  pool_sizes=10, num_filters=128, kern_size=3, epochs=15, batch_size=76, total=   5.1s\n",
      "[CV] pool_sizes=10, num_filters=128, kern_size=3, epochs=15, batch_size=76 \n",
      "Epoch 1/15\n",
      "60/60 [==============================] - 1s 20ms/step - loss: 0.5126 - accuracy: 0.7544 - val_loss: 0.5009 - val_accuracy: 0.7669\n",
      "Epoch 2/15\n",
      "60/60 [==============================] - 1s 18ms/step - loss: 0.3723 - accuracy: 0.8441 - val_loss: 0.4718 - val_accuracy: 0.7948\n",
      "Epoch 3/15\n",
      "60/60 [==============================] - 1s 19ms/step - loss: 0.2953 - accuracy: 0.8875 - val_loss: 0.4616 - val_accuracy: 0.8048\n",
      "Epoch 4/15\n",
      "60/60 [==============================] - 1s 19ms/step - loss: 0.2276 - accuracy: 0.9187 - val_loss: 0.4619 - val_accuracy: 0.8028\n",
      "Epoch 00004: early stopping\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "[CV]  pool_sizes=10, num_filters=128, kern_size=3, epochs=15, batch_size=76, total=   5.3s\n",
      "[CV] pool_sizes=10, num_filters=128, kern_size=3, epochs=15, batch_size=76 \n",
      "Epoch 1/15\n",
      "60/60 [==============================] - 1s 19ms/step - loss: 0.5093 - accuracy: 0.7553 - val_loss: 0.5077 - val_accuracy: 0.7709\n",
      "Epoch 2/15\n",
      "60/60 [==============================] - 1s 18ms/step - loss: 0.3637 - accuracy: 0.8479 - val_loss: 0.4651 - val_accuracy: 0.7869\n",
      "Epoch 3/15\n",
      "60/60 [==============================] - 1s 19ms/step - loss: 0.2857 - accuracy: 0.8919 - val_loss: 0.4591 - val_accuracy: 0.7988\n",
      "Epoch 4/15\n",
      "60/60 [==============================] - 1s 19ms/step - loss: 0.2234 - accuracy: 0.9218 - val_loss: 0.4575 - val_accuracy: 0.7988\n",
      "Epoch 5/15\n",
      "60/60 [==============================] - 1s 19ms/step - loss: 0.1669 - accuracy: 0.9471 - val_loss: 0.4741 - val_accuracy: 0.8008\n",
      "Epoch 00005: early stopping\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "[CV]  pool_sizes=10, num_filters=128, kern_size=3, epochs=15, batch_size=76, total=   6.4s\n",
      "[CV] pool_sizes=10, num_filters=128, kern_size=3, epochs=15, batch_size=76 \n",
      "Epoch 1/15\n",
      "60/60 [==============================] - 1s 20ms/step - loss: 0.6079 - accuracy: 0.6942 - val_loss: 0.5075 - val_accuracy: 0.7450\n",
      "Epoch 2/15\n",
      "60/60 [==============================] - 1s 20ms/step - loss: 0.3901 - accuracy: 0.8350 - val_loss: 0.4558 - val_accuracy: 0.7908\n",
      "Epoch 3/15\n",
      "60/60 [==============================] - 1s 18ms/step - loss: 0.3107 - accuracy: 0.8778 - val_loss: 0.4486 - val_accuracy: 0.8068\n",
      "Epoch 4/15\n",
      "60/60 [==============================] - 1s 18ms/step - loss: 0.2450 - accuracy: 0.9092 - val_loss: 0.4352 - val_accuracy: 0.8167\n",
      "Epoch 5/15\n",
      "60/60 [==============================] - 1s 19ms/step - loss: 0.1871 - accuracy: 0.9426 - val_loss: 0.4385 - val_accuracy: 0.8187\n",
      "Epoch 00005: early stopping\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "[CV]  pool_sizes=10, num_filters=128, kern_size=3, epochs=15, batch_size=76, total=   6.4s\n",
      "[CV] pool_sizes=10, num_filters=128, kern_size=3, epochs=15, batch_size=76 \n",
      "Epoch 1/15\n",
      "60/60 [==============================] - 1s 19ms/step - loss: 0.5210 - accuracy: 0.7447 - val_loss: 0.4984 - val_accuracy: 0.7709\n",
      "Epoch 2/15\n",
      "60/60 [==============================] - 1s 17ms/step - loss: 0.3715 - accuracy: 0.8437 - val_loss: 0.4714 - val_accuracy: 0.7888\n",
      "Epoch 3/15\n",
      "60/60 [==============================] - 1s 18ms/step - loss: 0.2919 - accuracy: 0.8842 - val_loss: 0.4653 - val_accuracy: 0.7948\n",
      "Epoch 4/15\n",
      "60/60 [==============================] - 1s 17ms/step - loss: 0.2258 - accuracy: 0.9192 - val_loss: 0.4729 - val_accuracy: 0.7888\n",
      "Epoch 00004: early stopping\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "[CV]  pool_sizes=10, num_filters=128, kern_size=3, epochs=15, batch_size=76, total=   4.9s\n",
      "[CV] pool_sizes=10, num_filters=128, kern_size=3, epochs=15, batch_size=76 \n",
      "Epoch 1/15\n",
      "60/60 [==============================] - 1s 18ms/step - loss: 0.5191 - accuracy: 0.7540 - val_loss: 0.4134 - val_accuracy: 0.8287\n",
      "Epoch 2/15\n",
      "60/60 [==============================] - 1s 19ms/step - loss: 0.3786 - accuracy: 0.8353 - val_loss: 0.4061 - val_accuracy: 0.8406\n",
      "Epoch 3/15\n",
      "60/60 [==============================] - 1s 18ms/step - loss: 0.3028 - accuracy: 0.8758 - val_loss: 0.3771 - val_accuracy: 0.8426\n",
      "Epoch 4/15\n",
      "60/60 [==============================] - 1s 19ms/step - loss: 0.2370 - accuracy: 0.9181 - val_loss: 0.3775 - val_accuracy: 0.8367\n",
      "Epoch 00004: early stopping\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "[CV]  pool_sizes=10, num_filters=128, kern_size=3, epochs=15, batch_size=76, total=   5.1s\n",
      "[CV] pool_sizes=2, num_filters=256, kern_size=3, epochs=15, batch_size=76 \n",
      "Epoch 1/15\n",
      "60/60 [==============================] - 1s 21ms/step - loss: 0.5060 - accuracy: 0.7557 - val_loss: 0.4801 - val_accuracy: 0.7829\n",
      "Epoch 2/15\n",
      "60/60 [==============================] - 1s 21ms/step - loss: 0.3580 - accuracy: 0.8492 - val_loss: 0.4646 - val_accuracy: 0.7789\n",
      "Epoch 3/15\n",
      "60/60 [==============================] - 1s 20ms/step - loss: 0.2678 - accuracy: 0.8977 - val_loss: 0.4752 - val_accuracy: 0.7928\n",
      "Epoch 00003: early stopping\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "[CV]  pool_sizes=2, num_filters=256, kern_size=3, epochs=15, batch_size=76, total=   4.4s\n",
      "[CV] pool_sizes=2, num_filters=256, kern_size=3, epochs=15, batch_size=76 \n",
      "Epoch 1/15\n",
      "60/60 [==============================] - 1s 22ms/step - loss: 0.5201 - accuracy: 0.7473 - val_loss: 0.4926 - val_accuracy: 0.7729\n",
      "Epoch 2/15\n",
      "60/60 [==============================] - 1s 20ms/step - loss: 0.3622 - accuracy: 0.8454 - val_loss: 0.4782 - val_accuracy: 0.7849\n",
      "Epoch 3/15\n",
      "60/60 [==============================] - 1s 25ms/step - loss: 0.2844 - accuracy: 0.8870 - val_loss: 0.4782 - val_accuracy: 0.7709\n",
      "Epoch 4/15\n",
      "60/60 [==============================] - 1s 24ms/step - loss: 0.1968 - accuracy: 0.9331 - val_loss: 0.5040 - val_accuracy: 0.7709\n",
      "Epoch 00004: early stopping\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "[CV]  pool_sizes=2, num_filters=256, kern_size=3, epochs=15, batch_size=76, total=   6.3s\n",
      "[CV] pool_sizes=2, num_filters=256, kern_size=3, epochs=15, batch_size=76 \n",
      "Epoch 1/15\n",
      "60/60 [==============================] - 1s 23ms/step - loss: 0.5180 - accuracy: 0.7455 - val_loss: 0.5027 - val_accuracy: 0.7809\n",
      "Epoch 2/15\n",
      "60/60 [==============================] - 1s 23ms/step - loss: 0.3614 - accuracy: 0.8456 - val_loss: 0.4681 - val_accuracy: 0.8028\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/15\n",
      "60/60 [==============================] - 1s 24ms/step - loss: 0.2750 - accuracy: 0.8939 - val_loss: 0.4987 - val_accuracy: 0.8028\n",
      "Epoch 00003: early stopping\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "[CV]  pool_sizes=2, num_filters=256, kern_size=3, epochs=15, batch_size=76, total=   4.9s\n",
      "[CV] pool_sizes=2, num_filters=256, kern_size=3, epochs=15, batch_size=76 \n",
      "Epoch 1/15\n",
      "60/60 [==============================] - 1s 24ms/step - loss: 0.5166 - accuracy: 0.7486 - val_loss: 0.4811 - val_accuracy: 0.7888\n",
      "Epoch 2/15\n",
      "60/60 [==============================] - 1s 21ms/step - loss: 0.3601 - accuracy: 0.8467 - val_loss: 0.4712 - val_accuracy: 0.7749\n",
      "Epoch 3/15\n",
      "60/60 [==============================] - 2s 26ms/step - loss: 0.2705 - accuracy: 0.8930 - val_loss: 0.4983 - val_accuracy: 0.7869\n",
      "Epoch 00003: early stopping\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "[CV]  pool_sizes=2, num_filters=256, kern_size=3, epochs=15, batch_size=76, total=   5.0s\n",
      "[CV] pool_sizes=2, num_filters=256, kern_size=3, epochs=15, batch_size=76 \n",
      "Epoch 1/15\n",
      "60/60 [==============================] - 2s 25ms/step - loss: 0.5192 - accuracy: 0.7477 - val_loss: 0.4766 - val_accuracy: 0.7829\n",
      "Epoch 2/15\n",
      "60/60 [==============================] - 1s 25ms/step - loss: 0.3603 - accuracy: 0.8443 - val_loss: 0.4629 - val_accuracy: 0.7928\n",
      "Epoch 3/15\n",
      "60/60 [==============================] - 1s 22ms/step - loss: 0.2690 - accuracy: 0.8968 - val_loss: 0.4756 - val_accuracy: 0.7769\n",
      "Epoch 00003: early stopping\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "[CV]  pool_sizes=2, num_filters=256, kern_size=3, epochs=15, batch_size=76, total=   5.1s\n",
      "[CV] pool_sizes=2, num_filters=256, kern_size=3, epochs=15, batch_size=76 \n",
      "Epoch 1/15\n",
      "60/60 [==============================] - 1s 23ms/step - loss: 0.5131 - accuracy: 0.7531 - val_loss: 0.5741 - val_accuracy: 0.7371\n",
      "Epoch 2/15\n",
      "60/60 [==============================] - 1s 21ms/step - loss: 0.3669 - accuracy: 0.8390 - val_loss: 0.4812 - val_accuracy: 0.7928\n",
      "Epoch 3/15\n",
      "60/60 [==============================] - 1s 22ms/step - loss: 0.2676 - accuracy: 0.8973 - val_loss: 0.4765 - val_accuracy: 0.7789\n",
      "Epoch 4/15\n",
      "60/60 [==============================] - 1s 22ms/step - loss: 0.1893 - accuracy: 0.9353 - val_loss: 0.5238 - val_accuracy: 0.7869\n",
      "Epoch 00004: early stopping\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "[CV]  pool_sizes=2, num_filters=256, kern_size=3, epochs=15, batch_size=76, total=   6.0s\n",
      "[CV] pool_sizes=2, num_filters=256, kern_size=3, epochs=15, batch_size=76 \n",
      "Epoch 1/15\n",
      "60/60 [==============================] - 2s 29ms/step - loss: 0.5141 - accuracy: 0.7571 - val_loss: 0.4801 - val_accuracy: 0.7669\n",
      "Epoch 2/15\n",
      "60/60 [==============================] - 1s 21ms/step - loss: 0.3597 - accuracy: 0.8459 - val_loss: 0.4572 - val_accuracy: 0.7888\n",
      "Epoch 3/15\n",
      "60/60 [==============================] - 1s 20ms/step - loss: 0.2673 - accuracy: 0.8953 - val_loss: 0.5136 - val_accuracy: 0.7829\n",
      "Epoch 00003: early stopping\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "[CV]  pool_sizes=2, num_filters=256, kern_size=3, epochs=15, batch_size=76, total=   4.9s\n",
      "[CV] pool_sizes=2, num_filters=256, kern_size=3, epochs=15, batch_size=76 \n",
      "Epoch 1/15\n",
      "60/60 [==============================] - 1s 20ms/step - loss: 0.5391 - accuracy: 0.7354 - val_loss: 0.5030 - val_accuracy: 0.7749\n",
      "Epoch 2/15\n",
      "60/60 [==============================] - 1s 20ms/step - loss: 0.3613 - accuracy: 0.8472 - val_loss: 0.4742 - val_accuracy: 0.7849\n",
      "Epoch 3/15\n",
      "60/60 [==============================] - 1s 20ms/step - loss: 0.2722 - accuracy: 0.8935 - val_loss: 0.4721 - val_accuracy: 0.7968\n",
      "Epoch 4/15\n",
      "60/60 [==============================] - 1s 20ms/step - loss: 0.1908 - accuracy: 0.9345 - val_loss: 0.4963 - val_accuracy: 0.7908\n",
      "Epoch 00004: early stopping\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "[CV]  pool_sizes=2, num_filters=256, kern_size=3, epochs=15, batch_size=76, total=   5.5s\n",
      "[CV] pool_sizes=2, num_filters=256, kern_size=3, epochs=15, batch_size=76 \n",
      "Epoch 1/15\n",
      "60/60 [==============================] - 1s 21ms/step - loss: 0.5287 - accuracy: 0.7378 - val_loss: 0.5145 - val_accuracy: 0.7789\n",
      "Epoch 2/15\n",
      "60/60 [==============================] - 1s 21ms/step - loss: 0.3708 - accuracy: 0.8448 - val_loss: 0.4743 - val_accuracy: 0.7948\n",
      "Epoch 3/15\n",
      "60/60 [==============================] - 1s 19ms/step - loss: 0.2799 - accuracy: 0.8913 - val_loss: 0.4831 - val_accuracy: 0.7869\n",
      "Epoch 00003: early stopping\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "[CV]  pool_sizes=2, num_filters=256, kern_size=3, epochs=15, batch_size=76, total=   4.3s\n",
      "[CV] pool_sizes=2, num_filters=256, kern_size=3, epochs=15, batch_size=76 \n",
      "Epoch 1/15\n",
      "60/60 [==============================] - 1s 22ms/step - loss: 0.5171 - accuracy: 0.7487 - val_loss: 0.4136 - val_accuracy: 0.8187\n",
      "Epoch 2/15\n",
      "60/60 [==============================] - 1s 19ms/step - loss: 0.3654 - accuracy: 0.8408 - val_loss: 0.3971 - val_accuracy: 0.8386\n",
      "Epoch 3/15\n",
      "60/60 [==============================] - 1s 19ms/step - loss: 0.2778 - accuracy: 0.8882 - val_loss: 0.3963 - val_accuracy: 0.8486\n",
      "Epoch 4/15\n",
      "60/60 [==============================] - 1s 19ms/step - loss: 0.1940 - accuracy: 0.9345 - val_loss: 0.4113 - val_accuracy: 0.8446\n",
      "Epoch 00004: early stopping\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "[CV]  pool_sizes=2, num_filters=256, kern_size=3, epochs=15, batch_size=76, total=   5.4s\n",
      "[CV] pool_sizes=10, num_filters=128, kern_size=7, epochs=15, batch_size=88 \n",
      "Epoch 1/15\n",
      "52/52 [==============================] - 1s 21ms/step - loss: 0.5080 - accuracy: 0.7493 - val_loss: 0.4879 - val_accuracy: 0.7849\n",
      "Epoch 2/15\n",
      "52/52 [==============================] - 1s 20ms/step - loss: 0.3366 - accuracy: 0.8640 - val_loss: 0.4546 - val_accuracy: 0.7888\n",
      "Epoch 3/15\n",
      "52/52 [==============================] - 1s 20ms/step - loss: 0.2508 - accuracy: 0.9125 - val_loss: 0.4655 - val_accuracy: 0.7948\n",
      "Epoch 00003: early stopping\n",
      "7/7 [==============================] - 0s 2ms/step\n",
      "[CV]  pool_sizes=10, num_filters=128, kern_size=7, epochs=15, batch_size=88, total=   3.9s\n",
      "[CV] pool_sizes=10, num_filters=128, kern_size=7, epochs=15, batch_size=88 \n",
      "Epoch 1/15\n",
      "52/52 [==============================] - 1s 21ms/step - loss: 0.5166 - accuracy: 0.7575 - val_loss: 0.4718 - val_accuracy: 0.7749\n",
      "Epoch 2/15\n",
      "52/52 [==============================] - 1s 19ms/step - loss: 0.3426 - accuracy: 0.8594 - val_loss: 0.4706 - val_accuracy: 0.7928\n",
      "Epoch 3/15\n",
      "52/52 [==============================] - 1s 20ms/step - loss: 0.2569 - accuracy: 0.9092 - val_loss: 0.4712 - val_accuracy: 0.7849\n",
      "Epoch 00003: early stopping\n",
      "7/7 [==============================] - 0s 2ms/step\n",
      "[CV]  pool_sizes=10, num_filters=128, kern_size=7, epochs=15, batch_size=88, total=   3.8s\n",
      "[CV] pool_sizes=10, num_filters=128, kern_size=7, epochs=15, batch_size=88 \n",
      "Epoch 1/15\n",
      "52/52 [==============================] - 1s 21ms/step - loss: 0.5067 - accuracy: 0.7604 - val_loss: 0.4883 - val_accuracy: 0.7849\n",
      "Epoch 2/15\n",
      "52/52 [==============================] - 1s 19ms/step - loss: 0.3418 - accuracy: 0.8602 - val_loss: 0.4789 - val_accuracy: 0.7928\n",
      "Epoch 3/15\n",
      "52/52 [==============================] - 1s 19ms/step - loss: 0.2554 - accuracy: 0.9065 - val_loss: 0.4756 - val_accuracy: 0.7789\n",
      "Epoch 4/15\n",
      "52/52 [==============================] - 1s 19ms/step - loss: 0.1863 - accuracy: 0.9415 - val_loss: 0.4892 - val_accuracy: 0.7888\n",
      "Epoch 00004: early stopping\n",
      "7/7 [==============================] - 0s 3ms/step\n",
      "[CV]  pool_sizes=10, num_filters=128, kern_size=7, epochs=15, batch_size=88, total=   4.8s\n",
      "[CV] pool_sizes=10, num_filters=128, kern_size=7, epochs=15, batch_size=88 \n",
      "Epoch 1/15\n",
      "52/52 [==============================] - 1s 20ms/step - loss: 0.4983 - accuracy: 0.7641 - val_loss: 0.5043 - val_accuracy: 0.7709\n",
      "Epoch 2/15\n",
      "52/52 [==============================] - 1s 19ms/step - loss: 0.3425 - accuracy: 0.8583 - val_loss: 0.4758 - val_accuracy: 0.7888\n",
      "Epoch 3/15\n",
      "52/52 [==============================] - 1s 19ms/step - loss: 0.2551 - accuracy: 0.9090 - val_loss: 0.4726 - val_accuracy: 0.7908\n",
      "Epoch 4/15\n",
      "52/52 [==============================] - 1s 19ms/step - loss: 0.1874 - accuracy: 0.9413 - val_loss: 0.4810 - val_accuracy: 0.7869\n",
      "Epoch 00004: early stopping\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 3ms/step\n",
      "[CV]  pool_sizes=10, num_filters=128, kern_size=7, epochs=15, batch_size=88, total=   4.7s\n",
      "[CV] pool_sizes=10, num_filters=128, kern_size=7, epochs=15, batch_size=88 \n",
      "Epoch 1/15\n",
      "52/52 [==============================] - 1s 20ms/step - loss: 0.5077 - accuracy: 0.7457 - val_loss: 0.5007 - val_accuracy: 0.7709\n",
      "Epoch 2/15\n",
      "52/52 [==============================] - 1s 19ms/step - loss: 0.3419 - accuracy: 0.8609 - val_loss: 0.5072 - val_accuracy: 0.7709\n",
      "Epoch 00002: early stopping\n",
      "7/7 [==============================] - 0s 2ms/step\n",
      "[CV]  pool_sizes=10, num_filters=128, kern_size=7, epochs=15, batch_size=88, total=   2.7s\n",
      "[CV] pool_sizes=10, num_filters=128, kern_size=7, epochs=15, batch_size=88 \n",
      "Epoch 1/15\n",
      "52/52 [==============================] - 1s 20ms/step - loss: 0.4981 - accuracy: 0.7664 - val_loss: 0.4805 - val_accuracy: 0.7749\n",
      "Epoch 2/15\n",
      "52/52 [==============================] - 1s 19ms/step - loss: 0.3421 - accuracy: 0.8623 - val_loss: 0.5004 - val_accuracy: 0.7769\n",
      "Epoch 00002: early stopping\n",
      "7/7 [==============================] - 0s 2ms/step\n",
      "[CV]  pool_sizes=10, num_filters=128, kern_size=7, epochs=15, batch_size=88, total=   2.7s\n",
      "[CV] pool_sizes=10, num_filters=128, kern_size=7, epochs=15, batch_size=88 \n",
      "Epoch 1/15\n",
      "52/52 [==============================] - 1s 20ms/step - loss: 0.5427 - accuracy: 0.7188 - val_loss: 0.5008 - val_accuracy: 0.7809\n",
      "Epoch 2/15\n",
      "52/52 [==============================] - 1s 19ms/step - loss: 0.3476 - accuracy: 0.8516 - val_loss: 0.4583 - val_accuracy: 0.7968\n",
      "Epoch 3/15\n",
      "52/52 [==============================] - 1s 19ms/step - loss: 0.2590 - accuracy: 0.9070 - val_loss: 0.4550 - val_accuracy: 0.7908\n",
      "Epoch 4/15\n",
      "52/52 [==============================] - 1s 19ms/step - loss: 0.1890 - accuracy: 0.9398 - val_loss: 0.4651 - val_accuracy: 0.7888\n",
      "Epoch 00004: early stopping\n",
      "7/7 [==============================] - 0s 3ms/step\n",
      "[CV]  pool_sizes=10, num_filters=128, kern_size=7, epochs=15, batch_size=88, total=   4.7s\n",
      "[CV] pool_sizes=10, num_filters=128, kern_size=7, epochs=15, batch_size=88 \n",
      "Epoch 1/15\n",
      "52/52 [==============================] - 1s 20ms/step - loss: 0.5021 - accuracy: 0.7677 - val_loss: 0.4819 - val_accuracy: 0.7928\n",
      "Epoch 2/15\n",
      "52/52 [==============================] - 1s 19ms/step - loss: 0.3325 - accuracy: 0.8671 - val_loss: 0.4635 - val_accuracy: 0.7948\n",
      "Epoch 3/15\n",
      "52/52 [==============================] - 1s 19ms/step - loss: 0.2423 - accuracy: 0.9170 - val_loss: 0.4658 - val_accuracy: 0.7948\n",
      "Epoch 00003: early stopping\n",
      "7/7 [==============================] - 0s 3ms/step\n",
      "[CV]  pool_sizes=10, num_filters=128, kern_size=7, epochs=15, batch_size=88, total=   4.7s\n",
      "[CV] pool_sizes=10, num_filters=128, kern_size=7, epochs=15, batch_size=88 \n",
      "Epoch 1/15\n",
      "52/52 [==============================] - 1s 20ms/step - loss: 0.5316 - accuracy: 0.7329 - val_loss: 0.4998 - val_accuracy: 0.7729\n",
      "Epoch 2/15\n",
      "52/52 [==============================] - 1s 19ms/step - loss: 0.3482 - accuracy: 0.8552 - val_loss: 0.4798 - val_accuracy: 0.7789\n",
      "Epoch 3/15\n",
      "52/52 [==============================] - 1s 19ms/step - loss: 0.2639 - accuracy: 0.9037 - val_loss: 0.4759 - val_accuracy: 0.7809\n",
      "Epoch 4/15\n",
      "52/52 [==============================] - 1s 19ms/step - loss: 0.1982 - accuracy: 0.9360 - val_loss: 0.4892 - val_accuracy: 0.7869\n",
      "Epoch 00004: early stopping\n",
      "7/7 [==============================] - 0s 2ms/step\n",
      "[CV]  pool_sizes=10, num_filters=128, kern_size=7, epochs=15, batch_size=88, total=   4.7s\n",
      "[CV] pool_sizes=10, num_filters=128, kern_size=7, epochs=15, batch_size=88 \n",
      "Epoch 1/15\n",
      "52/52 [==============================] - 1s 20ms/step - loss: 0.5148 - accuracy: 0.7504 - val_loss: 0.4096 - val_accuracy: 0.8227\n",
      "Epoch 2/15\n",
      "52/52 [==============================] - 1s 18ms/step - loss: 0.3517 - accuracy: 0.8565 - val_loss: 0.3849 - val_accuracy: 0.8486\n",
      "Epoch 3/15\n",
      "52/52 [==============================] - 1s 19ms/step - loss: 0.2609 - accuracy: 0.9037 - val_loss: 0.3928 - val_accuracy: 0.8526\n",
      "Epoch 00003: early stopping\n",
      "7/7 [==============================] - 0s 2ms/step\n",
      "[CV]  pool_sizes=10, num_filters=128, kern_size=7, epochs=15, batch_size=88, total=   3.7s\n",
      "[CV] pool_sizes=10, num_filters=256, kern_size=3, epochs=15, batch_size=88 \n",
      "Epoch 1/15\n",
      "52/52 [==============================] - 1s 20ms/step - loss: 0.5166 - accuracy: 0.7433 - val_loss: 0.4817 - val_accuracy: 0.7829\n",
      "Epoch 2/15\n",
      "52/52 [==============================] - 1s 19ms/step - loss: 0.3627 - accuracy: 0.8463 - val_loss: 0.4492 - val_accuracy: 0.7908\n",
      "Epoch 3/15\n",
      "52/52 [==============================] - 1s 19ms/step - loss: 0.2875 - accuracy: 0.8879 - val_loss: 0.4448 - val_accuracy: 0.7888\n",
      "Epoch 4/15\n",
      "52/52 [==============================] - 1s 19ms/step - loss: 0.2178 - accuracy: 0.9245 - val_loss: 0.4584 - val_accuracy: 0.8068\n",
      "Epoch 00004: early stopping\n",
      "7/7 [==============================] - 0s 2ms/step\n",
      "[CV]  pool_sizes=10, num_filters=256, kern_size=3, epochs=15, batch_size=88, total=   4.7s\n",
      "[CV] pool_sizes=10, num_filters=256, kern_size=3, epochs=15, batch_size=88 \n",
      "Epoch 1/15\n",
      "52/52 [==============================] - 1s 22ms/step - loss: 0.5133 - accuracy: 0.7442 - val_loss: 0.4944 - val_accuracy: 0.7709\n",
      "Epoch 2/15\n",
      "52/52 [==============================] - 1s 19ms/step - loss: 0.3608 - accuracy: 0.8472 - val_loss: 0.4670 - val_accuracy: 0.7988\n",
      "Epoch 3/15\n",
      "52/52 [==============================] - 1s 19ms/step - loss: 0.2838 - accuracy: 0.8890 - val_loss: 0.4593 - val_accuracy: 0.7948\n",
      "Epoch 4/15\n",
      "52/52 [==============================] - 1s 19ms/step - loss: 0.2171 - accuracy: 0.9256 - val_loss: 0.4727 - val_accuracy: 0.7849\n",
      "Epoch 00004: early stopping\n",
      "7/7 [==============================] - 0s 2ms/step\n",
      "[CV]  pool_sizes=10, num_filters=256, kern_size=3, epochs=15, batch_size=88, total=   4.8s\n",
      "[CV] pool_sizes=10, num_filters=256, kern_size=3, epochs=15, batch_size=88 \n",
      "Epoch 1/15\n",
      "52/52 [==============================] - 1s 20ms/step - loss: 0.5163 - accuracy: 0.7491 - val_loss: 0.5087 - val_accuracy: 0.7709\n",
      "Epoch 2/15\n",
      "52/52 [==============================] - 1s 19ms/step - loss: 0.3636 - accuracy: 0.8494 - val_loss: 0.4832 - val_accuracy: 0.7928\n",
      "Epoch 3/15\n",
      "52/52 [==============================] - 1s 19ms/step - loss: 0.2870 - accuracy: 0.8908 - val_loss: 0.4756 - val_accuracy: 0.7968\n",
      "Epoch 4/15\n",
      "52/52 [==============================] - 1s 20ms/step - loss: 0.2218 - accuracy: 0.9214 - val_loss: 0.4858 - val_accuracy: 0.7968\n",
      "Epoch 00004: early stopping\n",
      "7/7 [==============================] - 0s 2ms/step\n",
      "[CV]  pool_sizes=10, num_filters=256, kern_size=3, epochs=15, batch_size=88, total=   4.8s\n",
      "[CV] pool_sizes=10, num_filters=256, kern_size=3, epochs=15, batch_size=88 \n",
      "Epoch 1/15\n",
      "52/52 [==============================] - 1s 20ms/step - loss: 0.5119 - accuracy: 0.7457 - val_loss: 0.4829 - val_accuracy: 0.7729\n",
      "Epoch 2/15\n",
      "52/52 [==============================] - 1s 19ms/step - loss: 0.3625 - accuracy: 0.8423 - val_loss: 0.4554 - val_accuracy: 0.7928\n",
      "Epoch 3/15\n",
      "52/52 [==============================] - 1s 19ms/step - loss: 0.2811 - accuracy: 0.8926 - val_loss: 0.4549 - val_accuracy: 0.7888\n",
      "Epoch 4/15\n",
      "52/52 [==============================] - 1s 19ms/step - loss: 0.2148 - accuracy: 0.9262 - val_loss: 0.4525 - val_accuracy: 0.7968\n",
      "Epoch 5/15\n",
      "52/52 [==============================] - 1s 21ms/step - loss: 0.1549 - accuracy: 0.9544 - val_loss: 0.4710 - val_accuracy: 0.7968\n",
      "Epoch 00005: early stopping\n",
      "7/7 [==============================] - 0s 2ms/step\n",
      "[CV]  pool_sizes=10, num_filters=256, kern_size=3, epochs=15, batch_size=88, total=   5.8s\n",
      "[CV] pool_sizes=10, num_filters=256, kern_size=3, epochs=15, batch_size=88 \n",
      "Epoch 1/15\n",
      "52/52 [==============================] - 1s 20ms/step - loss: 0.5014 - accuracy: 0.7524 - val_loss: 0.4759 - val_accuracy: 0.7809\n",
      "Epoch 2/15\n",
      "52/52 [==============================] - 1s 19ms/step - loss: 0.3526 - accuracy: 0.8543 - val_loss: 0.4631 - val_accuracy: 0.7928\n",
      "Epoch 3/15\n",
      "52/52 [==============================] - 1s 19ms/step - loss: 0.2768 - accuracy: 0.8932 - val_loss: 0.4455 - val_accuracy: 0.7888\n",
      "Epoch 4/15\n",
      "52/52 [==============================] - 1s 21ms/step - loss: 0.2118 - accuracy: 0.9247 - val_loss: 0.4563 - val_accuracy: 0.7908\n",
      "Epoch 00004: early stopping\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 3ms/step\n",
      "[CV]  pool_sizes=10, num_filters=256, kern_size=3, epochs=15, batch_size=88, total=   4.8s\n",
      "[CV] pool_sizes=10, num_filters=256, kern_size=3, epochs=15, batch_size=88 \n",
      "Epoch 1/15\n",
      "52/52 [==============================] - 1s 20ms/step - loss: 0.4991 - accuracy: 0.7591 - val_loss: 0.4734 - val_accuracy: 0.7888\n",
      "Epoch 2/15\n",
      "52/52 [==============================] - 1s 21ms/step - loss: 0.3497 - accuracy: 0.8521 - val_loss: 0.4849 - val_accuracy: 0.7829\n",
      "Epoch 00002: early stopping\n",
      "7/7 [==============================] - 0s 3ms/step\n",
      "[CV]  pool_sizes=10, num_filters=256, kern_size=3, epochs=15, batch_size=88, total=   2.8s\n",
      "[CV] pool_sizes=10, num_filters=256, kern_size=3, epochs=15, batch_size=88 \n",
      "Epoch 1/15\n",
      "52/52 [==============================] - 1s 22ms/step - loss: 0.5150 - accuracy: 0.7516 - val_loss: 0.4820 - val_accuracy: 0.7689\n",
      "Epoch 2/15\n",
      "52/52 [==============================] - 1s 18ms/step - loss: 0.3556 - accuracy: 0.8516 - val_loss: 0.4513 - val_accuracy: 0.7809\n",
      "Epoch 3/15\n",
      "52/52 [==============================] - 1s 19ms/step - loss: 0.2774 - accuracy: 0.8915 - val_loss: 0.4757 - val_accuracy: 0.7908\n",
      "Epoch 00003: early stopping\n",
      "7/7 [==============================] - 0s 2ms/step\n",
      "[CV]  pool_sizes=10, num_filters=256, kern_size=3, epochs=15, batch_size=88, total=   3.7s\n",
      "[CV] pool_sizes=10, num_filters=256, kern_size=3, epochs=15, batch_size=88 \n",
      "Epoch 1/15\n",
      "52/52 [==============================] - 1s 20ms/step - loss: 0.4967 - accuracy: 0.7602 - val_loss: 0.4680 - val_accuracy: 0.7849\n",
      "Epoch 2/15\n",
      "52/52 [==============================] - 1s 19ms/step - loss: 0.3524 - accuracy: 0.8494 - val_loss: 0.4493 - val_accuracy: 0.7968\n",
      "Epoch 3/15\n",
      "52/52 [==============================] - 1s 19ms/step - loss: 0.2719 - accuracy: 0.8913 - val_loss: 0.4405 - val_accuracy: 0.8008\n",
      "Epoch 4/15\n",
      "52/52 [==============================] - 1s 19ms/step - loss: 0.2049 - accuracy: 0.9291 - val_loss: 0.4603 - val_accuracy: 0.7948\n",
      "Epoch 00004: early stopping\n",
      "7/7 [==============================] - 0s 2ms/step\n",
      "[CV]  pool_sizes=10, num_filters=256, kern_size=3, epochs=15, batch_size=88, total=   4.7s\n",
      "[CV] pool_sizes=10, num_filters=256, kern_size=3, epochs=15, batch_size=88 \n",
      "Epoch 1/15\n",
      "52/52 [==============================] - 1s 20ms/step - loss: 0.4993 - accuracy: 0.7602 - val_loss: 0.4896 - val_accuracy: 0.7789\n",
      "Epoch 2/15\n",
      "52/52 [==============================] - 1s 19ms/step - loss: 0.3529 - accuracy: 0.8510 - val_loss: 0.4626 - val_accuracy: 0.7829\n",
      "Epoch 3/15\n",
      "52/52 [==============================] - 1s 19ms/step - loss: 0.2740 - accuracy: 0.8939 - val_loss: 0.4710 - val_accuracy: 0.7908\n",
      "Epoch 00003: early stopping\n",
      "7/7 [==============================] - 0s 2ms/step\n",
      "[CV]  pool_sizes=10, num_filters=256, kern_size=3, epochs=15, batch_size=88, total=   3.7s\n",
      "[CV] pool_sizes=10, num_filters=256, kern_size=3, epochs=15, batch_size=88 \n",
      "Epoch 1/15\n",
      "52/52 [==============================] - 1s 20ms/step - loss: 0.5044 - accuracy: 0.7609 - val_loss: 0.4056 - val_accuracy: 0.8267\n",
      "Epoch 2/15\n",
      "52/52 [==============================] - 1s 21ms/step - loss: 0.3647 - accuracy: 0.8439 - val_loss: 0.3925 - val_accuracy: 0.8446\n",
      "Epoch 3/15\n",
      "52/52 [==============================] - 1s 19ms/step - loss: 0.2835 - accuracy: 0.8906 - val_loss: 0.4338 - val_accuracy: 0.8068\n",
      "Epoch 00003: early stopping\n",
      "7/7 [==============================] - 0s 2ms/step\n",
      "[CV]  pool_sizes=10, num_filters=256, kern_size=3, epochs=15, batch_size=88, total=   3.8s\n",
      "Epoch 1/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:  4.0min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "67/67 [==============================] - 1s 16ms/step - loss: 0.5134 - accuracy: 0.7459 - val_loss: 0.4836 - val_accuracy: 0.7867\n",
      "Epoch 2/15\n",
      "67/67 [==============================] - 1s 15ms/step - loss: 0.3863 - accuracy: 0.8314 - val_loss: 0.4707 - val_accuracy: 0.7849\n",
      "Epoch 3/15\n",
      "67/67 [==============================] - 1s 15ms/step - loss: 0.3058 - accuracy: 0.8778 - val_loss: 0.4358 - val_accuracy: 0.7993\n",
      "Epoch 4/15\n",
      "67/67 [==============================] - 1s 15ms/step - loss: 0.2564 - accuracy: 0.9005 - val_loss: 0.4584 - val_accuracy: 0.7957\n",
      "Epoch 00004: early stopping\n",
      "25/25 [==============================] - 0s 2ms/step\n",
      "Best Accuracy : 0.8093\n",
      "{'pool_sizes': 10, 'num_filters': 128, 'kern_size': 3, 'epochs': 15, 'batch_size': 76}\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "param_grid = dict(num_filters=[128, 256],\n",
    "                      kern_size=[3, 5, 7],\n",
    "                      batch_size = [76,88],\n",
    "                      pool_sizes = [2, 10], epochs = [15])\n",
    "\n",
    "model = KerasClassifier(build_fn=build_model, epochs=15, validation_split=0.1,verbose=1)\n",
    "\n",
    "grid = RandomizedSearchCV(estimator=model, param_distributions=param_grid,\n",
    "                              cv=10, verbose=2, n_iter=5, n_jobs=1,scoring = 'accuracy')\n",
    "\n",
    "grid_result = grid.fit(x_train, y_train, callbacks=[callback])\n",
    "\n",
    "\n",
    "test_accuracy = grid.score(x_test, y_test)\n",
    "\n",
    "# Save and evaluate results\n",
    "s = ('Best Accuracy : {:.4f}\\n{}\\n\\n\\n')\n",
    "output_string = s.format(\n",
    "            grid_result.best_score_,\n",
    "            grid_result.best_params_)\n",
    "            \n",
    "print(output_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_583\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_583 (Embedding)    (None, 31, 100)           2258600   \n",
      "_________________________________________________________________\n",
      "conv1d_748 (Conv1D)          (None, 29, 128)           38528     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_52 (MaxPooling (None, 2, 128)            0         \n",
      "_________________________________________________________________\n",
      "flatten_559 (Flatten)        (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_923 (Dense)            (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 2,297,385\n",
      "Trainable params: 2,297,385\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = build_model(128, 3, 10)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "44/44 - 1s - loss: 0.5500 - accuracy: 0.7157 - val_loss: 0.4626 - val_accuracy: 0.7881\n",
      "Epoch 2/15\n",
      "44/44 - 1s - loss: 0.3979 - accuracy: 0.8280 - val_loss: 0.4310 - val_accuracy: 0.8085\n",
      "Epoch 3/15\n",
      "44/44 - 1s - loss: 0.3286 - accuracy: 0.8725 - val_loss: 0.4232 - val_accuracy: 0.8144\n",
      "Epoch 4/15\n",
      "44/44 - 1s - loss: 0.2700 - accuracy: 0.8945 - val_loss: 0.4233 - val_accuracy: 0.8187\n",
      "Epoch 00004: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x14b281550>"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "callback = EarlyStopping(monitor = 'val_loss', patience = 1, verbose=1)\n",
    "callbacks = [callback]\n",
    "\n",
    "model.fit(x_train, y_train,\n",
    "          validation_data=(x_test, y_test),\n",
    "          batch_size=128,\n",
    "          epochs=15,\n",
    "          verbose=2,\n",
    "          callbacks=callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_585\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_585 (Embedding)    (None, 31, 100)           2258600   \n",
      "_________________________________________________________________\n",
      "conv1d_750 (Conv1D)          (None, 29, 128)           38528     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_54 (MaxPooling (None, 2, 128)            0         \n",
      "_________________________________________________________________\n",
      "flatten_561 (Flatten)        (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_925 (Dense)            (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 2,297,385\n",
      "Trainable params: 2,297,385\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model2 = build_model(128, 3, 10)\n",
    "model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "98/98 - 1s - loss: 0.4860 - accuracy: 0.7689\n",
      "Epoch 2/3\n",
      "98/98 - 2s - loss: 0.3591 - accuracy: 0.8489\n",
      "Epoch 3/3\n",
      "98/98 - 1s - loss: 0.2790 - accuracy: 0.8901\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x265219810>"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.fit(padded_docs, tweets['target'],\n",
    "          batch_size=76,\n",
    "          epochs=3,\n",
    "          verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_result = model2.predict(padded_tests)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.7977159 ],\n",
       "       [0.78402555],\n",
       "       [0.8646941 ],\n",
       "       ...,\n",
       "       [0.9667603 ],\n",
       "       [0.9011095 ],\n",
       "       [0.6470193 ]], dtype=float32)"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " ...]"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submit = []\n",
    "\n",
    "for i in test_result:\n",
    "    if i >= 0.5 :\n",
    "        submit.append(1)\n",
    "    else:\n",
    "        submit.append(0)\n",
    "\n",
    "submit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "tests['target'] = submit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit_df = tests[['id', 'target']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3258</th>\n",
       "      <td>10861</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3259</th>\n",
       "      <td>10865</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3260</th>\n",
       "      <td>10868</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3261</th>\n",
       "      <td>10874</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3262</th>\n",
       "      <td>10875</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3263 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id  target\n",
       "0         0       1\n",
       "1         2       1\n",
       "2         3       1\n",
       "3         9       1\n",
       "4        11       1\n",
       "...     ...     ...\n",
       "3258  10861       1\n",
       "3259  10865       1\n",
       "3260  10868       1\n",
       "3261  10874       1\n",
       "3262  10875       1\n",
       "\n",
       "[3263 rows x 2 columns]"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submit_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit_df.to_csv('submit_prueba_40.csv', index=False) #39 fue este con un epoch menos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_features = pd.read_csv(\"train_features.csv\")\n",
    "test_features = pd.read_csv(\"test_features.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>text_without_stopwords</th>\n",
       "      <th>length</th>\n",
       "      <th>avg_word_length</th>\n",
       "      <th>amount_of_words</th>\n",
       "      <th>amount_of_unique_words</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>stopwords_count</th>\n",
       "      <th>punctuation_count</th>\n",
       "      <th>mentions_count</th>\n",
       "      <th>hashtags_count</th>\n",
       "      <th>longest_word_length_without_stopwords</th>\n",
       "      <th>stopword_word_ratio</th>\n",
       "      <th>adjectives_count</th>\n",
       "      <th>nouns_count</th>\n",
       "      <th>verbs_count</th>\n",
       "      <th>adverbs_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "      <td>1</td>\n",
       "      <td>Our Deeds Reason May ALLAH Forgive us</td>\n",
       "      <td>69</td>\n",
       "      <td>4.384615</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>0.2732</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0.461538</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                               text  target  \\\n",
       "0   1  Our Deeds are the Reason of this #earthquake M...       1   \n",
       "\n",
       "                  text_without_stopwords  length  avg_word_length  \\\n",
       "0  Our Deeds Reason May ALLAH Forgive us      69         4.384615   \n",
       "\n",
       "   amount_of_words  amount_of_unique_words  sentiment  stopwords_count  \\\n",
       "0               13                      13     0.2732                6   \n",
       "\n",
       "   punctuation_count  mentions_count  hashtags_count  \\\n",
       "0                  1               0               1   \n",
       "\n",
       "   longest_word_length_without_stopwords  stopword_word_ratio  \\\n",
       "0                                      7             0.461538   \n",
       "\n",
       "   adjectives_count  nouns_count  verbs_count  adverbs_count  \n",
       "0                 0            6            1              0  "
      ]
     },
     "execution_count": 419,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_features.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>text_without_stopwords</th>\n",
       "      <th>length</th>\n",
       "      <th>avg_word_length</th>\n",
       "      <th>amount_of_words</th>\n",
       "      <th>amount_of_unique_words</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>stopwords_count</th>\n",
       "      <th>punctuation_count</th>\n",
       "      <th>mentions_count</th>\n",
       "      <th>hashtags_count</th>\n",
       "      <th>longest_word_length_without_stopwords</th>\n",
       "      <th>stopword_word_ratio</th>\n",
       "      <th>adjectives_count</th>\n",
       "      <th>nouns_count</th>\n",
       "      <th>verbs_count</th>\n",
       "      <th>adverbs_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Just happened a terrible car crash</td>\n",
       "      <td>Just happened terrible car crash</td>\n",
       "      <td>34</td>\n",
       "      <td>4.833333</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>-0.7003</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                text            text_without_stopwords  \\\n",
       "0   0  Just happened a terrible car crash  Just happened terrible car crash   \n",
       "\n",
       "   length  avg_word_length  amount_of_words  amount_of_unique_words  \\\n",
       "0      34         4.833333                6                       6   \n",
       "\n",
       "   sentiment  stopwords_count  punctuation_count  mentions_count  \\\n",
       "0    -0.7003                2                  0               0   \n",
       "\n",
       "   hashtags_count  longest_word_length_without_stopwords  stopword_word_ratio  \\\n",
       "0               0                                      8             0.333333   \n",
       "\n",
       "   adjectives_count  nouns_count  verbs_count  adverbs_count  \n",
       "0                 1            2            1              1  "
      ]
     },
     "execution_count": 420,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_features.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_features = tweets_features.drop(columns=['text', 'text_without_stopwords', 'target'])\n",
    "test_features = test_features.drop(columns=['text', 'text_without_stopwords'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 534,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "features_train = scaler.fit_transform(tweets_features.iloc[:, 1:])\n",
    "features_test = scaler.fit_transform(test_features.iloc[:, 1:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### My tweets process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 521,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>All residents asked to 'shelter in place' are ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id keyword location                                               text  \\\n",
       "0   1     NaN      NaN  Our Deeds are the Reason of this #earthquake M...   \n",
       "1   4     NaN      NaN             Forest fire near La Ronge Sask. Canada   \n",
       "2   5     NaN      NaN  All residents asked to 'shelter in place' are ...   \n",
       "3   6     NaN      NaN  13,000 people receive #wildfires evacuation or...   \n",
       "4   7     NaN      NaN  Just got sent this photo from Ruby #Alaska as ...   \n",
       "\n",
       "   target  \n",
       "0       1  \n",
       "1       1  \n",
       "2       1  \n",
       "3       1  \n",
       "4       1  "
      ]
     },
     "execution_count": 521,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 516,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mocks real tokenizer used in glove\n",
    "\n",
    "import re\n",
    "\n",
    "def tokenize_input(input_text):\n",
    "    to_tokens = input_text[:]\n",
    "    token_specification = [\n",
    "        ('url', r'https?:\\/\\/\\S+\\b|www\\.(\\w+\\.)+\\S*'),\n",
    "        (' / ', r'/'),\n",
    "        ('user', r'@\\w+'),            \n",
    "        ('smile', r'[8:=;][)d]+|[)d]+[\\'`\\-]?[8:=;]'),    \n",
    "        ('lolface', r'[8:=;][\\'`\\-]?p'),      \n",
    "        ('sadface', r'[8:=;][\\'`\\-]?\\(|\\)+[8:=;][\\'`\\-]?'),          \n",
    "        ('neutralface', r'[8:=;][\\'`\\-]?[\\/|l*]'),       \n",
    "        ('heart', r'<3'),   \n",
    "        ('number', r'[-+]?[.\\d]*[\\d]+[:,.\\d]*')\n",
    "    ]\n",
    "    for replacement, regex in token_specification:\n",
    "        to_tokens = re.sub(regex, replacement, to_tokens)\n",
    "    return to_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 513,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "url hola  /  smile heart lolface sadface  number !!!! wayyy user\n"
     ]
    }
   ],
   "source": [
    "# Check\n",
    "tokenize_input('https://regexr.com hola / :) <3 :p :(  8888 @justin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 544,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets['text'] = tweets['text'].apply(tokenize_input)\n",
    "tests['text'] = tests['text'].apply(tokenize_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train with features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 536,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15325\n"
     ]
    }
   ],
   "source": [
    "t = Tokenizer()\n",
    "t.fit_on_texts(tweets['text'])\n",
    "vocab_size = len(t.word_index) + 1\n",
    "print(vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 537,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'url': 1,\n",
       " 'the': 2,\n",
       " 'user': 3,\n",
       " 'a': 4,\n",
       " 'in': 5,\n",
       " 'to': 6,\n",
       " 'number': 7,\n",
       " 'of': 8,\n",
       " 'and': 9,\n",
       " 'i': 10,\n",
       " 'is': 11,\n",
       " 'for': 12,\n",
       " 'on': 13,\n",
       " 'you': 14,\n",
       " 'my': 15,\n",
       " 'that': 16,\n",
       " 'it': 17,\n",
       " 'with': 18,\n",
       " 'at': 19,\n",
       " 'by': 20,\n",
       " 'this': 21,\n",
       " 'from': 22,\n",
       " 'be': 23,\n",
       " 'are': 24,\n",
       " 'was': 25,\n",
       " 'have': 26,\n",
       " 'like': 27,\n",
       " 'amp': 28,\n",
       " 'me': 29,\n",
       " 'as': 30,\n",
       " 'but': 31,\n",
       " 'up': 32,\n",
       " 'just': 33,\n",
       " 'so': 34,\n",
       " 'not': 35,\n",
       " 'your': 36,\n",
       " 'out': 37,\n",
       " 'no': 38,\n",
       " 'all': 39,\n",
       " 'will': 40,\n",
       " 'after': 41,\n",
       " 'an': 42,\n",
       " 'has': 43,\n",
       " 'when': 44,\n",
       " 'fire': 45,\n",
       " \"i'm\": 46,\n",
       " 'get': 47,\n",
       " 'now': 48,\n",
       " 'we': 49,\n",
       " 'new': 50,\n",
       " 'if': 51,\n",
       " 'more': 52,\n",
       " 'via': 53,\n",
       " 'about': 54,\n",
       " 'or': 55,\n",
       " 'what': 56,\n",
       " 'news': 57,\n",
       " 'they': 58,\n",
       " 'one': 59,\n",
       " 'how': 60,\n",
       " 'people': 61,\n",
       " 'he': 62,\n",
       " \"it's\": 63,\n",
       " \"don't\": 64,\n",
       " 'been': 65,\n",
       " 'who': 66,\n",
       " 'over': 67,\n",
       " 'into': 68,\n",
       " 'do': 69,\n",
       " 'video': 70,\n",
       " 'can': 71,\n",
       " 'emergency': 72,\n",
       " 'there': 73,\n",
       " 'disaster': 74,\n",
       " \"'\": 75,\n",
       " 'police': 76,\n",
       " 'than': 77,\n",
       " 'u': 78,\n",
       " 'her': 79,\n",
       " 'his': 80,\n",
       " 'would': 81,\n",
       " 'still': 82,\n",
       " 'were': 83,\n",
       " 'body': 84,\n",
       " 'some': 85,\n",
       " 'us': 86,\n",
       " 'back': 87,\n",
       " 'storm': 88,\n",
       " 'crash': 89,\n",
       " 'day': 90,\n",
       " 'them': 91,\n",
       " 'off': 92,\n",
       " 'got': 93,\n",
       " 'california': 94,\n",
       " 'why': 95,\n",
       " 'man': 96,\n",
       " 'had': 97,\n",
       " 'know': 98,\n",
       " 'time': 99,\n",
       " 'first': 100,\n",
       " 'suicide': 101,\n",
       " 'see': 102,\n",
       " 'rt': 103,\n",
       " 'going': 104,\n",
       " 'world': 105,\n",
       " 'nuclear': 106,\n",
       " 'love': 107,\n",
       " 'burning': 108,\n",
       " 'fires': 109,\n",
       " 'killed': 110,\n",
       " 'our': 111,\n",
       " 's': 112,\n",
       " 'attack': 113,\n",
       " 'bomb': 114,\n",
       " 'two': 115,\n",
       " 'dead': 116,\n",
       " 'gt': 117,\n",
       " 'go': 118,\n",
       " 'their': 119,\n",
       " 'full': 120,\n",
       " 'car': 121,\n",
       " 'life': 122,\n",
       " 'buildings': 123,\n",
       " 'being': 124,\n",
       " \"can't\": 125,\n",
       " 'good': 126,\n",
       " 'hiroshima': 127,\n",
       " 'here': 128,\n",
       " 'accident': 129,\n",
       " 'today': 130,\n",
       " 'only': 131,\n",
       " 'may': 132,\n",
       " 'say': 133,\n",
       " 'watch': 134,\n",
       " 'war': 135,\n",
       " 'down': 136,\n",
       " 'families': 137,\n",
       " 'train': 138,\n",
       " 'think': 139,\n",
       " 'could': 140,\n",
       " 'did': 141,\n",
       " 'last': 142,\n",
       " 'way': 143,\n",
       " 'years': 144,\n",
       " 'then': 145,\n",
       " 'too': 146,\n",
       " 'home': 147,\n",
       " 'make': 148,\n",
       " 'w': 149,\n",
       " 'its': 150,\n",
       " 'many': 151,\n",
       " 'year': 152,\n",
       " 'work': 153,\n",
       " 'because': 154,\n",
       " 'best': 155,\n",
       " 'look': 156,\n",
       " 'want': 157,\n",
       " 'help': 158,\n",
       " 'need': 159,\n",
       " 'take': 160,\n",
       " 'collapse': 161,\n",
       " 'really': 162,\n",
       " 'army': 163,\n",
       " 'mass': 164,\n",
       " 'please': 165,\n",
       " 'death': 166,\n",
       " 'am': 167,\n",
       " 'lol': 168,\n",
       " 'mhnumber': 169,\n",
       " 'black': 170,\n",
       " 'right': 171,\n",
       " 'should': 172,\n",
       " \"you're\": 173,\n",
       " 'another': 174,\n",
       " 'hot': 175,\n",
       " 'forest': 176,\n",
       " 'those': 177,\n",
       " 'bombing': 178,\n",
       " 'old': 179,\n",
       " 'school': 180,\n",
       " 'much': 181,\n",
       " 'never': 182,\n",
       " 'wildfire': 183,\n",
       " 'live': 184,\n",
       " 'pm': 185,\n",
       " 'him': 186,\n",
       " '\\x89û': 187,\n",
       " 'even': 188,\n",
       " 'she': 189,\n",
       " 'wreck': 190,\n",
       " 'latest': 191,\n",
       " 'city': 192,\n",
       " 'any': 193,\n",
       " 'northern': 194,\n",
       " 'let': 195,\n",
       " 'homes': 196,\n",
       " 'where': 197,\n",
       " 'fear': 198,\n",
       " 'every': 199,\n",
       " 'great': 200,\n",
       " 'read': 201,\n",
       " 'under': 202,\n",
       " 'obama': 203,\n",
       " 'atomic': 204,\n",
       " 'flames': 205,\n",
       " 'getting': 206,\n",
       " 'damage': 207,\n",
       " 'im': 208,\n",
       " 'come': 209,\n",
       " 'feel': 210,\n",
       " 'bomber': 211,\n",
       " 'god': 212,\n",
       " 'fatal': 213,\n",
       " 'ever': 214,\n",
       " 'typhoon': 215,\n",
       " 'flood': 216,\n",
       " 'top': 217,\n",
       " 'hit': 218,\n",
       " \"that's\": 219,\n",
       " 'japan': 220,\n",
       " 'cross': 221,\n",
       " 'oil': 222,\n",
       " 'floods': 223,\n",
       " 'shit': 224,\n",
       " 'everyone': 225,\n",
       " 'since': 226,\n",
       " 'hope': 227,\n",
       " 'military': 228,\n",
       " 'injured': 229,\n",
       " 'content': 230,\n",
       " 'near': 231,\n",
       " 'coming': 232,\n",
       " 'stop': 233,\n",
       " 'most': 234,\n",
       " 'said': 235,\n",
       " 'weather': 236,\n",
       " 'night': 237,\n",
       " 'next': 238,\n",
       " 'before': 239,\n",
       " 'while': 240,\n",
       " 'found': 241,\n",
       " 'flooding': 242,\n",
       " 'times': 243,\n",
       " 'during': 244,\n",
       " 'without': 245,\n",
       " 'ass': 246,\n",
       " 'plan': 247,\n",
       " 'smoke': 248,\n",
       " 'set': 249,\n",
       " 'truck': 250,\n",
       " 'debris': 251,\n",
       " 'well': 252,\n",
       " 'movie': 253,\n",
       " 'thunderstorm': 254,\n",
       " 'earthquake': 255,\n",
       " 'area': 256,\n",
       " 'heat': 257,\n",
       " 'face': 258,\n",
       " 'state': 259,\n",
       " 'wild': 260,\n",
       " 'through': 261,\n",
       " 'water': 262,\n",
       " 'severe': 263,\n",
       " 'fucking': 264,\n",
       " 'explosion': 265,\n",
       " 'looks': 266,\n",
       " 'made': 267,\n",
       " 'wounded': 268,\n",
       " 'lightning': 269,\n",
       " 'm': 270,\n",
       " 'malaysia': 271,\n",
       " 'these': 272,\n",
       " 'cause': 273,\n",
       " 'services': 274,\n",
       " 'check': 275,\n",
       " 'high': 276,\n",
       " 'bad': 277,\n",
       " 'warning': 278,\n",
       " 'says': 279,\n",
       " 'natural': 280,\n",
       " 'thunder': 281,\n",
       " 'rain': 282,\n",
       " 'always': 283,\n",
       " 'until': 284,\n",
       " 'also': 285,\n",
       " 'bloody': 286,\n",
       " 'little': 287,\n",
       " 'run': 288,\n",
       " 'liked': 289,\n",
       " 'fall': 290,\n",
       " 'spill': 291,\n",
       " 'loud': 292,\n",
       " 'gonna': 293,\n",
       " 'head': 294,\n",
       " 'free': 295,\n",
       " 'house': 296,\n",
       " 'which': 297,\n",
       " 'red': 298,\n",
       " 'again': 299,\n",
       " 'evacuate': 300,\n",
       " 'reddit': 301,\n",
       " 'evacuation': 302,\n",
       " 'photo': 303,\n",
       " 'summer': 304,\n",
       " 'end': 305,\n",
       " 'screaming': 306,\n",
       " 'family': 307,\n",
       " 'hail': 308,\n",
       " 'missing': 309,\n",
       " 'weapon': 310,\n",
       " 'bags': 311,\n",
       " 'sinking': 312,\n",
       " 'trapped': 313,\n",
       " 'injuries': 314,\n",
       " 'fatalities': 315,\n",
       " 'numberth': 316,\n",
       " 'destroy': 317,\n",
       " 'blood': 318,\n",
       " 'big': 319,\n",
       " 'released': 320,\n",
       " 'attacked': 321,\n",
       " 'explode': 322,\n",
       " 'failure': 323,\n",
       " 'sinkhole': 324,\n",
       " \"i've\": 325,\n",
       " 'someone': 326,\n",
       " 'air': 327,\n",
       " 'ambulance': 328,\n",
       " \"he's\": 329,\n",
       " 'destruction': 330,\n",
       " 'girl': 331,\n",
       " 'destroyed': 332,\n",
       " 'post': 333,\n",
       " 'saudi': 334,\n",
       " 'weapons': 335,\n",
       " 'bag': 336,\n",
       " 'hurricane': 337,\n",
       " 'hazard': 338,\n",
       " 'harm': 339,\n",
       " 'rescue': 340,\n",
       " 'panic': 341,\n",
       " 'devastated': 342,\n",
       " 'week': 343,\n",
       " 'around': 344,\n",
       " '\\x89ûò': 345,\n",
       " 'does': 346,\n",
       " 'game': 347,\n",
       " 'murder': 348,\n",
       " 'trauma': 349,\n",
       " 'survivors': 350,\n",
       " 'survive': 351,\n",
       " 'keep': 352,\n",
       " 'drought': 353,\n",
       " 'deaths': 354,\n",
       " 'twister': 355,\n",
       " 'wrecked': 356,\n",
       " 'county': 357,\n",
       " 'breaking': 358,\n",
       " 'tonight': 359,\n",
       " 'call': 360,\n",
       " 'ok': 361,\n",
       " 'self': 362,\n",
       " 'away': 363,\n",
       " 'white': 364,\n",
       " 'fuck': 365,\n",
       " 'terrorism': 366,\n",
       " 'battle': 367,\n",
       " 'wind': 368,\n",
       " 'bombed': 369,\n",
       " 'bridge': 370,\n",
       " 'ruin': 371,\n",
       " 'service': 372,\n",
       " 'collided': 373,\n",
       " 'rescued': 374,\n",
       " 'crush': 375,\n",
       " 'survived': 376,\n",
       " 'dust': 377,\n",
       " 'outbreak': 378,\n",
       " 'windstorm': 379,\n",
       " 'update': 380,\n",
       " \"there's\": 381,\n",
       " 'bus': 382,\n",
       " 'n': 383,\n",
       " 'crashed': 384,\n",
       " 'whole': 385,\n",
       " 'august': 386,\n",
       " 'burned': 387,\n",
       " 'things': 388,\n",
       " 'real': 389,\n",
       " 'twitter': 390,\n",
       " 'terrorist': 391,\n",
       " 'put': 392,\n",
       " 'curfew': 393,\n",
       " 'wreckage': 394,\n",
       " 'whirlwind': 395,\n",
       " 'other': 396,\n",
       " 'least': 397,\n",
       " 'injury': 398,\n",
       " 'suspect': 399,\n",
       " 'long': 400,\n",
       " 'numberpm': 401,\n",
       " 'saw': 402,\n",
       " 'against': 403,\n",
       " 'hostage': 404,\n",
       " 'wanna': 405,\n",
       " 'tragedy': 406,\n",
       " 'traumatised': 407,\n",
       " 'catastrophe': 408,\n",
       " 'landslide': 409,\n",
       " 'collision': 410,\n",
       " 'deluge': 411,\n",
       " 'devastation': 412,\n",
       " 'screamed': 413,\n",
       " 'famine': 414,\n",
       " 'investigators': 415,\n",
       " 'hostages': 416,\n",
       " 'massacre': 417,\n",
       " 'quarantined': 418,\n",
       " 'sandstorm': 419,\n",
       " 'sunk': 420,\n",
       " 'wave': 421,\n",
       " 'better': 422,\n",
       " 'past': 423,\n",
       " 'heard': 424,\n",
       " 'thing': 425,\n",
       " 'o': 426,\n",
       " 'kills': 427,\n",
       " 'national': 428,\n",
       " 'apocalypse': 429,\n",
       " 'heart': 430,\n",
       " 'story': 431,\n",
       " 'woman': 432,\n",
       " 'power': 433,\n",
       " 'oh': 434,\n",
       " 'bleeding': 435,\n",
       " 'blown': 436,\n",
       " 'show': 437,\n",
       " 'rioting': 438,\n",
       " 'casualties': 439,\n",
       " 'chemical': 440,\n",
       " 'collapsed': 441,\n",
       " 'danger': 442,\n",
       " 'stock': 443,\n",
       " 'migrants': 444,\n",
       " 'derail': 445,\n",
       " 'derailed': 446,\n",
       " 'desolation': 447,\n",
       " 'drowning': 448,\n",
       " 'inundated': 449,\n",
       " 'quarantine': 450,\n",
       " 'screams': 451,\n",
       " 'structural': 452,\n",
       " \"i'll\": 453,\n",
       " 'road': 454,\n",
       " 'meltdown': 455,\n",
       " 'p': 456,\n",
       " 'plane': 457,\n",
       " 'iran': 458,\n",
       " 'went': 459,\n",
       " 'save': 460,\n",
       " 'violent': 461,\n",
       " 'women': 462,\n",
       " 'light': 463,\n",
       " 'rescuers': 464,\n",
       " 'riot': 465,\n",
       " 'boat': 466,\n",
       " 'catastrophic': 467,\n",
       " 'cliff': 468,\n",
       " 'wounds': 469,\n",
       " 'electrocuted': 470,\n",
       " 'lava': 471,\n",
       " 'bang': 472,\n",
       " 'smile': 473,\n",
       " 'd': 474,\n",
       " 'something': 475,\n",
       " 'use': 476,\n",
       " 'thank': 477,\n",
       " \"'the\": 478,\n",
       " 'airplane': 479,\n",
       " 'lot': 480,\n",
       " 'zone': 481,\n",
       " 'soon': 482,\n",
       " 'part': 483,\n",
       " 'mosque': 484,\n",
       " 'blew': 485,\n",
       " 'drown': 486,\n",
       " 'bagging': 487,\n",
       " 'anniversary': 488,\n",
       " 'caused': 489,\n",
       " 'derailment': 490,\n",
       " 'evacuated': 491,\n",
       " 'flattened': 492,\n",
       " 'pandemonium': 493,\n",
       " 'panicking': 494,\n",
       " 'cool': 495,\n",
       " 'left': 496,\n",
       " 'minute': 497,\n",
       " 'phone': 498,\n",
       " 'sure': 499,\n",
       " 'food': 500,\n",
       " 'river': 501,\n",
       " 'change': 502,\n",
       " 'armageddon': 503,\n",
       " 'calgary': 504,\n",
       " 'fedex': 505,\n",
       " 'bioterror': 506,\n",
       " 'market': 507,\n",
       " 'send': 508,\n",
       " 'baby': 509,\n",
       " 'hazardous': 510,\n",
       " 'trouble': 511,\n",
       " 'refugees': 512,\n",
       " 'exploded': 513,\n",
       " 'fatality': 514,\n",
       " 'hijacking': 515,\n",
       " 'razed': 516,\n",
       " 'tornado': 517,\n",
       " 'care': 518,\n",
       " 'horrible': 519,\n",
       " 'doing': 520,\n",
       " 'possible': 521,\n",
       " 'goes': 522,\n",
       " 'government': 523,\n",
       " 'must': 524,\n",
       " 'thought': 525,\n",
       " 'kill': 526,\n",
       " 'tomorrow': 527,\n",
       " 'b': 528,\n",
       " 'officials': 529,\n",
       " 'india': 530,\n",
       " 'group': 531,\n",
       " 'longer': 532,\n",
       " 'security': 533,\n",
       " 'song': 534,\n",
       " 'affected': 535,\n",
       " 'collide': 536,\n",
       " 'isis': 537,\n",
       " 'demolish': 538,\n",
       " 'detonation': 539,\n",
       " 'drowned': 540,\n",
       " 'hijacker': 541,\n",
       " 'murderer': 542,\n",
       " 'obliterated': 543,\n",
       " 'three': 544,\n",
       " 'st': 545,\n",
       " 'used': 546,\n",
       " 'kids': 547,\n",
       " 'came': 548,\n",
       " 'very': 549,\n",
       " 'issues': 550,\n",
       " 'same': 551,\n",
       " 'reunion': 552,\n",
       " 'airport': 553,\n",
       " 'ebay': 554,\n",
       " 'annihilated': 555,\n",
       " 'numbernumber': 556,\n",
       " 'arson': 557,\n",
       " 'sound': 558,\n",
       " 'stay': 559,\n",
       " 'blazing': 560,\n",
       " 'half': 561,\n",
       " 'shoulder': 562,\n",
       " 'casualty': 563,\n",
       " 'responders': 564,\n",
       " 'officer': 565,\n",
       " 'crushed': 566,\n",
       " 'blast': 567,\n",
       " 'hundreds': 568,\n",
       " \"legionnaires'\": 569,\n",
       " 'demolished': 570,\n",
       " 'demolition': 571,\n",
       " 'prebreak': 572,\n",
       " 'mudslide': 573,\n",
       " 'obliterate': 574,\n",
       " 'rainstorm': 575,\n",
       " 'due': 576,\n",
       " 'south': 577,\n",
       " 'days': 578,\n",
       " 'thanks': 579,\n",
       " 'r': 580,\n",
       " 'few': 581,\n",
       " 'already': 582,\n",
       " 'making': 583,\n",
       " 'done': 584,\n",
       " 'believe': 585,\n",
       " 'hours': 586,\n",
       " 'start': 587,\n",
       " 'yet': 588,\n",
       " 'remember': 589,\n",
       " 'beautiful': 590,\n",
       " 'report': 591,\n",
       " 'ur': 592,\n",
       " 'cyclone': 593,\n",
       " 'tsunami': 594,\n",
       " 'engulfed': 595,\n",
       " 'eyewitness': 596,\n",
       " 'obliteration': 597,\n",
       " 'upheaval': 598,\n",
       " 'building': 599,\n",
       " 'died': 600,\n",
       " 'far': 601,\n",
       " 'inside': 602,\n",
       " 'leave': 603,\n",
       " 'shooting': 604,\n",
       " 'actually': 605,\n",
       " 'men': 606,\n",
       " 'island': 607,\n",
       " 'wake': 608,\n",
       " 'lt': 609,\n",
       " 'fan': 610,\n",
       " 'israeli': 611,\n",
       " 't': 612,\n",
       " 'having': 613,\n",
       " 'nothing': 614,\n",
       " 'policy': 615,\n",
       " 'such': 616,\n",
       " 'turkey': 617,\n",
       " 'electrocute': 618,\n",
       " 'both': 619,\n",
       " 'ablaze': 620,\n",
       " 'site': 621,\n",
       " 'shot': 622,\n",
       " 'traffic': 623,\n",
       " 'support': 624,\n",
       " 'die': 625,\n",
       " 'play': 626,\n",
       " 'sirens': 627,\n",
       " 'trying': 628,\n",
       " 'media': 629,\n",
       " 'music': 630,\n",
       " 'lab': 631,\n",
       " 'yes': 632,\n",
       " 'pic': 633,\n",
       " 're\\x89û': 634,\n",
       " 'words': 635,\n",
       " 'blight': 636,\n",
       " 'nearby': 637,\n",
       " 'mp': 638,\n",
       " 'displaced': 639,\n",
       " 'bush': 640,\n",
       " 'deluged': 641,\n",
       " 'seismic': 642,\n",
       " 'reactor': 643,\n",
       " 'wait': 644,\n",
       " '\\x89ûó': 645,\n",
       " 'nowplaying': 646,\n",
       " 'plans': 647,\n",
       " 'gets': 648,\n",
       " 'brown': 649,\n",
       " 'ago': 650,\n",
       " 'fun': 651,\n",
       " \"i'd\": 652,\n",
       " 'children': 653,\n",
       " 'guys': 654,\n",
       " \"doesn't\": 655,\n",
       " 'line': 656,\n",
       " 'low': 657,\n",
       " 'find': 658,\n",
       " 'legionnaires': 659,\n",
       " 'hijack': 660,\n",
       " 'sue': 661,\n",
       " 'volcano': 662,\n",
       " 'rubble': 663,\n",
       " 'swallowed': 664,\n",
       " 'second': 665,\n",
       " 'outside': 666,\n",
       " 'north': 667,\n",
       " 'tell': 668,\n",
       " 'job': 669,\n",
       " 'almost': 670,\n",
       " 'aircraft': 671,\n",
       " 'helicopter': 672,\n",
       " 'bc': 673,\n",
       " 'order': 674,\n",
       " 'fight': 675,\n",
       " 'data': 676,\n",
       " 'own': 677,\n",
       " 'yeah': 678,\n",
       " 'deal': 679,\n",
       " 'health': 680,\n",
       " 'photos': 681,\n",
       " 'watching': 682,\n",
       " 'bigger': 683,\n",
       " 'pkk': 684,\n",
       " 'memories': 685,\n",
       " 'snowstorm': 686,\n",
       " 'detonated': 687,\n",
       " 'lost': 688,\n",
       " 'west': 689,\n",
       " 'happy': 690,\n",
       " 'inumber': 691,\n",
       " \"didn't\": 692,\n",
       " 'book': 693,\n",
       " 'anyone': 694,\n",
       " 'hey': 695,\n",
       " 'history': 696,\n",
       " 'bar': 697,\n",
       " 'hell': 698,\n",
       " 'maybe': 699,\n",
       " 'pick': 700,\n",
       " 'american': 701,\n",
       " 'makes': 702,\n",
       " 'transport': 703,\n",
       " 'bioterrorism': 704,\n",
       " 'lives': 705,\n",
       " 'rise': 706,\n",
       " 'hear': 707,\n",
       " \"number'\": 708,\n",
       " 'waves': 709,\n",
       " 'abc': 710,\n",
       " 'desolate': 711,\n",
       " 'hat': 712,\n",
       " 'place': 713,\n",
       " 'street': 714,\n",
       " \"what's\": 715,\n",
       " 'side': 716,\n",
       " 'rd': 717,\n",
       " 'finally': 718,\n",
       " 'property': 719,\n",
       " 'might': 720,\n",
       " 'eyes': 721,\n",
       " 'pakistan': 722,\n",
       " 'amid': 723,\n",
       " 'damn': 724,\n",
       " 'team': 725,\n",
       " 'person': 726,\n",
       " 'avalanche': 727,\n",
       " 'listen': 728,\n",
       " 'hollywood': 729,\n",
       " 'pretty': 730,\n",
       " 'online': 731,\n",
       " 'though': 732,\n",
       " 'money': 733,\n",
       " 'probably': 734,\n",
       " 'soudelor': 735,\n",
       " 'effect': 736,\n",
       " 'detonate': 737,\n",
       " 'declares': 738,\n",
       " 'numberkm': 739,\n",
       " 'siren': 740,\n",
       " 'fast': 741,\n",
       " 'center': 742,\n",
       " 'mom': 743,\n",
       " 'once': 744,\n",
       " 'wrong': 745,\n",
       " 'feared': 746,\n",
       " 'hate': 747,\n",
       " 'everything': 748,\n",
       " 'horror': 749,\n",
       " 'seen': 750,\n",
       " 'case': 751,\n",
       " \"we're\": 752,\n",
       " 'major': 753,\n",
       " 'child': 754,\n",
       " 'crisis': 755,\n",
       " 'tv': 756,\n",
       " 'leather': 757,\n",
       " 'caught': 758,\n",
       " 'anything': 759,\n",
       " 'business': 760,\n",
       " 'okay': 761,\n",
       " 'literally': 762,\n",
       " 'space': 763,\n",
       " 'morning': 764,\n",
       " 'spot': 765,\n",
       " 'co': 766,\n",
       " 'confirmed': 767,\n",
       " 'trains': 768,\n",
       " 'sensor': 769,\n",
       " 'trench': 770,\n",
       " 'hailstorm': 771,\n",
       " 'refugio': 772,\n",
       " 'costlier': 773,\n",
       " 'numberyr': 774,\n",
       " 'miners': 775,\n",
       " \"'conclusively\": 776,\n",
       " \"confirmed'\": 777,\n",
       " 'la': 778,\n",
       " 'flash': 779,\n",
       " 'flag': 780,\n",
       " 'cars': 781,\n",
       " 'vehicle': 782,\n",
       " 'daily': 783,\n",
       " 'jobs': 784,\n",
       " \"they're\": 785,\n",
       " 'ship': 786,\n",
       " 'crazy': 787,\n",
       " 'country': 788,\n",
       " 'ball': 789,\n",
       " 'annihilation': 790,\n",
       " 'stand': 791,\n",
       " 'called': 792,\n",
       " 'name': 793,\n",
       " 'class': 794,\n",
       " 'blaze': 795,\n",
       " 'texas': 796,\n",
       " 'worst': 797,\n",
       " 'needs': 798,\n",
       " 'fukushima': 799,\n",
       " 'move': 800,\n",
       " 'land': 801,\n",
       " 'wow': 802,\n",
       " 'russian': 803,\n",
       " 'giant': 804,\n",
       " 'crews': 805,\n",
       " 'course': 806,\n",
       " 'banned': 807,\n",
       " 'knock': 808,\n",
       " 'saipan': 809,\n",
       " 'projected': 810,\n",
       " 'reason': 811,\n",
       " 'heavy': 812,\n",
       " 'across': 813,\n",
       " 'haha': 814,\n",
       " 'lord': 815,\n",
       " 'others': 816,\n",
       " 'huge': 817,\n",
       " 'talk': 818,\n",
       " 'win': 819,\n",
       " 'yourself': 820,\n",
       " \"she's\": 821,\n",
       " 'omg': 822,\n",
       " 'reuters': 823,\n",
       " 'sorry': 824,\n",
       " 'usa': 825,\n",
       " 'sign': 826,\n",
       " 'poor': 827,\n",
       " 'boy': 828,\n",
       " 'united': 829,\n",
       " \"isn't\": 830,\n",
       " 'east': 831,\n",
       " 'town': 832,\n",
       " 'gun': 833,\n",
       " 'anthrax': 834,\n",
       " 'running': 835,\n",
       " 'nearly': 836,\n",
       " 'computers': 837,\n",
       " 'dont': 838,\n",
       " 'follow': 839,\n",
       " 'entire': 840,\n",
       " 'searching': 841,\n",
       " 'meek': 842,\n",
       " 'myself': 843,\n",
       " 'gbbo': 844,\n",
       " 'chance': 845,\n",
       " 'friends': 846,\n",
       " 'angry': 847,\n",
       " 'bodies': 848,\n",
       " 'image': 849,\n",
       " 'ignition': 850,\n",
       " 'mayhem': 851,\n",
       " 'offensive': 852,\n",
       " 'stretcher': 853,\n",
       " 'try': 854,\n",
       " 'wanted': 855,\n",
       " 'chicago': 856,\n",
       " 'alone': 857,\n",
       " 'hard': 858,\n",
       " 'yours': 859,\n",
       " \"'i\": 860,\n",
       " 'happened': 861,\n",
       " 'guy': 862,\n",
       " 'radio': 863,\n",
       " 'totally': 864,\n",
       " 'learn': 865,\n",
       " 'charged': 866,\n",
       " 'truth': 867,\n",
       " 'beach': 868,\n",
       " 'ca': 869,\n",
       " 'feeling': 870,\n",
       " 'christian': 871,\n",
       " 'muslims': 872,\n",
       " 'temple': 873,\n",
       " 'view': 874,\n",
       " 'eye': 875,\n",
       " 'taken': 876,\n",
       " 'playing': 877,\n",
       " 'mishaps': 878,\n",
       " 'public': 879,\n",
       " 'e': 880,\n",
       " 'mad': 881,\n",
       " \"let's\": 882,\n",
       " 'cake': 883,\n",
       " 'level': 884,\n",
       " 'blizzard': 885,\n",
       " 'ladies': 886,\n",
       " 'appears': 887,\n",
       " 'centre': 888,\n",
       " 'alarm': 889,\n",
       " 'x': 890,\n",
       " 'bbc': 891,\n",
       " 'china': 892,\n",
       " 'uk': 893,\n",
       " 'issued': 894,\n",
       " 'signs': 895,\n",
       " 'become': 896,\n",
       " 'disea': 897,\n",
       " 'closed': 898,\n",
       " 'arsonist': 899,\n",
       " 'front': 900,\n",
       " 'else': 901,\n",
       " 'drive': 902,\n",
       " 'global': 903,\n",
       " 'official': 904,\n",
       " 'dog': 905,\n",
       " 'ready': 906,\n",
       " 'vs': 907,\n",
       " 'film': 908,\n",
       " 'till': 909,\n",
       " 'friend': 910,\n",
       " 'blue': 911,\n",
       " 'green': 912,\n",
       " 'mount': 913,\n",
       " 'driving': 914,\n",
       " 'favorite': 915,\n",
       " 'star': 916,\n",
       " 'germs': 917,\n",
       " 'looking': 918,\n",
       " 'pain': 919,\n",
       " \"ain't\": 920,\n",
       " 'link': 921,\n",
       " 'large': 922,\n",
       " 'womens': 923,\n",
       " 'downtown': 924,\n",
       " 'houses': 925,\n",
       " 'insurance': 926,\n",
       " 'mph': 927,\n",
       " 'instead': 928,\n",
       " 'coaches': 929,\n",
       " 'flight': 930,\n",
       " 'quiz': 931,\n",
       " 'aug': 932,\n",
       " \"reddit's\": 933,\n",
       " 'virgin': 934,\n",
       " 'chile': 935,\n",
       " 'bring': 936,\n",
       " 'thousands': 937,\n",
       " 'reported': 938,\n",
       " 'dies': 939,\n",
       " 'moment': 940,\n",
       " 'behind': 941,\n",
       " 'four': 942,\n",
       " 'couple': 943,\n",
       " 'trust': 944,\n",
       " \"won't\": 945,\n",
       " 'driver': 946,\n",
       " 'israel': 947,\n",
       " 'park': 948,\n",
       " 'following': 949,\n",
       " 'comes': 950,\n",
       " 'scared': 951,\n",
       " 'escape': 952,\n",
       " 'russia': 953,\n",
       " 'control': 954,\n",
       " 'reports': 955,\n",
       " 'hiring': 956,\n",
       " 'true': 957,\n",
       " 'theater': 958,\n",
       " 'gave': 959,\n",
       " 'added': 960,\n",
       " 'c': 961,\n",
       " 'turn': 962,\n",
       " 'info': 963,\n",
       " 'sad': 964,\n",
       " 'middle': 965,\n",
       " 'libya': 966,\n",
       " 'camp': 967,\n",
       " 'sounds': 968,\n",
       " 'sex': 969,\n",
       " 'nagasaki': 970,\n",
       " 'british': 971,\n",
       " 'landing': 972,\n",
       " 'sea': 973,\n",
       " 'download': 974,\n",
       " 'patience': 975,\n",
       " 'former': 976,\n",
       " 'cnn': 977,\n",
       " 'wonder': 978,\n",
       " 'numberw': 979,\n",
       " 'picking': 980,\n",
       " 'led': 981,\n",
       " 'gems': 982,\n",
       " 'funtenna': 983,\n",
       " 'ancient': 984,\n",
       " 'subreddits': 985,\n",
       " 'colorado': 986,\n",
       " 'myanmar': 987,\n",
       " 'awesome': 988,\n",
       " 'taking': 989,\n",
       " 'shots': 990,\n",
       " 'scene': 991,\n",
       " 'mode': 992,\n",
       " 'early': 993,\n",
       " 'pakistani': 994,\n",
       " 'numbers': 995,\n",
       " 'share': 996,\n",
       " 'dad': 997,\n",
       " 'give': 998,\n",
       " 'action': 999,\n",
       " 'bed': 1000,\n",
       " ...}"
      ]
     },
     "execution_count": 537,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 545,
   "metadata": {},
   "outputs": [],
   "source": [
    "# integer encode the documents\n",
    "encoded_docs = t.texts_to_sequences(tweets['text'])\n",
    "enconded_test = t.texts_to_sequences(tests['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 546,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 111 4340   24 ...    0    0    0]\n",
      " [ 176   45  231 ...    0    0    0]\n",
      " [  39 1656 1526 ...    0    0    0]\n",
      " ...\n",
      " [ 101  211  427 ...    0    0    0]\n",
      " [ 115  804 1303 ...    0    0    0]\n",
      " [   2  191   52 ...    0    0    0]]\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "max_length = 36 # Maxima cantidad de palabras en los tweets tokenizados\n",
    "padded_docs = pad_sequences(encoded_docs, maxlen=max_length, padding='post')\n",
    "padded_tests = pad_sequences(enconded_test, maxlen=max_length, padding='post')\n",
    "print(padded_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 547,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 1193514 word vectors.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "embeddings_index = dict()\n",
    "f = open('glove.twitter.27B.100d.txt') # Vectores entrenados de 100 dimensiones\n",
    "for line in f:\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    coefs = np.asarray(values[1:], dtype='float32')\n",
    "    embeddings_index[word] = coefs\n",
    "f.close()\n",
    "print('Loaded %s word vectors.' % len(embeddings_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 548,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_matrix = np.zeros((vocab_size, 100))\n",
    "for word, i in t.word_index.items():\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None: # Si la palabra no esta queda llena de 0s\n",
    "        embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 556,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding, Flatten, Dense\n",
    "from keras import layers\n",
    "from keras import activations\n",
    "\n",
    "from keras.callbacks import EarlyStopping\n",
    "callback = EarlyStopping(monitor = 'val_loss', patience = 1, verbose=1)\n",
    "callbacks = [callback]\n",
    "\n",
    "def build_model(num_filters, kern_size, pool_sizes, fully_connected):\n",
    "    model = Sequential()\n",
    "    e = Embedding(vocab_size, 100, weights=[embedding_matrix], input_length=36, trainable=True)\n",
    "    model.add(e)\n",
    "    model.add(layers.Conv1D(num_filters, kern_size, activation='relu'))\n",
    "    model.add(layers.Activation(activations.relu))\n",
    "    model.add(layers.MaxPooling1D(pool_size=pool_sizes, padding=\"valid\"))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(fully_connected, activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 557,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = \\\n",
    "train_test_split(padded_docs, tweets['target'], test_size = 0.25, random_state = 123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 558,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 5 candidates, totalling 50 fits\n",
      "[CV] pool_sizes=2, num_filters=128, kern_size=7, fully_connected=16, epochs=15, batch_size=76 \n",
      "Epoch 1/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60/60 [==============================] - 1s 21ms/step - loss: 0.5223 - accuracy: 0.7515 - val_loss: 0.4962 - val_accuracy: 0.7769\n",
      "Epoch 2/15\n",
      "60/60 [==============================] - 1s 19ms/step - loss: 0.3545 - accuracy: 0.8509 - val_loss: 0.5038 - val_accuracy: 0.7689\n",
      "Epoch 00002: early stopping\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "[CV]  pool_sizes=2, num_filters=128, kern_size=7, fully_connected=16, epochs=15, batch_size=76, total=   3.4s\n",
      "[CV] pool_sizes=2, num_filters=128, kern_size=7, fully_connected=16, epochs=15, batch_size=76 \n",
      "Epoch 1/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    3.4s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60/60 [==============================] - 1s 20ms/step - loss: 0.5187 - accuracy: 0.7528 - val_loss: 0.4886 - val_accuracy: 0.7729\n",
      "Epoch 2/15\n",
      "60/60 [==============================] - 1s 20ms/step - loss: 0.3513 - accuracy: 0.8509 - val_loss: 0.4968 - val_accuracy: 0.7789\n",
      "Epoch 00002: early stopping\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "[CV]  pool_sizes=2, num_filters=128, kern_size=7, fully_connected=16, epochs=15, batch_size=76, total=   3.3s\n",
      "[CV] pool_sizes=2, num_filters=128, kern_size=7, fully_connected=16, epochs=15, batch_size=76 \n",
      "Epoch 1/15\n",
      "60/60 [==============================] - 1s 21ms/step - loss: 0.5237 - accuracy: 0.7468 - val_loss: 0.4823 - val_accuracy: 0.7829\n",
      "Epoch 2/15\n",
      "60/60 [==============================] - 1s 21ms/step - loss: 0.3563 - accuracy: 0.8505 - val_loss: 0.4978 - val_accuracy: 0.7749\n",
      "Epoch 00002: early stopping\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "[CV]  pool_sizes=2, num_filters=128, kern_size=7, fully_connected=16, epochs=15, batch_size=76, total=   3.4s\n",
      "[CV] pool_sizes=2, num_filters=128, kern_size=7, fully_connected=16, epochs=15, batch_size=76 \n",
      "Epoch 1/15\n",
      "60/60 [==============================] - 1s 22ms/step - loss: 0.5093 - accuracy: 0.7606 - val_loss: 0.4941 - val_accuracy: 0.7709\n",
      "Epoch 2/15\n",
      "60/60 [==============================] - 1s 20ms/step - loss: 0.3362 - accuracy: 0.8547 - val_loss: 0.5293 - val_accuracy: 0.7769\n",
      "Epoch 00002: early stopping\n",
      "8/8 [==============================] - 0s 4ms/step\n",
      "[CV]  pool_sizes=2, num_filters=128, kern_size=7, fully_connected=16, epochs=15, batch_size=76, total=   3.5s\n",
      "[CV] pool_sizes=2, num_filters=128, kern_size=7, fully_connected=16, epochs=15, batch_size=76 \n",
      "Epoch 1/15\n",
      "60/60 [==============================] - 1s 22ms/step - loss: 0.5085 - accuracy: 0.7597 - val_loss: 0.5135 - val_accuracy: 0.7590\n",
      "Epoch 2/15\n",
      "60/60 [==============================] - 1s 20ms/step - loss: 0.3476 - accuracy: 0.8538 - val_loss: 0.4820 - val_accuracy: 0.7789\n",
      "Epoch 3/15\n",
      "60/60 [==============================] - 1s 21ms/step - loss: 0.2238 - accuracy: 0.9218 - val_loss: 0.5452 - val_accuracy: 0.7709\n",
      "Epoch 00003: early stopping\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "[CV]  pool_sizes=2, num_filters=128, kern_size=7, fully_connected=16, epochs=15, batch_size=76, total=   4.7s\n",
      "[CV] pool_sizes=2, num_filters=128, kern_size=7, fully_connected=16, epochs=15, batch_size=76 \n",
      "Epoch 1/15\n",
      "60/60 [==============================] - 1s 24ms/step - loss: 0.5302 - accuracy: 0.7407 - val_loss: 0.5132 - val_accuracy: 0.7709\n",
      "Epoch 2/15\n",
      "60/60 [==============================] - 1s 22ms/step - loss: 0.3500 - accuracy: 0.8534 - val_loss: 0.5738 - val_accuracy: 0.7649\n",
      "Epoch 00002: early stopping\n",
      "8/8 [==============================] - 0s 4ms/step\n",
      "[CV]  pool_sizes=2, num_filters=128, kern_size=7, fully_connected=16, epochs=15, batch_size=76, total=   3.7s\n",
      "[CV] pool_sizes=2, num_filters=128, kern_size=7, fully_connected=16, epochs=15, batch_size=76 \n",
      "Epoch 1/15\n",
      "60/60 [==============================] - 2s 27ms/step - loss: 0.5292 - accuracy: 0.7447 - val_loss: 0.5009 - val_accuracy: 0.7530\n",
      "Epoch 2/15\n",
      "60/60 [==============================] - 1s 23ms/step - loss: 0.3591 - accuracy: 0.8461 - val_loss: 0.4772 - val_accuracy: 0.7689\n",
      "Epoch 3/15\n",
      "60/60 [==============================] - 1s 22ms/step - loss: 0.2587 - accuracy: 0.9023 - val_loss: 0.5058 - val_accuracy: 0.7789\n",
      "Epoch 00003: early stopping\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "[CV]  pool_sizes=2, num_filters=128, kern_size=7, fully_connected=16, epochs=15, batch_size=76, total=   5.4s\n",
      "[CV] pool_sizes=2, num_filters=128, kern_size=7, fully_connected=16, epochs=15, batch_size=76 \n",
      "Epoch 1/15\n",
      "60/60 [==============================] - 1s 24ms/step - loss: 0.5004 - accuracy: 0.7671 - val_loss: 0.5019 - val_accuracy: 0.7709\n",
      "Epoch 2/15\n",
      "60/60 [==============================] - 1s 22ms/step - loss: 0.3369 - accuracy: 0.8625 - val_loss: 0.4838 - val_accuracy: 0.8028\n",
      "Epoch 3/15\n",
      "60/60 [==============================] - 1s 22ms/step - loss: 0.2193 - accuracy: 0.9240 - val_loss: 0.5856 - val_accuracy: 0.7510\n",
      "Epoch 00003: early stopping\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "[CV]  pool_sizes=2, num_filters=128, kern_size=7, fully_connected=16, epochs=15, batch_size=76, total=   4.9s\n",
      "[CV] pool_sizes=2, num_filters=128, kern_size=7, fully_connected=16, epochs=15, batch_size=76 \n",
      "Epoch 1/15\n",
      "60/60 [==============================] - 1s 24ms/step - loss: 0.5191 - accuracy: 0.7409 - val_loss: 0.4788 - val_accuracy: 0.7749\n",
      "Epoch 2/15\n",
      "60/60 [==============================] - 1s 23ms/step - loss: 0.3620 - accuracy: 0.8468 - val_loss: 0.4970 - val_accuracy: 0.7869\n",
      "Epoch 00002: early stopping\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "[CV]  pool_sizes=2, num_filters=128, kern_size=7, fully_connected=16, epochs=15, batch_size=76, total=   3.6s\n",
      "[CV] pool_sizes=2, num_filters=128, kern_size=7, fully_connected=16, epochs=15, batch_size=76 \n",
      "Epoch 1/15\n",
      "60/60 [==============================] - 1s 22ms/step - loss: 0.5260 - accuracy: 0.7476 - val_loss: 0.4174 - val_accuracy: 0.8227\n",
      "Epoch 2/15\n",
      "60/60 [==============================] - 1s 23ms/step - loss: 0.3741 - accuracy: 0.8364 - val_loss: 0.3852 - val_accuracy: 0.8466\n",
      "Epoch 3/15\n",
      "60/60 [==============================] - 1s 23ms/step - loss: 0.2611 - accuracy: 0.9032 - val_loss: 0.3889 - val_accuracy: 0.8347\n",
      "Epoch 00003: early stopping\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "[CV]  pool_sizes=2, num_filters=128, kern_size=7, fully_connected=16, epochs=15, batch_size=76, total=   4.9s\n",
      "[CV] pool_sizes=2, num_filters=128, kern_size=5, fully_connected=16, epochs=15, batch_size=76 \n",
      "Epoch 1/15\n",
      "60/60 [==============================] - 1s 22ms/step - loss: 0.5299 - accuracy: 0.7369 - val_loss: 0.5009 - val_accuracy: 0.7729\n",
      "Epoch 2/15\n",
      "60/60 [==============================] - 1s 23ms/step - loss: 0.3793 - accuracy: 0.8365 - val_loss: 0.4681 - val_accuracy: 0.7769\n",
      "Epoch 3/15\n",
      "60/60 [==============================] - 1s 23ms/step - loss: 0.2734 - accuracy: 0.8904 - val_loss: 0.5449 - val_accuracy: 0.7829\n",
      "Epoch 00003: early stopping\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "[CV]  pool_sizes=2, num_filters=128, kern_size=5, fully_connected=16, epochs=15, batch_size=76, total=   4.9s\n",
      "[CV] pool_sizes=2, num_filters=128, kern_size=5, fully_connected=16, epochs=15, batch_size=76 \n",
      "Epoch 1/15\n",
      "60/60 [==============================] - 1s 24ms/step - loss: 0.5346 - accuracy: 0.7362 - val_loss: 0.5115 - val_accuracy: 0.7610\n",
      "Epoch 2/15\n",
      "60/60 [==============================] - 1s 23ms/step - loss: 0.3706 - accuracy: 0.8414 - val_loss: 0.5057 - val_accuracy: 0.7610\n",
      "Epoch 3/15\n",
      "60/60 [==============================] - 1s 23ms/step - loss: 0.2679 - accuracy: 0.8968 - val_loss: 0.5252 - val_accuracy: 0.7331\n",
      "Epoch 00003: early stopping\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "[CV]  pool_sizes=2, num_filters=128, kern_size=5, fully_connected=16, epochs=15, batch_size=76, total=   5.0s\n",
      "[CV] pool_sizes=2, num_filters=128, kern_size=5, fully_connected=16, epochs=15, batch_size=76 \n",
      "Epoch 1/15\n",
      "60/60 [==============================] - 1s 23ms/step - loss: 0.5174 - accuracy: 0.7440 - val_loss: 0.5306 - val_accuracy: 0.7729\n",
      "Epoch 2/15\n",
      "60/60 [==============================] - 1s 24ms/step - loss: 0.3482 - accuracy: 0.8534 - val_loss: 0.5274 - val_accuracy: 0.7669\n",
      "Epoch 3/15\n",
      "60/60 [==============================] - 1s 24ms/step - loss: 0.2423 - accuracy: 0.9103 - val_loss: 0.5247 - val_accuracy: 0.7649\n",
      "Epoch 4/15\n",
      "60/60 [==============================] - 1s 23ms/step - loss: 0.1473 - accuracy: 0.9497 - val_loss: 0.6221 - val_accuracy: 0.7490\n",
      "Epoch 00004: early stopping\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "[CV]  pool_sizes=2, num_filters=128, kern_size=5, fully_connected=16, epochs=15, batch_size=76, total=   6.5s\n",
      "[CV] pool_sizes=2, num_filters=128, kern_size=5, fully_connected=16, epochs=15, batch_size=76 \n",
      "Epoch 1/15\n",
      "60/60 [==============================] - 1s 24ms/step - loss: 0.5200 - accuracy: 0.7519 - val_loss: 0.4876 - val_accuracy: 0.7749\n",
      "Epoch 2/15\n",
      "60/60 [==============================] - 1s 24ms/step - loss: 0.3747 - accuracy: 0.8359 - val_loss: 0.4695 - val_accuracy: 0.7749\n",
      "Epoch 3/15\n",
      "60/60 [==============================] - 1s 20ms/step - loss: 0.2456 - accuracy: 0.9094 - val_loss: 0.5114 - val_accuracy: 0.7709\n",
      "Epoch 00003: early stopping\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "[CV]  pool_sizes=2, num_filters=128, kern_size=5, fully_connected=16, epochs=15, batch_size=76, total=   4.9s\n",
      "[CV] pool_sizes=2, num_filters=128, kern_size=5, fully_connected=16, epochs=15, batch_size=76 \n",
      "Epoch 1/15\n",
      "60/60 [==============================] - 1s 20ms/step - loss: 0.5301 - accuracy: 0.7382 - val_loss: 0.4878 - val_accuracy: 0.7649\n",
      "Epoch 2/15\n",
      "60/60 [==============================] - 1s 19ms/step - loss: 0.3662 - accuracy: 0.8427 - val_loss: 0.4747 - val_accuracy: 0.7769\n",
      "Epoch 3/15\n",
      "60/60 [==============================] - 1s 20ms/step - loss: 0.2593 - accuracy: 0.9032 - val_loss: 0.5236 - val_accuracy: 0.7689\n",
      "Epoch 00003: early stopping\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "[CV]  pool_sizes=2, num_filters=128, kern_size=5, fully_connected=16, epochs=15, batch_size=76, total=   4.4s\n",
      "[CV] pool_sizes=2, num_filters=128, kern_size=5, fully_connected=16, epochs=15, batch_size=76 \n",
      "Epoch 1/15\n",
      "60/60 [==============================] - 1s 21ms/step - loss: 0.5324 - accuracy: 0.7391 - val_loss: 0.5071 - val_accuracy: 0.7809\n",
      "Epoch 2/15\n",
      "60/60 [==============================] - 1s 20ms/step - loss: 0.3693 - accuracy: 0.8408 - val_loss: 0.4696 - val_accuracy: 0.7908\n",
      "Epoch 3/15\n",
      "60/60 [==============================] - 1s 21ms/step - loss: 0.2544 - accuracy: 0.9037 - val_loss: 0.5340 - val_accuracy: 0.7749\n",
      "Epoch 00003: early stopping\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "[CV]  pool_sizes=2, num_filters=128, kern_size=5, fully_connected=16, epochs=15, batch_size=76, total=   4.5s\n",
      "[CV] pool_sizes=2, num_filters=128, kern_size=5, fully_connected=16, epochs=15, batch_size=76 \n",
      "Epoch 1/15\n",
      "60/60 [==============================] - 1s 21ms/step - loss: 0.5401 - accuracy: 0.7274 - val_loss: 0.4902 - val_accuracy: 0.7610\n",
      "Epoch 2/15\n",
      "60/60 [==============================] - 1s 20ms/step - loss: 0.3624 - accuracy: 0.8439 - val_loss: 0.4793 - val_accuracy: 0.7769\n",
      "Epoch 3/15\n",
      "60/60 [==============================] - 1s 21ms/step - loss: 0.2523 - accuracy: 0.9032 - val_loss: 0.5403 - val_accuracy: 0.7709\n",
      "Epoch 00003: early stopping\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "[CV]  pool_sizes=2, num_filters=128, kern_size=5, fully_connected=16, epochs=15, batch_size=76, total=   4.5s\n",
      "[CV] pool_sizes=2, num_filters=128, kern_size=5, fully_connected=16, epochs=15, batch_size=76 \n",
      "Epoch 1/15\n",
      "60/60 [==============================] - 1s 21ms/step - loss: 0.5087 - accuracy: 0.7597 - val_loss: 0.4885 - val_accuracy: 0.7749\n",
      "Epoch 2/15\n",
      "60/60 [==============================] - 1s 20ms/step - loss: 0.3408 - accuracy: 0.8567 - val_loss: 0.4793 - val_accuracy: 0.7709\n",
      "Epoch 3/15\n",
      "60/60 [==============================] - 1s 20ms/step - loss: 0.2277 - accuracy: 0.9147 - val_loss: 0.5046 - val_accuracy: 0.7709\n",
      "Epoch 00003: early stopping\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "[CV]  pool_sizes=2, num_filters=128, kern_size=5, fully_connected=16, epochs=15, batch_size=76, total=   4.5s\n",
      "[CV] pool_sizes=2, num_filters=128, kern_size=5, fully_connected=16, epochs=15, batch_size=76 \n",
      "Epoch 1/15\n",
      "60/60 [==============================] - 1s 21ms/step - loss: 0.5053 - accuracy: 0.7611 - val_loss: 0.4852 - val_accuracy: 0.7689\n",
      "Epoch 2/15\n",
      "60/60 [==============================] - 1s 19ms/step - loss: 0.3472 - accuracy: 0.8532 - val_loss: 0.5181 - val_accuracy: 0.7749\n",
      "Epoch 00002: early stopping\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "[CV]  pool_sizes=2, num_filters=128, kern_size=5, fully_connected=16, epochs=15, batch_size=76, total=   3.2s\n",
      "[CV] pool_sizes=2, num_filters=128, kern_size=5, fully_connected=16, epochs=15, batch_size=76 \n",
      "Epoch 1/15\n",
      "60/60 [==============================] - 1s 21ms/step - loss: 0.5201 - accuracy: 0.7482 - val_loss: 0.4031 - val_accuracy: 0.8367\n",
      "Epoch 2/15\n",
      "60/60 [==============================] - 1s 21ms/step - loss: 0.3529 - accuracy: 0.8481 - val_loss: 0.4232 - val_accuracy: 0.8187\n",
      "Epoch 00002: early stopping\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "[CV]  pool_sizes=2, num_filters=128, kern_size=5, fully_connected=16, epochs=15, batch_size=76, total=   3.3s\n",
      "[CV] pool_sizes=2, num_filters=128, kern_size=7, fully_connected=20, epochs=15, batch_size=88 \n",
      "Epoch 1/15\n",
      "52/52 [==============================] - 1s 24ms/step - loss: 0.5302 - accuracy: 0.7409 - val_loss: 0.5268 - val_accuracy: 0.7610\n",
      "Epoch 2/15\n",
      "52/52 [==============================] - 1s 23ms/step - loss: 0.3605 - accuracy: 0.8456 - val_loss: 0.5513 - val_accuracy: 0.7689\n",
      "Epoch 00002: early stopping\n",
      "7/7 [==============================] - 0s 3ms/step\n",
      "[CV]  pool_sizes=2, num_filters=128, kern_size=7, fully_connected=20, epochs=15, batch_size=88, total=   3.2s\n",
      "[CV] pool_sizes=2, num_filters=128, kern_size=7, fully_connected=20, epochs=15, batch_size=88 \n",
      "Epoch 1/15\n",
      "52/52 [==============================] - 1s 24ms/step - loss: 0.5315 - accuracy: 0.7502 - val_loss: 0.4940 - val_accuracy: 0.7669\n",
      "Epoch 2/15\n",
      "52/52 [==============================] - 1s 23ms/step - loss: 0.3625 - accuracy: 0.8452 - val_loss: 0.4866 - val_accuracy: 0.7729\n",
      "Epoch 3/15\n",
      "52/52 [==============================] - 1s 23ms/step - loss: 0.2560 - accuracy: 0.9063 - val_loss: 0.5241 - val_accuracy: 0.7709\n",
      "Epoch 00003: early stopping\n",
      "7/7 [==============================] - 0s 4ms/step\n",
      "[CV]  pool_sizes=2, num_filters=128, kern_size=7, fully_connected=20, epochs=15, batch_size=88, total=   4.4s\n",
      "[CV] pool_sizes=2, num_filters=128, kern_size=7, fully_connected=20, epochs=15, batch_size=88 \n",
      "Epoch 1/15\n",
      "52/52 [==============================] - 1s 24ms/step - loss: 0.5350 - accuracy: 0.7367 - val_loss: 0.5012 - val_accuracy: 0.7649\n",
      "Epoch 2/15\n",
      "52/52 [==============================] - 1s 23ms/step - loss: 0.3715 - accuracy: 0.8381 - val_loss: 0.4679 - val_accuracy: 0.7809\n",
      "Epoch 3/15\n",
      "52/52 [==============================] - 1s 23ms/step - loss: 0.2674 - accuracy: 0.9001 - val_loss: 0.5020 - val_accuracy: 0.7729\n",
      "Epoch 00003: early stopping\n",
      "7/7 [==============================] - 0s 4ms/step\n",
      "[CV]  pool_sizes=2, num_filters=128, kern_size=7, fully_connected=20, epochs=15, batch_size=88, total=   4.5s\n",
      "[CV] pool_sizes=2, num_filters=128, kern_size=7, fully_connected=20, epochs=15, batch_size=88 \n",
      "Epoch 1/15\n",
      "52/52 [==============================] - 1s 23ms/step - loss: 0.5206 - accuracy: 0.7453 - val_loss: 0.4886 - val_accuracy: 0.7410\n",
      "Epoch 2/15\n",
      "52/52 [==============================] - 1s 22ms/step - loss: 0.3556 - accuracy: 0.8507 - val_loss: 0.4860 - val_accuracy: 0.7729\n",
      "Epoch 3/15\n",
      "52/52 [==============================] - 1s 22ms/step - loss: 0.2450 - accuracy: 0.9094 - val_loss: 0.5104 - val_accuracy: 0.7769\n",
      "Epoch 00003: early stopping\n",
      "7/7 [==============================] - 0s 3ms/step\n",
      "[CV]  pool_sizes=2, num_filters=128, kern_size=7, fully_connected=20, epochs=15, batch_size=88, total=   4.3s\n",
      "[CV] pool_sizes=2, num_filters=128, kern_size=7, fully_connected=20, epochs=15, batch_size=88 \n",
      "Epoch 1/15\n",
      "52/52 [==============================] - 1s 24ms/step - loss: 0.5248 - accuracy: 0.7404 - val_loss: 0.5105 - val_accuracy: 0.7629\n",
      "Epoch 2/15\n",
      "52/52 [==============================] - 1s 22ms/step - loss: 0.3583 - accuracy: 0.8472 - val_loss: 0.5035 - val_accuracy: 0.7610\n",
      "Epoch 3/15\n",
      "52/52 [==============================] - 1s 23ms/step - loss: 0.2459 - accuracy: 0.9105 - val_loss: 0.5536 - val_accuracy: 0.7610\n",
      "Epoch 00003: early stopping\n",
      "7/7 [==============================] - 0s 4ms/step\n",
      "[CV]  pool_sizes=2, num_filters=128, kern_size=7, fully_connected=20, epochs=15, batch_size=88, total=   4.5s\n",
      "[CV] pool_sizes=2, num_filters=128, kern_size=7, fully_connected=20, epochs=15, batch_size=88 \n",
      "Epoch 1/15\n",
      "52/52 [==============================] - 1s 24ms/step - loss: 0.5086 - accuracy: 0.7597 - val_loss: 0.4846 - val_accuracy: 0.7769\n",
      "Epoch 2/15\n",
      "52/52 [==============================] - 1s 23ms/step - loss: 0.3447 - accuracy: 0.8545 - val_loss: 0.4847 - val_accuracy: 0.7789\n",
      "Epoch 00002: early stopping\n",
      "7/7 [==============================] - 0s 3ms/step\n",
      "[CV]  pool_sizes=2, num_filters=128, kern_size=7, fully_connected=20, epochs=15, batch_size=88, total=   3.4s\n",
      "[CV] pool_sizes=2, num_filters=128, kern_size=7, fully_connected=20, epochs=15, batch_size=88 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "52/52 [==============================] - 1s 24ms/step - loss: 0.5129 - accuracy: 0.7635 - val_loss: 0.4959 - val_accuracy: 0.7629\n",
      "Epoch 2/15\n",
      "52/52 [==============================] - 1s 22ms/step - loss: 0.3367 - accuracy: 0.8603 - val_loss: 0.5000 - val_accuracy: 0.7829\n",
      "Epoch 00002: early stopping\n",
      "7/7 [==============================] - 0s 4ms/step\n",
      "[CV]  pool_sizes=2, num_filters=128, kern_size=7, fully_connected=20, epochs=15, batch_size=88, total=   3.3s\n",
      "[CV] pool_sizes=2, num_filters=128, kern_size=7, fully_connected=20, epochs=15, batch_size=88 \n",
      "Epoch 1/15\n",
      "52/52 [==============================] - 1s 23ms/step - loss: 0.5287 - accuracy: 0.7416 - val_loss: 0.4938 - val_accuracy: 0.7610\n",
      "Epoch 2/15\n",
      "52/52 [==============================] - 1s 22ms/step - loss: 0.3541 - accuracy: 0.8527 - val_loss: 0.4976 - val_accuracy: 0.7769\n",
      "Epoch 00002: early stopping\n",
      "7/7 [==============================] - 0s 4ms/step\n",
      "[CV]  pool_sizes=2, num_filters=128, kern_size=7, fully_connected=20, epochs=15, batch_size=88, total=   3.3s\n",
      "[CV] pool_sizes=2, num_filters=128, kern_size=7, fully_connected=20, epochs=15, batch_size=88 \n",
      "Epoch 1/15\n",
      "52/52 [==============================] - 1s 24ms/step - loss: 0.5217 - accuracy: 0.7445 - val_loss: 0.5046 - val_accuracy: 0.7709\n",
      "Epoch 2/15\n",
      "52/52 [==============================] - 1s 23ms/step - loss: 0.3627 - accuracy: 0.8446 - val_loss: 0.4788 - val_accuracy: 0.7829\n",
      "Epoch 3/15\n",
      "52/52 [==============================] - 1s 23ms/step - loss: 0.2522 - accuracy: 0.9059 - val_loss: 0.5006 - val_accuracy: 0.7789\n",
      "Epoch 00003: early stopping\n",
      "7/7 [==============================] - 0s 3ms/step\n",
      "[CV]  pool_sizes=2, num_filters=128, kern_size=7, fully_connected=20, epochs=15, batch_size=88, total=   4.6s\n",
      "[CV] pool_sizes=2, num_filters=128, kern_size=7, fully_connected=20, epochs=15, batch_size=88 \n",
      "Epoch 1/15\n",
      "52/52 [==============================] - 1s 24ms/step - loss: 0.5226 - accuracy: 0.7442 - val_loss: 0.4334 - val_accuracy: 0.8127\n",
      "Epoch 2/15\n",
      "52/52 [==============================] - 1s 22ms/step - loss: 0.3562 - accuracy: 0.8461 - val_loss: 0.4054 - val_accuracy: 0.8187\n",
      "Epoch 3/15\n",
      "52/52 [==============================] - 1s 23ms/step - loss: 0.2489 - accuracy: 0.9081 - val_loss: 0.4030 - val_accuracy: 0.8207\n",
      "Epoch 4/15\n",
      "52/52 [==============================] - 1s 24ms/step - loss: 0.1462 - accuracy: 0.9542 - val_loss: 0.4829 - val_accuracy: 0.8088\n",
      "Epoch 00004: early stopping\n",
      "7/7 [==============================] - 0s 4ms/step\n",
      "[CV]  pool_sizes=2, num_filters=128, kern_size=7, fully_connected=20, epochs=15, batch_size=88, total=   5.8s\n",
      "[CV] pool_sizes=10, num_filters=128, kern_size=5, fully_connected=16, epochs=15, batch_size=88 \n",
      "Epoch 1/15\n",
      "52/52 [==============================] - 1s 22ms/step - loss: 0.5122 - accuracy: 0.7466 - val_loss: 0.4852 - val_accuracy: 0.7649\n",
      "Epoch 2/15\n",
      "52/52 [==============================] - 1s 20ms/step - loss: 0.3516 - accuracy: 0.8529 - val_loss: 0.4638 - val_accuracy: 0.7869\n",
      "Epoch 3/15\n",
      "52/52 [==============================] - 1s 20ms/step - loss: 0.2548 - accuracy: 0.9074 - val_loss: 0.4929 - val_accuracy: 0.7948\n",
      "Epoch 00003: early stopping\n",
      "7/7 [==============================] - 0s 3ms/step\n",
      "[CV]  pool_sizes=10, num_filters=128, kern_size=5, fully_connected=16, epochs=15, batch_size=88, total=   4.2s\n",
      "[CV] pool_sizes=10, num_filters=128, kern_size=5, fully_connected=16, epochs=15, batch_size=88 \n",
      "Epoch 1/15\n",
      "52/52 [==============================] - 1s 21ms/step - loss: 0.5179 - accuracy: 0.7542 - val_loss: 0.5429 - val_accuracy: 0.7390\n",
      "Epoch 2/15\n",
      "52/52 [==============================] - 1s 19ms/step - loss: 0.3616 - accuracy: 0.8523 - val_loss: 0.4770 - val_accuracy: 0.7789\n",
      "Epoch 3/15\n",
      "52/52 [==============================] - 1s 20ms/step - loss: 0.2600 - accuracy: 0.9032 - val_loss: 0.5349 - val_accuracy: 0.7649\n",
      "Epoch 00003: early stopping\n",
      "7/7 [==============================] - 0s 3ms/step\n",
      "[CV]  pool_sizes=10, num_filters=128, kern_size=5, fully_connected=16, epochs=15, batch_size=88, total=   4.0s\n",
      "[CV] pool_sizes=10, num_filters=128, kern_size=5, fully_connected=16, epochs=15, batch_size=88 \n",
      "Epoch 1/15\n",
      "52/52 [==============================] - 1s 21ms/step - loss: 0.5154 - accuracy: 0.7460 - val_loss: 0.5004 - val_accuracy: 0.7669\n",
      "Epoch 2/15\n",
      "52/52 [==============================] - 1s 19ms/step - loss: 0.3562 - accuracy: 0.8512 - val_loss: 0.4759 - val_accuracy: 0.7809\n",
      "Epoch 3/15\n",
      "52/52 [==============================] - 1s 20ms/step - loss: 0.2593 - accuracy: 0.9041 - val_loss: 0.4855 - val_accuracy: 0.7809\n",
      "Epoch 00003: early stopping\n",
      "7/7 [==============================] - 0s 3ms/step\n",
      "[CV]  pool_sizes=10, num_filters=128, kern_size=5, fully_connected=16, epochs=15, batch_size=88, total=   4.0s\n",
      "[CV] pool_sizes=10, num_filters=128, kern_size=5, fully_connected=16, epochs=15, batch_size=88 \n",
      "Epoch 1/15\n",
      "52/52 [==============================] - 1s 21ms/step - loss: 0.5128 - accuracy: 0.7537 - val_loss: 0.5169 - val_accuracy: 0.7610\n",
      "Epoch 2/15\n",
      "52/52 [==============================] - 1s 19ms/step - loss: 0.3617 - accuracy: 0.8452 - val_loss: 0.4663 - val_accuracy: 0.7769\n",
      "Epoch 3/15\n",
      "52/52 [==============================] - 1s 20ms/step - loss: 0.2616 - accuracy: 0.9061 - val_loss: 0.4773 - val_accuracy: 0.7888\n",
      "Epoch 00003: early stopping\n",
      "7/7 [==============================] - 0s 3ms/step\n",
      "[CV]  pool_sizes=10, num_filters=128, kern_size=5, fully_connected=16, epochs=15, batch_size=88, total=   4.0s\n",
      "[CV] pool_sizes=10, num_filters=128, kern_size=5, fully_connected=16, epochs=15, batch_size=88 \n",
      "Epoch 1/15\n",
      "52/52 [==============================] - 1s 21ms/step - loss: 0.5059 - accuracy: 0.7575 - val_loss: 0.4818 - val_accuracy: 0.7729\n",
      "Epoch 2/15\n",
      "52/52 [==============================] - 1s 19ms/step - loss: 0.3389 - accuracy: 0.8620 - val_loss: 0.4590 - val_accuracy: 0.7948\n",
      "Epoch 3/15\n",
      "52/52 [==============================] - 1s 20ms/step - loss: 0.2347 - accuracy: 0.9156 - val_loss: 0.4926 - val_accuracy: 0.7908\n",
      "Epoch 00003: early stopping\n",
      "7/7 [==============================] - 0s 3ms/step\n",
      "[CV]  pool_sizes=10, num_filters=128, kern_size=5, fully_connected=16, epochs=15, batch_size=88, total=   4.0s\n",
      "[CV] pool_sizes=10, num_filters=128, kern_size=5, fully_connected=16, epochs=15, batch_size=88 \n",
      "Epoch 1/15\n",
      "52/52 [==============================] - 1s 21ms/step - loss: 0.5200 - accuracy: 0.7502 - val_loss: 0.5106 - val_accuracy: 0.7550\n",
      "Epoch 2/15\n",
      "52/52 [==============================] - 1s 19ms/step - loss: 0.3606 - accuracy: 0.8490 - val_loss: 0.4582 - val_accuracy: 0.8008\n",
      "Epoch 3/15\n",
      "52/52 [==============================] - 1s 20ms/step - loss: 0.2609 - accuracy: 0.9052 - val_loss: 0.4901 - val_accuracy: 0.7908\n",
      "Epoch 00003: early stopping\n",
      "7/7 [==============================] - 0s 3ms/step\n",
      "[CV]  pool_sizes=10, num_filters=128, kern_size=5, fully_connected=16, epochs=15, batch_size=88, total=   4.0s\n",
      "[CV] pool_sizes=10, num_filters=128, kern_size=5, fully_connected=16, epochs=15, batch_size=88 \n",
      "Epoch 1/15\n",
      "52/52 [==============================] - 6s 107ms/step - loss: 0.5365 - accuracy: 0.7434 - val_loss: 0.5076 - val_accuracy: 0.7590\n",
      "Epoch 2/15\n",
      "52/52 [==============================] - 1s 17ms/step - loss: 0.3839 - accuracy: 0.8359 - val_loss: 0.4942 - val_accuracy: 0.7629\n",
      "Epoch 3/15\n",
      "52/52 [==============================] - 1s 17ms/step - loss: 0.2884 - accuracy: 0.8880 - val_loss: 0.4410 - val_accuracy: 0.8068\n",
      "Epoch 4/15\n",
      "52/52 [==============================] - 1s 17ms/step - loss: 0.2028 - accuracy: 0.9274 - val_loss: 0.4614 - val_accuracy: 0.8008\n",
      "Epoch 00004: early stopping\n",
      "7/7 [==============================] - 0s 3ms/step\n",
      "[CV]  pool_sizes=10, num_filters=128, kern_size=5, fully_connected=16, epochs=15, batch_size=88, total=   9.2s\n",
      "[CV] pool_sizes=10, num_filters=128, kern_size=5, fully_connected=16, epochs=15, batch_size=88 \n",
      "Epoch 1/15\n",
      "52/52 [==============================] - 1s 20ms/step - loss: 0.6122 - accuracy: 0.6306 - val_loss: 0.5601 - val_accuracy: 0.7311\n",
      "Epoch 2/15\n",
      "52/52 [==============================] - 1s 18ms/step - loss: 0.4237 - accuracy: 0.8184 - val_loss: 0.4691 - val_accuracy: 0.7729\n",
      "Epoch 3/15\n",
      "52/52 [==============================] - 1s 18ms/step - loss: 0.3116 - accuracy: 0.8747 - val_loss: 0.4439 - val_accuracy: 0.8028\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/15\n",
      "52/52 [==============================] - 1s 18ms/step - loss: 0.2168 - accuracy: 0.9218 - val_loss: 0.5038 - val_accuracy: 0.7849\n",
      "Epoch 00004: early stopping\n",
      "7/7 [==============================] - 0s 3ms/step\n",
      "[CV]  pool_sizes=10, num_filters=128, kern_size=5, fully_connected=16, epochs=15, batch_size=88, total=   4.7s\n",
      "[CV] pool_sizes=10, num_filters=128, kern_size=5, fully_connected=16, epochs=15, batch_size=88 \n",
      "Epoch 1/15\n",
      "52/52 [==============================] - 1s 20ms/step - loss: 0.5219 - accuracy: 0.7453 - val_loss: 0.5039 - val_accuracy: 0.7789\n",
      "Epoch 2/15\n",
      "52/52 [==============================] - 1s 19ms/step - loss: 0.3608 - accuracy: 0.8470 - val_loss: 0.4752 - val_accuracy: 0.7968\n",
      "Epoch 3/15\n",
      "52/52 [==============================] - 1s 19ms/step - loss: 0.2632 - accuracy: 0.8973 - val_loss: 0.4823 - val_accuracy: 0.7789\n",
      "Epoch 00003: early stopping\n",
      "7/7 [==============================] - 0s 3ms/step\n",
      "[CV]  pool_sizes=10, num_filters=128, kern_size=5, fully_connected=16, epochs=15, batch_size=88, total=   3.9s\n",
      "[CV] pool_sizes=10, num_filters=128, kern_size=5, fully_connected=16, epochs=15, batch_size=88 \n",
      "Epoch 1/15\n",
      "52/52 [==============================] - 1s 20ms/step - loss: 0.5164 - accuracy: 0.7502 - val_loss: 0.4034 - val_accuracy: 0.8147\n",
      "Epoch 2/15\n",
      "52/52 [==============================] - 1s 19ms/step - loss: 0.3673 - accuracy: 0.8434 - val_loss: 0.3863 - val_accuracy: 0.8386\n",
      "Epoch 3/15\n",
      "52/52 [==============================] - 1s 20ms/step - loss: 0.2689 - accuracy: 0.8984 - val_loss: 0.4100 - val_accuracy: 0.8267\n",
      "Epoch 00003: early stopping\n",
      "7/7 [==============================] - 0s 3ms/step\n",
      "[CV]  pool_sizes=10, num_filters=128, kern_size=5, fully_connected=16, epochs=15, batch_size=88, total=   4.0s\n",
      "[CV] pool_sizes=2, num_filters=256, kern_size=5, fully_connected=20, epochs=15, batch_size=88 \n",
      "Epoch 1/15\n",
      "52/52 [==============================] - 2s 29ms/step - loss: 0.5219 - accuracy: 0.7404 - val_loss: 0.4846 - val_accuracy: 0.7709\n",
      "Epoch 2/15\n",
      "52/52 [==============================] - 1s 28ms/step - loss: 0.3614 - accuracy: 0.8454 - val_loss: 0.4625 - val_accuracy: 0.7849\n",
      "Epoch 3/15\n",
      "52/52 [==============================] - 2s 31ms/step - loss: 0.2608 - accuracy: 0.9030 - val_loss: 0.5017 - val_accuracy: 0.7829\n",
      "Epoch 00003: early stopping\n",
      "7/7 [==============================] - 0s 5ms/step\n",
      "[CV]  pool_sizes=2, num_filters=256, kern_size=5, fully_connected=20, epochs=15, batch_size=88, total=   5.6s\n",
      "[CV] pool_sizes=2, num_filters=256, kern_size=5, fully_connected=20, epochs=15, batch_size=88 \n",
      "Epoch 1/15\n",
      "52/52 [==============================] - 2s 29ms/step - loss: 0.5207 - accuracy: 0.7491 - val_loss: 0.4881 - val_accuracy: 0.7749\n",
      "Epoch 2/15\n",
      "52/52 [==============================] - 1s 28ms/step - loss: 0.3458 - accuracy: 0.8589 - val_loss: 0.4829 - val_accuracy: 0.7689\n",
      "Epoch 3/15\n",
      "52/52 [==============================] - 2s 29ms/step - loss: 0.2330 - accuracy: 0.9165 - val_loss: 0.5407 - val_accuracy: 0.7669\n",
      "Epoch 00003: early stopping\n",
      "7/7 [==============================] - 0s 5ms/step\n",
      "[CV]  pool_sizes=2, num_filters=256, kern_size=5, fully_connected=20, epochs=15, batch_size=88, total=   5.5s\n",
      "[CV] pool_sizes=2, num_filters=256, kern_size=5, fully_connected=20, epochs=15, batch_size=88 \n",
      "Epoch 1/15\n",
      "52/52 [==============================] - 2s 30ms/step - loss: 0.5251 - accuracy: 0.7389 - val_loss: 0.4753 - val_accuracy: 0.7789\n",
      "Epoch 2/15\n",
      "52/52 [==============================] - 1s 28ms/step - loss: 0.3571 - accuracy: 0.8518 - val_loss: 0.4645 - val_accuracy: 0.7789\n",
      "Epoch 3/15\n",
      "52/52 [==============================] - 2s 32ms/step - loss: 0.2490 - accuracy: 0.9063 - val_loss: 0.5280 - val_accuracy: 0.7789\n",
      "Epoch 00003: early stopping\n",
      "7/7 [==============================] - 0s 5ms/step\n",
      "[CV]  pool_sizes=2, num_filters=256, kern_size=5, fully_connected=20, epochs=15, batch_size=88, total=   5.7s\n",
      "[CV] pool_sizes=2, num_filters=256, kern_size=5, fully_connected=20, epochs=15, batch_size=88 \n",
      "Epoch 1/15\n",
      "52/52 [==============================] - 2s 30ms/step - loss: 0.5508 - accuracy: 0.7276 - val_loss: 0.4982 - val_accuracy: 0.7829\n",
      "Epoch 2/15\n",
      "52/52 [==============================] - 1s 28ms/step - loss: 0.3723 - accuracy: 0.8394 - val_loss: 0.4651 - val_accuracy: 0.7649\n",
      "Epoch 3/15\n",
      "52/52 [==============================] - 2s 29ms/step - loss: 0.2691 - accuracy: 0.8983 - val_loss: 0.6119 - val_accuracy: 0.7709\n",
      "Epoch 00003: early stopping\n",
      "7/7 [==============================] - 0s 5ms/step\n",
      "[CV]  pool_sizes=2, num_filters=256, kern_size=5, fully_connected=20, epochs=15, batch_size=88, total=   5.5s\n",
      "[CV] pool_sizes=2, num_filters=256, kern_size=5, fully_connected=20, epochs=15, batch_size=88 \n",
      "Epoch 1/15\n",
      "52/52 [==============================] - 2s 32ms/step - loss: 0.5163 - accuracy: 0.7455 - val_loss: 0.4932 - val_accuracy: 0.7669\n",
      "Epoch 2/15\n",
      "52/52 [==============================] - 2s 31ms/step - loss: 0.3407 - accuracy: 0.8580 - val_loss: 0.4969 - val_accuracy: 0.7809\n",
      "Epoch 00002: early stopping\n",
      "7/7 [==============================] - 0s 4ms/step\n",
      "[CV]  pool_sizes=2, num_filters=256, kern_size=5, fully_connected=20, epochs=15, batch_size=88, total=   4.2s\n",
      "[CV] pool_sizes=2, num_filters=256, kern_size=5, fully_connected=20, epochs=15, batch_size=88 \n",
      "Epoch 1/15\n",
      "52/52 [==============================] - 2s 29ms/step - loss: 0.5108 - accuracy: 0.7522 - val_loss: 0.4869 - val_accuracy: 0.7689\n",
      "Epoch 2/15\n",
      "52/52 [==============================] - 1s 28ms/step - loss: 0.3560 - accuracy: 0.8490 - val_loss: 0.5132 - val_accuracy: 0.7789\n",
      "Epoch 00002: early stopping\n",
      "7/7 [==============================] - 0s 4ms/step\n",
      "[CV]  pool_sizes=2, num_filters=256, kern_size=5, fully_connected=20, epochs=15, batch_size=88, total=   4.0s\n",
      "[CV] pool_sizes=2, num_filters=256, kern_size=5, fully_connected=20, epochs=15, batch_size=88 \n",
      "Epoch 1/15\n",
      "52/52 [==============================] - 2s 30ms/step - loss: 0.5282 - accuracy: 0.7504 - val_loss: 0.4794 - val_accuracy: 0.7709\n",
      "Epoch 2/15\n",
      "52/52 [==============================] - 1s 28ms/step - loss: 0.3596 - accuracy: 0.8434 - val_loss: 0.4708 - val_accuracy: 0.7789\n",
      "Epoch 3/15\n",
      "52/52 [==============================] - 2s 30ms/step - loss: 0.2441 - accuracy: 0.9046 - val_loss: 0.5167 - val_accuracy: 0.7789\n",
      "Epoch 00003: early stopping\n",
      "7/7 [==============================] - 0s 4ms/step\n",
      "[CV]  pool_sizes=2, num_filters=256, kern_size=5, fully_connected=20, epochs=15, batch_size=88, total=   5.5s\n",
      "[CV] pool_sizes=2, num_filters=256, kern_size=5, fully_connected=20, epochs=15, batch_size=88 \n",
      "Epoch 1/15\n",
      "52/52 [==============================] - 2s 30ms/step - loss: 0.5165 - accuracy: 0.7524 - val_loss: 0.4951 - val_accuracy: 0.7629\n",
      "Epoch 2/15\n",
      "52/52 [==============================] - 2s 29ms/step - loss: 0.3508 - accuracy: 0.8492 - val_loss: 0.4926 - val_accuracy: 0.7649\n",
      "Epoch 3/15\n",
      "52/52 [==============================] - 2s 29ms/step - loss: 0.2370 - accuracy: 0.9123 - val_loss: 0.5081 - val_accuracy: 0.7709\n",
      "Epoch 00003: early stopping\n",
      "7/7 [==============================] - 0s 4ms/step\n",
      "[CV]  pool_sizes=2, num_filters=256, kern_size=5, fully_connected=20, epochs=15, batch_size=88, total=   5.5s\n",
      "[CV] pool_sizes=2, num_filters=256, kern_size=5, fully_connected=20, epochs=15, batch_size=88 \n",
      "Epoch 1/15\n",
      "52/52 [==============================] - 2s 30ms/step - loss: 0.5417 - accuracy: 0.7398 - val_loss: 0.4904 - val_accuracy: 0.7610\n",
      "Epoch 2/15\n",
      "52/52 [==============================] - 1s 29ms/step - loss: 0.3897 - accuracy: 0.8297 - val_loss: 0.4631 - val_accuracy: 0.7729\n",
      "Epoch 3/15\n",
      "52/52 [==============================] - 2s 30ms/step - loss: 0.2757 - accuracy: 0.8930 - val_loss: 0.4947 - val_accuracy: 0.7729\n",
      "Epoch 00003: early stopping\n",
      "7/7 [==============================] - 0s 5ms/step\n",
      "[CV]  pool_sizes=2, num_filters=256, kern_size=5, fully_connected=20, epochs=15, batch_size=88, total=   5.6s\n",
      "[CV] pool_sizes=2, num_filters=256, kern_size=5, fully_connected=20, epochs=15, batch_size=88 \n",
      "Epoch 1/15\n",
      "52/52 [==============================] - 2s 30ms/step - loss: 0.5089 - accuracy: 0.7586 - val_loss: 0.4456 - val_accuracy: 0.8187\n",
      "Epoch 2/15\n",
      "52/52 [==============================] - 1s 28ms/step - loss: 0.3429 - accuracy: 0.8545 - val_loss: 0.3914 - val_accuracy: 0.8426\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/15\n",
      "52/52 [==============================] - 2s 29ms/step - loss: 0.2210 - accuracy: 0.9176 - val_loss: 0.4627 - val_accuracy: 0.7829\n",
      "Epoch 00003: early stopping\n",
      "7/7 [==============================] - 0s 5ms/step\n",
      "[CV]  pool_sizes=2, num_filters=256, kern_size=5, fully_connected=20, epochs=15, batch_size=88, total=   5.5s\n",
      "Epoch 1/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:  3.8min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "58/58 [==============================] - 1s 22ms/step - loss: 0.5107 - accuracy: 0.7485 - val_loss: 0.4646 - val_accuracy: 0.7760\n",
      "Epoch 2/15\n",
      "58/58 [==============================] - 1s 18ms/step - loss: 0.3817 - accuracy: 0.8356 - val_loss: 0.4606 - val_accuracy: 0.7832\n",
      "Epoch 3/15\n",
      "58/58 [==============================] - 1s 19ms/step - loss: 0.3234 - accuracy: 0.8635 - val_loss: 0.4374 - val_accuracy: 0.8011\n",
      "Epoch 4/15\n",
      "58/58 [==============================] - 1s 19ms/step - loss: 0.2386 - accuracy: 0.9129 - val_loss: 0.4406 - val_accuracy: 0.8100\n",
      "Epoch 00004: early stopping\n",
      "22/22 [==============================] - 0s 3ms/step\n",
      "Best Accuracy : 0.8095\n",
      "{'pool_sizes': 10, 'num_filters': 128, 'kern_size': 5, 'fully_connected': 16, 'epochs': 15, 'batch_size': 88}\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "param_grid = dict(num_filters=[128, 256],\n",
    "                      kern_size=[3, 5, 7],\n",
    "                      batch_size = [76,88],\n",
    "                      fully_connected = [16, 20],\n",
    "                      pool_sizes = [2, 10], \n",
    "                      epochs = [15])\n",
    "\n",
    "model = KerasClassifier(build_fn=build_model, epochs=15, validation_split=0.1,verbose=1)\n",
    "\n",
    "grid = RandomizedSearchCV(estimator=model, param_distributions=param_grid,\n",
    "                              cv=10, verbose=2, n_iter=5, n_jobs=1,scoring = 'accuracy')\n",
    "\n",
    "grid_result = grid.fit(x_train, y_train, callbacks=[callback])\n",
    "\n",
    "\n",
    "test_accuracy = grid.score(x_test, y_test)\n",
    "\n",
    "# Save and evaluate results\n",
    "s = ('Best Accuracy : {:.4f}\\n{}\\n\\n\\n')\n",
    "output_string = s.format(\n",
    "            grid_result.best_score_,\n",
    "            grid_result.best_params_)\n",
    "            \n",
    "print(output_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 563,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1258\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1258 (Embedding)   (None, 36, 100)           1532500   \n",
      "_________________________________________________________________\n",
      "conv1d_1632 (Conv1D)         (None, 32, 128)           64128     \n",
      "_________________________________________________________________\n",
      "activation_865 (Activation)  (None, 32, 128)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_780 (MaxPoolin (None, 3, 128)            0         \n",
      "_________________________________________________________________\n",
      "flatten_1162 (Flatten)       (None, 384)               0         \n",
      "_________________________________________________________________\n",
      "dense_2063 (Dense)           (None, 16)                6160      \n",
      "_________________________________________________________________\n",
      "dense_2064 (Dense)           (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 1,602,805\n",
      "Trainable params: 1,602,805\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = build_model(128, 5, 10, 16)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 564,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "64/64 - 1s - loss: 0.5112 - accuracy: 0.7512 - val_loss: 0.4428 - val_accuracy: 0.7945\n",
      "Epoch 2/15\n",
      "64/64 - 1s - loss: 0.3603 - accuracy: 0.8488 - val_loss: 0.4188 - val_accuracy: 0.8090\n",
      "Epoch 3/15\n",
      "64/64 - 1s - loss: 0.2597 - accuracy: 0.9024 - val_loss: 0.4332 - val_accuracy: 0.8004\n",
      "Epoch 00003: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x3933f98d0>"
      ]
     },
     "execution_count": 564,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "callback = EarlyStopping(monitor = 'val_loss', patience = 1, verbose=1)\n",
    "callbacks = [callback]\n",
    "\n",
    "model.fit(x_train, y_train,\n",
    "          validation_data=(x_test, y_test),\n",
    "          batch_size=88,\n",
    "          epochs=15,\n",
    "          verbose=2,\n",
    "          callbacks=callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 567,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1260\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1260 (Embedding)   (None, 36, 100)           1532500   \n",
      "_________________________________________________________________\n",
      "conv1d_1634 (Conv1D)         (None, 32, 128)           64128     \n",
      "_________________________________________________________________\n",
      "activation_867 (Activation)  (None, 32, 128)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_782 (MaxPoolin (None, 3, 128)            0         \n",
      "_________________________________________________________________\n",
      "flatten_1164 (Flatten)       (None, 384)               0         \n",
      "_________________________________________________________________\n",
      "dense_2067 (Dense)           (None, 16)                6160      \n",
      "_________________________________________________________________\n",
      "dense_2068 (Dense)           (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 1,602,805\n",
      "Trainable params: 1,602,805\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_s = build_model(128, 5, 10, 16)\n",
    "model_s.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 568,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "85/85 - 1s - loss: 0.4859 - accuracy: 0.7735\n",
      "Epoch 2/2\n",
      "85/85 - 1s - loss: 0.3435 - accuracy: 0.8555\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x4f0213650>"
      ]
     },
     "execution_count": 568,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_s.fit(padded_docs, tweets['target'],\n",
    "          batch_size=88,\n",
    "          epochs=2,\n",
    "          verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 569,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_result = model_s.predict(padded_tests)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 570,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.8464004 ],\n",
       "       [0.8057761 ],\n",
       "       [0.78480256],\n",
       "       ...,\n",
       "       [0.9500956 ],\n",
       "       [0.90281564],\n",
       "       [0.63919055]], dtype=float32)"
      ]
     },
     "execution_count": 570,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 571,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " ...]"
      ]
     },
     "execution_count": 571,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submit = []\n",
    "\n",
    "for i in test_result:\n",
    "    if i >= 0.5 :\n",
    "        submit.append(1)\n",
    "    else:\n",
    "        submit.append(0)\n",
    "\n",
    "submit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 572,
   "metadata": {},
   "outputs": [],
   "source": [
    "tests['target'] = submit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 573,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit_df = tests[['id', 'target']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 574,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3258</th>\n",
       "      <td>10861</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3259</th>\n",
       "      <td>10865</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3260</th>\n",
       "      <td>10868</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3261</th>\n",
       "      <td>10874</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3262</th>\n",
       "      <td>10875</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3263 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id  target\n",
       "0         0       1\n",
       "1         2       1\n",
       "2         3       1\n",
       "3         9       1\n",
       "4        11       1\n",
       "...     ...     ...\n",
       "3258  10861       1\n",
       "3259  10865       1\n",
       "3260  10868       1\n",
       "3261  10874       1\n",
       "3262  10875       1\n",
       "\n",
       "[3263 rows x 2 columns]"
      ]
     },
     "execution_count": 574,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submit_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 577,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit_df.to_csv('submit_prueba_41.csv', index=False) #39 fue este con un epoch menos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN Submit 0.8204"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 673,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>length</th>\n",
       "      <th>avg_word_length</th>\n",
       "      <th>amount_of_words</th>\n",
       "      <th>amount_of_unique_words</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>stopwords_count</th>\n",
       "      <th>punctuation_count</th>\n",
       "      <th>mentions_count</th>\n",
       "      <th>hashtags_count</th>\n",
       "      <th>longest_word_length_without_stopwords</th>\n",
       "      <th>stopword_word_ratio</th>\n",
       "      <th>adjectives_count</th>\n",
       "      <th>nouns_count</th>\n",
       "      <th>verbs_count</th>\n",
       "      <th>adverbs_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>69</td>\n",
       "      <td>4.384615</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>0.2732</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0.461538</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>38</td>\n",
       "      <td>4.571429</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>-0.3400</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>133</td>\n",
       "      <td>5.090909</td>\n",
       "      <td>22</td>\n",
       "      <td>20</td>\n",
       "      <td>-0.2960</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>65</td>\n",
       "      <td>7.125000</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>88</td>\n",
       "      <td>4.500000</td>\n",
       "      <td>16</td>\n",
       "      <td>15</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>0.437500</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7429</th>\n",
       "      <td>136</td>\n",
       "      <td>6.210526</td>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "      <td>-0.6841</td>\n",
       "      <td>6</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>0.315789</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7430</th>\n",
       "      <td>114</td>\n",
       "      <td>3.423077</td>\n",
       "      <td>26</td>\n",
       "      <td>25</td>\n",
       "      <td>-0.4939</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0.615385</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7431</th>\n",
       "      <td>121</td>\n",
       "      <td>5.100000</td>\n",
       "      <td>20</td>\n",
       "      <td>18</td>\n",
       "      <td>-0.7650</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7432</th>\n",
       "      <td>83</td>\n",
       "      <td>6.636364</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>-0.4939</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7433</th>\n",
       "      <td>94</td>\n",
       "      <td>6.307692</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0.230769</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7434 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      length  avg_word_length  amount_of_words  amount_of_unique_words  \\\n",
       "0         69         4.384615               13                      13   \n",
       "1         38         4.571429                7                       7   \n",
       "2        133         5.090909               22                      20   \n",
       "3         65         7.125000                8                       8   \n",
       "4         88         4.500000               16                      15   \n",
       "...      ...              ...              ...                     ...   \n",
       "7429     136         6.210526               19                      19   \n",
       "7430     114         3.423077               26                      25   \n",
       "7431     121         5.100000               20                      18   \n",
       "7432      83         6.636364               11                      11   \n",
       "7433      94         6.307692               13                      13   \n",
       "\n",
       "      sentiment  stopwords_count  punctuation_count  mentions_count  \\\n",
       "0        0.2732                6                  1               0   \n",
       "1       -0.3400                0                  1               0   \n",
       "2       -0.2960               11                  3               0   \n",
       "3        0.0000                1                  2               0   \n",
       "4        0.0000                7                  2               0   \n",
       "...         ...              ...                ...             ...   \n",
       "7429    -0.6841                6                 12               0   \n",
       "7430    -0.4939               16                  1               0   \n",
       "7431    -0.7650                1                 11               0   \n",
       "7432    -0.4939                2                  5               0   \n",
       "7433     0.0000                3                  7               0   \n",
       "\n",
       "      hashtags_count  longest_word_length_without_stopwords  \\\n",
       "0                  1                                      7   \n",
       "1                  0                                      6   \n",
       "2                  0                                     10   \n",
       "3                  1                                     10   \n",
       "4                  2                                      6   \n",
       "...              ...                                    ...   \n",
       "7429               1                                     10   \n",
       "7430               0                                      8   \n",
       "7431               0                                      8   \n",
       "7432               0                                      8   \n",
       "7433               0                                     10   \n",
       "\n",
       "      stopword_word_ratio  adjectives_count  nouns_count  verbs_count  \\\n",
       "0                0.461538                 0            6            1   \n",
       "1                0.000000                 0            6            0   \n",
       "2                0.500000                 1            7            7   \n",
       "3                0.125000                 1            4            1   \n",
       "4                0.437500                 0            6            3   \n",
       "...                   ...               ...          ...          ...   \n",
       "7429             0.315789                 0           13            3   \n",
       "7430             0.615385                 2            4            5   \n",
       "7431             0.050000                 0           14            0   \n",
       "7432             0.181818                 2            6            1   \n",
       "7433             0.230769                 2            8            1   \n",
       "\n",
       "      adverbs_count  \n",
       "0                 0  \n",
       "1                 0  \n",
       "2                 0  \n",
       "3                 0  \n",
       "4                 1  \n",
       "...             ...  \n",
       "7429              0  \n",
       "7430              3  \n",
       "7431              0  \n",
       "7432              0  \n",
       "7433              0  \n",
       "\n",
       "[7434 rows x 15 columns]"
      ]
     },
     "execution_count": 673,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_features.loc[:, 'length':]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 830,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import layers, Input, Model\n",
    "from keras.layers import Dropout, Flatten, Concatenate, Embedding, Conv1D, GlobalMaxPooling1D, Dense, Lambda, Activation\n",
    "from keras import layers, Input, Model\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "callback = EarlyStopping(monitor = 'val_loss', patience = 1, verbose=1)\n",
    "callbacks = [callback]\n",
    "\n",
    "def build_model():\n",
    "    model = Sequential()\n",
    "    x_train_input = Input(shape=(36,), name = 'x_train_input')\n",
    "    x_train_features_input = Input(shape = (15, ), name = 'x_features_train') \n",
    "    e = Embedding(vocab_size, 100, weights=[embedding_matrix], input_length=36, trainable=True)\n",
    "    emb = e(x_train_input)\n",
    "    \n",
    "    conv_out1 = Conv1D(256, 2, activation='relu')(emb)\n",
    "    \n",
    "    conv_out2 = Conv1D(111, 2, activation='relu')(conv_out1)\n",
    "    activation = Activation('relu')(conv_out2)\n",
    "    max_pool2 = GlobalMaxPooling1D()(activation)\n",
    "\n",
    "    conc = Concatenate()([max_pool2, x_train_features_input])\n",
    "\n",
    "    dense2 = Dense(100, activation='relu', kernel_regularizer=keras.regularizers.l2(0.01))(conc)\n",
    "    dense3 = Dense(1, activation='sigmoid')(dense2)\n",
    "    \n",
    "    model = Model(inputs = [x_train_input , x_train_features_input], outputs = dense3)\n",
    "    \n",
    "    optimizer = Adam(learning_rate=0.001) #default\n",
    "    model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 831,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_14\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "x_train_input (InputLayer)      [(None, 36)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1699 (Embedding)      (None, 36, 100)      1532500     x_train_input[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_2079 (Conv1D)            (None, 35, 256)      51456       embedding_1699[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_2080 (Conv1D)            (None, 34, 111)      56943       conv1d_2079[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1297 (Activation)    (None, 34, 111)      0           conv1d_2080[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_15 (Global (None, 111)          0           activation_1297[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "x_features_train (InputLayer)   [(None, 15)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_14 (Concatenate)    (None, 126)          0           global_max_pooling1d_15[0][0]    \n",
      "                                                                 x_features_train[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dense_2677 (Dense)              (None, 100)          12700       concatenate_14[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_2678 (Dense)              (None, 1)            101         dense_2677[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 1,653,700\n",
      "Trainable params: 1,653,700\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = build_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 832,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "85/85 - 2s - loss: 1.3256 - accuracy: 0.7037\n",
      "Epoch 2/3\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "85/85 - 2s - loss: 0.7101 - accuracy: 0.8301\n",
      "Epoch 3/3\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "85/85 - 2s - loss: 0.5264 - accuracy: 0.8520\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x4d18c5c10>"
      ]
     },
     "execution_count": 832,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit([padded_docs,tweets_features.loc[:, 'length':]], tweets['target'],\n",
    "          batch_size=88,\n",
    "          epochs=3,\n",
    "          verbose=2, callbacks = [callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 833,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_result = model.predict([padded_tests, test_features.loc[:, 'length':]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 834,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.6675244],\n",
       "       [0.9170276],\n",
       "       [0.7969888],\n",
       "       ...,\n",
       "       [0.9986186],\n",
       "       [0.8948508],\n",
       "       [0.6564589]], dtype=float32)"
      ]
     },
     "execution_count": 834,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 835,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " ...]"
      ]
     },
     "execution_count": 835,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submit = []\n",
    "\n",
    "for i in test_result:\n",
    "    if i >= 0.5 :\n",
    "        submit.append(1)\n",
    "    else:\n",
    "        submit.append(0)\n",
    "\n",
    "submit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 836,
   "metadata": {},
   "outputs": [],
   "source": [
    "tests['target'] = submit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 837,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit_df = tests[['id', 'target']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 838,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3258</th>\n",
       "      <td>10861</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3259</th>\n",
       "      <td>10865</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3260</th>\n",
       "      <td>10868</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3261</th>\n",
       "      <td>10874</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3262</th>\n",
       "      <td>10875</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3263 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id  target\n",
       "0         0       1\n",
       "1         2       1\n",
       "2         3       1\n",
       "3         9       1\n",
       "4        11       1\n",
       "...     ...     ...\n",
       "3258  10861       0\n",
       "3259  10865       1\n",
       "3260  10868       1\n",
       "3261  10874       1\n",
       "3262  10875       1\n",
       "\n",
       "[3263 rows x 2 columns]"
      ]
     },
     "execution_count": 838,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submit_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 840,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit_df.to_csv('submit_prueba_42.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN  Submit 0.8256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 926,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import layers, Input, Model\n",
    "from keras.layers import Dropout, Flatten, Concatenate, Embedding, Conv1D, GlobalMaxPooling1D, Dense, Lambda, Activation\n",
    "from keras import layers, Input, Model\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "callback = EarlyStopping(monitor = 'val_loss', patience = 1, verbose=1)\n",
    "callbacks = [callback]\n",
    "\n",
    "def build_model():\n",
    "    model = Sequential()\n",
    "    x_train_input = Input(shape=(36,), name = 'x_train_input')\n",
    "    x_train_features_input = Input(shape = (15, ), name = 'x_features_train') \n",
    "    e = Embedding(vocab_size, 100, weights=[embedding_matrix], input_length=36, trainable=True)\n",
    "    emb = e(x_train_input)\n",
    "    \n",
    "    conv_out1 = Conv1D(256, 2, activation='relu')(emb)\n",
    "    \n",
    "    activation_1 = Activation('relu')(conv_out1)\n",
    "    \n",
    "    conv_out2 = Conv1D(111, 2, activation='relu')(activation_1)\n",
    "    \n",
    "    activation = Activation('relu')(conv_out2)\n",
    "    \n",
    "    max_pool2 = GlobalMaxPooling1D()(activation)\n",
    "\n",
    "    conc = Concatenate()([max_pool2, x_train_features_input])\n",
    "\n",
    "    dense2 = Dense(100, activation='relu', kernel_regularizer=keras.regularizers.l2(0.01))(conc)\n",
    "    dense3 = Dense(1, activation='sigmoid')(dense2)\n",
    "    \n",
    "    model = Model(inputs = [x_train_input , x_train_features_input], outputs = dense3)\n",
    "    \n",
    "    optimizer = Adam(learning_rate=0.001) #default\n",
    "    model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 927,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_23\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "x_train_input (InputLayer)      [(None, 36)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1710 (Embedding)      (None, 36, 100)      1532500     x_train_input[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_2101 (Conv1D)            (None, 35, 256)      51456       embedding_1710[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_1309 (Activation)    (None, 35, 256)      0           conv1d_2101[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_2102 (Conv1D)            (None, 34, 111)      56943       activation_1309[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_1310 (Activation)    (None, 34, 111)      0           conv1d_2102[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_24 (Global (None, 111)          0           activation_1310[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "x_features_train (InputLayer)   [(None, 15)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_24 (Concatenate)    (None, 126)          0           global_max_pooling1d_24[0][0]    \n",
      "                                                                 x_features_train[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dense_2695 (Dense)              (None, 100)          12700       concatenate_24[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_2696 (Dense)              (None, 1)            101         dense_2695[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 1,653,700\n",
      "Trainable params: 1,653,700\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = build_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 928,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "85/85 - 2s - loss: 1.5573 - accuracy: 0.6536\n",
      "Epoch 2/3\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "85/85 - 2s - loss: 0.7745 - accuracy: 0.8245\n",
      "Epoch 3/3\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "85/85 - 2s - loss: 0.5746 - accuracy: 0.8528\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x548723750>"
      ]
     },
     "execution_count": 928,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit([padded_docs,tweets_features.loc[:, 'length':]], tweets['target'],\n",
    "          batch_size=88,\n",
    "          epochs=3,\n",
    "          verbose=2, callbacks = [callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 929,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_result = model.predict([padded_tests, test_features.loc[:, 'length':]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 930,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.72363526],\n",
       "       [0.95123327],\n",
       "       [0.86855066],\n",
       "       ...,\n",
       "       [0.99703455],\n",
       "       [0.9047524 ],\n",
       "       [0.6253783 ]], dtype=float32)"
      ]
     },
     "execution_count": 930,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 931,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " ...]"
      ]
     },
     "execution_count": 931,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submit = []\n",
    "\n",
    "for i in test_result:\n",
    "    if i >= 0.5 :\n",
    "        submit.append(1)\n",
    "    else:\n",
    "        submit.append(0)\n",
    "\n",
    "submit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 932,
   "metadata": {},
   "outputs": [],
   "source": [
    "tests['target'] = submit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 933,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit_df = tests[['id', 'target']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 934,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3258</th>\n",
       "      <td>10861</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3259</th>\n",
       "      <td>10865</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3260</th>\n",
       "      <td>10868</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3261</th>\n",
       "      <td>10874</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3262</th>\n",
       "      <td>10875</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3263 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id  target\n",
       "0         0       1\n",
       "1         2       1\n",
       "2         3       1\n",
       "3         9       1\n",
       "4        11       1\n",
       "...     ...     ...\n",
       "3258  10861       0\n",
       "3259  10865       1\n",
       "3260  10868       1\n",
       "3261  10874       1\n",
       "3262  10875       1\n",
       "\n",
       "[3263 rows x 2 columns]"
      ]
     },
     "execution_count": 934,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submit_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 936,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit_df.to_csv('submit_prueba_43.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1314,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import layers, Input, Model\n",
    "from keras.layers import Dropout, Flatten, Concatenate, Embedding, Conv1D, GlobalMaxPooling1D, Dense, Lambda, Activation\n",
    "from keras import layers, Input, Model\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "callback = EarlyStopping(monitor = 'val_loss', patience = 1, verbose=1)\n",
    "callbacks = [callback]\n",
    "\n",
    "def build_model():\n",
    "    model = Sequential()\n",
    "    x_train_input = Input(shape=(36,), name = 'x_train_input')\n",
    "    x_train_features_input = Input(shape = (15, ), name = 'x_features_train') \n",
    "    e = Embedding(vocab_size, 100, weights=[embedding_matrix], input_length=36, trainable=True)\n",
    "    emb = e(x_train_input)\n",
    "    \n",
    "    conv_out1 = Conv1D(256, 2, activation='relu')(emb)\n",
    "    \n",
    "    activation_1 = Activation('relu')(conv_out1)\n",
    "    \n",
    "    conv_out1 = Conv1D(111, 2, activation='relu')(activation_1)\n",
    "    \n",
    "    activation_2 = Activation('relu')(conv_out1)\n",
    "    \n",
    "    conv_out2 = Conv1D(111, 2, activation='relu')(activation_2)\n",
    "    \n",
    "    activation = Activation('relu')(conv_out2)\n",
    "    \n",
    "    max_pool2 = GlobalMaxPooling1D()(activation)\n",
    "\n",
    "    conc = Concatenate()([max_pool2, x_train_features_input])\n",
    "\n",
    "    dense2 = Dense(90, activation='relu', kernel_regularizer=keras.regularizers.l2(0.01))(conc)\n",
    "    dense3 = Dense(1, activation='sigmoid')(dense2)\n",
    "    \n",
    "    model = Model(inputs = [x_train_input , x_train_features_input], outputs = dense3)\n",
    "    \n",
    "    optimizer = Adam(learning_rate=0.001) #default\n",
    "    model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1315,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_65\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "x_train_input (InputLayer)      [(None, 36)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1753 (Embedding)      (None, 36, 100)      1532500     x_train_input[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_2228 (Conv1D)            (None, 35, 256)      51456       embedding_1753[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_1428 (Activation)    (None, 35, 256)      0           conv1d_2228[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_2229 (Conv1D)            (None, 34, 111)      56943       activation_1428[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_1429 (Activation)    (None, 34, 111)      0           conv1d_2229[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_2230 (Conv1D)            (None, 33, 111)      24753       activation_1429[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_1430 (Activation)    (None, 33, 111)      0           conv1d_2230[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_66 (Global (None, 111)          0           activation_1430[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "x_features_train (InputLayer)   [(None, 15)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_66 (Concatenate)    (None, 126)          0           global_max_pooling1d_66[0][0]    \n",
      "                                                                 x_features_train[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dense_2779 (Dense)              (None, 90)           11430       concatenate_66[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_2780 (Dense)              (None, 1)            91          dense_2779[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 1,677,173\n",
      "Trainable params: 1,677,173\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = build_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1316,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "85/85 - 3s - loss: 2.0475 - accuracy: 0.6219\n",
      "Epoch 2/3\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "85/85 - 3s - loss: 0.8349 - accuracy: 0.7674\n",
      "Epoch 3/3\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "85/85 - 3s - loss: 0.6080 - accuracy: 0.8391\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x57d6ac810>"
      ]
     },
     "execution_count": 1316,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit([padded_docs,tweets_features.loc[:, 'length':]], tweets['target'],\n",
    "          batch_size=88,\n",
    "          epochs=3,\n",
    "          verbose=2, callbacks = [callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1317,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_result = model.predict([padded_tests, test_features.loc[:, 'length':]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1318,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.7608732 ],\n",
       "       [0.8834977 ],\n",
       "       [0.75991297],\n",
       "       ...,\n",
       "       [0.9748985 ],\n",
       "       [0.94214296],\n",
       "       [0.63062084]], dtype=float32)"
      ]
     },
     "execution_count": 1318,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1319,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " ...]"
      ]
     },
     "execution_count": 1319,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submit = []\n",
    "\n",
    "for i in test_result:\n",
    "    if i >= 0.5 :\n",
    "        submit.append(1)\n",
    "    else:\n",
    "        submit.append(0)\n",
    "\n",
    "submit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1320,
   "metadata": {},
   "outputs": [],
   "source": [
    "tests['target'] = submit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1321,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit_df = tests[['id', 'target']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1322,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3258</th>\n",
       "      <td>10861</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3259</th>\n",
       "      <td>10865</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3260</th>\n",
       "      <td>10868</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3261</th>\n",
       "      <td>10874</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3262</th>\n",
       "      <td>10875</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3263 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id  target\n",
       "0         0       1\n",
       "1         2       1\n",
       "2         3       1\n",
       "3         9       1\n",
       "4        11       1\n",
       "...     ...     ...\n",
       "3258  10861       0\n",
       "3259  10865       1\n",
       "3260  10868       1\n",
       "3261  10874       1\n",
       "3262  10875       1\n",
       "\n",
       "[3263 rows x 2 columns]"
      ]
     },
     "execution_count": 1322,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submit_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
