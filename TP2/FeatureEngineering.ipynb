{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     C:\\Users\\mausa\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\mausa\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\mausa\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\mausa\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import string\n",
    "#import xgboost as xgb\n",
    "import io\n",
    "import nltk\n",
    "import matplotlib\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn import preprocessing\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "nltk.download('vader_lexicon')\n",
    "nltk.download('stopwords')\n",
    "stopwords = stopwords.words('english')\n",
    "stemmer = SnowballStemmer('english')\n",
    "\n",
    "from textblob import TextBlob\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "pd.set_option('mode.chained_assignment', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = pd.read_csv(\"train.csv\")\n",
    "test = pd.read_csv(\"test.csv\")\n",
    "tweets['keyword'] = tweets.keyword.str.replace('%20',' ')\n",
    "test['keyword'] = test.keyword.str.replace('%20',' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 7434 entries, 0 to 7612\n",
      "Data columns (total 5 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   id        7434 non-null   int64 \n",
      " 1   keyword   7378 non-null   object\n",
      " 2   location  4982 non-null   object\n",
      " 3   text      7434 non-null   object\n",
      " 4   target    7434 non-null   int64 \n",
      "dtypes: int64(2), object(3)\n",
      "memory usage: 348.5+ KB\n"
     ]
    }
   ],
   "source": [
    "tweets.drop_duplicates(subset = 'text', keep = False, inplace = True)\n",
    "tweets.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    3243\n",
       "True       20\n",
       "Name: text, dtype: int64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test['text'].duplicated().value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extra Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "sia = SentimentIntensityAnalyzer()\n",
    "def return_sia_compound_values(text):\n",
    "    return sia.polarity_scores(text)['compound']\n",
    "\n",
    "def remove_stopword(text):\n",
    "    new_text = []\n",
    "    for e in text:\n",
    "        if e not in stopwords and e.isalpha():\n",
    "            new_text.append(e)\n",
    "    text = new_text\n",
    "    return \" \".join(new_text)\n",
    "\n",
    "def stemm(text):\n",
    "    text = [stemmer.stem(word) for word in text.split()]\n",
    "    return \" \".join(text)\n",
    "\n",
    "def contains_punctuation(text):\n",
    "    punctuation = set(string.punctuation)\n",
    "    for character in text:\n",
    "        if character in punctuation:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "def amount_of_punctuation(text):\n",
    "    punctuation = set(string.punctuation)\n",
    "    amount = 0\n",
    "    for character in text:\n",
    "        if character in punctuation: amount += 1\n",
    "    return amount\n",
    "\n",
    "def get_adjectives(text):\n",
    "    blob = TextBlob(text)\n",
    "    return len([word for (word,tag) in blob.tags if tag.startswith(\"JJ\")])\n",
    "\n",
    "def get_nouns(text):\n",
    "    blob = TextBlob(text)\n",
    "    return len([word for (word,tag) in blob.tags if tag.startswith(\"NN\")])\n",
    "\n",
    "def get_verbs(text):\n",
    "    blob = TextBlob(text)\n",
    "    return len([word for (word,tag) in blob.tags if tag.startswith(\"VB\")])\n",
    "\n",
    "def get_adverbs(text):\n",
    "    blob = TextBlob(text)\n",
    "    return len([word for (word,tag) in blob.tags if tag.startswith(\"RB\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_metrics(df):\n",
    "    tweets_metrics = df[['id','text']]\n",
    "    tweets_metrics['text_without_stopwords'] = tweets_metrics['text'].str.split()\n",
    "    tweets_metrics['text_without_stopwords'] = tweets_metrics['text_without_stopwords'].apply(remove_stopword)\n",
    "    tweets_metrics['length'] = tweets_metrics['text'].apply(lambda x: len(x))\n",
    "    tweets_metrics['avg_word_length'] = tweets_metrics['text'].str.split().apply(lambda x: [len(y) for y in x]).transform(lambda x: np.mean(x))\n",
    "    tweets_metrics['amount_of_words'] = tweets_metrics['text'].str.split().transform(lambda x: len(x))\n",
    "    unique_words_by_tweet = tweets_metrics['text'].transform(lambda x: x.split()).transform(lambda x: pd.Series(x).unique()).transform(lambda x: len(x))\n",
    "    tweets_metrics['amount_of_unique_words'] = unique_words_by_tweet\n",
    "    tweets_metrics['sentiment'] = tweets_metrics['text'].apply(lambda x: return_sia_compound_values(x))\n",
    "    tweets_metrics['stopwords_count'] = tweets_metrics['text'].apply(lambda x: len([word for word in str(x).lower().split() if word in stopwords]))\n",
    "    tweets_metrics['punctuation_count'] = tweets_metrics['text'].apply(lambda x: amount_of_punctuation(x))\n",
    "    mentions = tweets_metrics['text'].str.findall(r'@.\\S*?(?=\\s|[:]|$)').to_frame()\n",
    "    tweets_metrics['mentions_count'] = mentions['text'].apply(lambda x: len(x))\n",
    "    hashtags = tweets_metrics['text'].str.findall(r'#[^?\\s].*?(?=\\s|$)')\n",
    "    tweets_metrics['hashtags_count'] = hashtags.apply(lambda x: len(x))\n",
    "    tweets_metrics['longest_word_length_without_stopwords'] = tweets_metrics['text_without_stopwords'].apply(lambda x: ([len(word) for word in str(x).lower().split() if not word.startswith('http')])).apply(lambda x: max(x) if len(x) > 0 else 0)\n",
    "    tweets_metrics['stopword_word_ratio'] = tweets_metrics['stopwords_count'] / tweets_metrics['amount_of_words']\n",
    "    tweets_metrics['adjectives_count'] = tweets_metrics['text'].apply(get_adjectives)\n",
    "    tweets_metrics['nouns_count'] = tweets_metrics['text'].apply(get_nouns)\n",
    "    tweets_metrics['verbs_count'] = tweets_metrics['text'].apply(get_verbs)\n",
    "    tweets_metrics['adverbs_count'] = tweets_metrics['text'].apply(get_adverbs)\n",
    "    return tweets_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_metrics = get_metrics(tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_metrics = get_metrics(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run for files\n",
    "#train_metrics.to_csv('train_features.csv', index=False)\n",
    "#test_metrics.to_csv('test_features.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mocks real tokenizer used in glove\n",
    "import re\n",
    "\n",
    "def tokenize_input(input_text):\n",
    "    to_tokens = input_text[:]\n",
    "    token_specification = [\n",
    "        ('url', r'https?:\\/\\/\\S+\\b|www\\.(\\w+\\.)+\\S*'),\n",
    "        (' / ', r'/'),\n",
    "        ('user', r'@\\w+'),            \n",
    "        ('smile', r'[8:=;][)d]+|[)d]+[\\'`\\-]?[8:=;]'),    \n",
    "        ('lolface', r'[8:=;][\\'`\\-]?p'),      \n",
    "        ('sadface', r'[8:=;][\\'`\\-]?\\(|\\)+[8:=;][\\'`\\-]?'),          \n",
    "        ('neutralface', r'[8:=;][\\'`\\-]?[\\/|l*]'),       \n",
    "        ('heart', r'<3'),   \n",
    "        ('number', r'[-+]?[.\\d]*[\\d]+[:,.\\d]*')\n",
    "    ]\n",
    "    for replacement, regex in token_specification:\n",
    "        to_tokens = re.sub(regex, replacement, to_tokens)\n",
    "    return to_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'url hola  /  smile heart lolface sadface  number user'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check\n",
    "tokenize_input('https://regexr.com hola / :) <3 :p :(  8888 @justin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "\n",
    "tweets['text'] = tweets['text'].apply(tokenize_input)\n",
    "test['text'] = test['text'].apply(tokenize_input)\n",
    "tweets['text'] = tweets['text'].apply(lambda x: x.translate({ord(i): ' ' for i in string.punctuation}))\n",
    "test['text'] = test['text'].apply(lambda x: x.translate({ord(i): ' ' for i in string.punctuation}))\n",
    "tweets['text'] = tweets['text'].apply(lambda x: x.lower())\n",
    "test['text'] = test['text'].apply(lambda x: x.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run for files\n",
    "#tweets.to_csv('processed_train.csv', index=False)\n",
    "#test.to_csv('processed_test.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vector encoding\n",
    "\n",
    "#### Keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets['keyword'] = tweets['keyword'].fillna('null')\n",
    "test['keyword'] = test['keyword'].fillna('null')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "keyword_tokens = tweets.keyword.unique().tolist()\n",
    "keyword_test = test.keyword.unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in keyword_test:\n",
    "    if k not in keyword_tokens:\n",
    "        print(k) # Mismas palabras en ambos sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 400000 word vectors.\n"
     ]
    }
   ],
   "source": [
    "embeddings_index = dict()\n",
    "f = open('Embeddings/glove.6B.100d.txt', encoding='utf8') # Vectores entrenados de 100 dimensiones\n",
    "for line in f:\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    coefs = np.asarray(values[1:], dtype='float32')\n",
    "    embeddings_index[word] = coefs\n",
    "f.close()\n",
    "print('Loaded %s word vectors.' % len(embeddings_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectors = {}\n",
    "for keyword in keyword_tokens:\n",
    "    words = keyword.split(' ')\n",
    "    n = len(words)\n",
    "    if n == 1:\n",
    "        vectors[keyword] = embeddings_index[keyword]\n",
    "    else:\n",
    "        acum = np.zeros(100)\n",
    "        for w in words:\n",
    "            acum = np.sum([acum,embeddings_index[w]] , axis=0)\n",
    "        vectors[keyword] = acum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>...</th>\n",
       "      <th>90</th>\n",
       "      <th>91</th>\n",
       "      <th>92</th>\n",
       "      <th>93</th>\n",
       "      <th>94</th>\n",
       "      <th>95</th>\n",
       "      <th>96</th>\n",
       "      <th>97</th>\n",
       "      <th>98</th>\n",
       "      <th>99</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>null</td>\n",
       "      <td>0.079432</td>\n",
       "      <td>-0.14054</td>\n",
       "      <td>-0.104620</td>\n",
       "      <td>-0.362590</td>\n",
       "      <td>-0.22721</td>\n",
       "      <td>-0.13612</td>\n",
       "      <td>0.74755</td>\n",
       "      <td>0.328090</td>\n",
       "      <td>0.54364</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.21230</td>\n",
       "      <td>0.515730</td>\n",
       "      <td>0.16573</td>\n",
       "      <td>0.679430</td>\n",
       "      <td>0.353270</td>\n",
       "      <td>0.17672</td>\n",
       "      <td>0.258030</td>\n",
       "      <td>0.068445</td>\n",
       "      <td>-1.20160</td>\n",
       "      <td>-0.20168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ablaze</td>\n",
       "      <td>0.137010</td>\n",
       "      <td>-0.31349</td>\n",
       "      <td>-0.047427</td>\n",
       "      <td>-0.245820</td>\n",
       "      <td>0.76459</td>\n",
       "      <td>1.21330</td>\n",
       "      <td>0.25674</td>\n",
       "      <td>0.446160</td>\n",
       "      <td>1.21040</td>\n",
       "      <td>...</td>\n",
       "      <td>1.42780</td>\n",
       "      <td>-0.402050</td>\n",
       "      <td>-0.26682</td>\n",
       "      <td>-0.029039</td>\n",
       "      <td>-1.102300</td>\n",
       "      <td>0.20442</td>\n",
       "      <td>-0.064528</td>\n",
       "      <td>0.305040</td>\n",
       "      <td>0.42830</td>\n",
       "      <td>0.54531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>accident</td>\n",
       "      <td>-0.006329</td>\n",
       "      <td>-0.37913</td>\n",
       "      <td>0.409920</td>\n",
       "      <td>-0.003844</td>\n",
       "      <td>-0.81139</td>\n",
       "      <td>-0.67840</td>\n",
       "      <td>0.25995</td>\n",
       "      <td>1.090300</td>\n",
       "      <td>0.60039</td>\n",
       "      <td>...</td>\n",
       "      <td>0.49451</td>\n",
       "      <td>-0.308700</td>\n",
       "      <td>-0.18550</td>\n",
       "      <td>0.714090</td>\n",
       "      <td>0.198860</td>\n",
       "      <td>1.12760</td>\n",
       "      <td>-0.100960</td>\n",
       "      <td>-0.100000</td>\n",
       "      <td>0.21349</td>\n",
       "      <td>-1.24530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>aftershock</td>\n",
       "      <td>0.136920</td>\n",
       "      <td>1.02570</td>\n",
       "      <td>0.539610</td>\n",
       "      <td>0.275310</td>\n",
       "      <td>-0.91579</td>\n",
       "      <td>0.24287</td>\n",
       "      <td>0.77162</td>\n",
       "      <td>0.025242</td>\n",
       "      <td>0.47416</td>\n",
       "      <td>...</td>\n",
       "      <td>1.23600</td>\n",
       "      <td>0.126510</td>\n",
       "      <td>-0.93994</td>\n",
       "      <td>0.187410</td>\n",
       "      <td>0.712540</td>\n",
       "      <td>0.79876</td>\n",
       "      <td>-0.040149</td>\n",
       "      <td>-0.591220</td>\n",
       "      <td>-0.28051</td>\n",
       "      <td>-0.23293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>airplane accident</td>\n",
       "      <td>-0.175379</td>\n",
       "      <td>-0.10526</td>\n",
       "      <td>0.977860</td>\n",
       "      <td>-0.001856</td>\n",
       "      <td>-0.93397</td>\n",
       "      <td>-1.15404</td>\n",
       "      <td>0.79570</td>\n",
       "      <td>1.143708</td>\n",
       "      <td>0.94012</td>\n",
       "      <td>...</td>\n",
       "      <td>0.78136</td>\n",
       "      <td>-0.287935</td>\n",
       "      <td>0.23436</td>\n",
       "      <td>0.676289</td>\n",
       "      <td>0.262775</td>\n",
       "      <td>1.53821</td>\n",
       "      <td>-0.300710</td>\n",
       "      <td>-0.089367</td>\n",
       "      <td>0.77883</td>\n",
       "      <td>-2.21178</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 101 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               index         0        1         2         3        4        5  \\\n",
       "0               null  0.079432 -0.14054 -0.104620 -0.362590 -0.22721 -0.13612   \n",
       "1             ablaze  0.137010 -0.31349 -0.047427 -0.245820  0.76459  1.21330   \n",
       "2           accident -0.006329 -0.37913  0.409920 -0.003844 -0.81139 -0.67840   \n",
       "3         aftershock  0.136920  1.02570  0.539610  0.275310 -0.91579  0.24287   \n",
       "4  airplane accident -0.175379 -0.10526  0.977860 -0.001856 -0.93397 -1.15404   \n",
       "\n",
       "         6         7        8  ...       90        91       92        93  \\\n",
       "0  0.74755  0.328090  0.54364  ... -1.21230  0.515730  0.16573  0.679430   \n",
       "1  0.25674  0.446160  1.21040  ...  1.42780 -0.402050 -0.26682 -0.029039   \n",
       "2  0.25995  1.090300  0.60039  ...  0.49451 -0.308700 -0.18550  0.714090   \n",
       "3  0.77162  0.025242  0.47416  ...  1.23600  0.126510 -0.93994  0.187410   \n",
       "4  0.79570  1.143708  0.94012  ...  0.78136 -0.287935  0.23436  0.676289   \n",
       "\n",
       "         94       95        96        97       98       99  \n",
       "0  0.353270  0.17672  0.258030  0.068445 -1.20160 -0.20168  \n",
       "1 -1.102300  0.20442 -0.064528  0.305040  0.42830  0.54531  \n",
       "2  0.198860  1.12760 -0.100960 -0.100000  0.21349 -1.24530  \n",
       "3  0.712540  0.79876 -0.040149 -0.591220 -0.28051 -0.23293  \n",
       "4  0.262775  1.53821 -0.300710 -0.089367  0.77883 -2.21178  \n",
       "\n",
       "[5 rows x 101 columns]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keyword_vectors = pd.DataFrame.from_dict(vectors).T.reset_index()\n",
    "keyword_vectors.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "aux = []\n",
    "aux.append('keyword')\n",
    "for i in range (0, 100):\n",
    "    name = 'k' + str(i)\n",
    "    aux.append(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>location</th>\n",
       "      <th>l0</th>\n",
       "      <th>l1</th>\n",
       "      <th>l2</th>\n",
       "      <th>l3</th>\n",
       "      <th>l4</th>\n",
       "      <th>l5</th>\n",
       "      <th>l6</th>\n",
       "      <th>l7</th>\n",
       "      <th>l8</th>\n",
       "      <th>...</th>\n",
       "      <th>l90</th>\n",
       "      <th>l91</th>\n",
       "      <th>l92</th>\n",
       "      <th>l93</th>\n",
       "      <th>l94</th>\n",
       "      <th>l95</th>\n",
       "      <th>l96</th>\n",
       "      <th>l97</th>\n",
       "      <th>l98</th>\n",
       "      <th>l99</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>null</td>\n",
       "      <td>0.079432</td>\n",
       "      <td>-0.14054</td>\n",
       "      <td>-0.104620</td>\n",
       "      <td>-0.362590</td>\n",
       "      <td>-0.22721</td>\n",
       "      <td>-0.13612</td>\n",
       "      <td>0.74755</td>\n",
       "      <td>0.328090</td>\n",
       "      <td>0.54364</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.21230</td>\n",
       "      <td>0.515730</td>\n",
       "      <td>0.16573</td>\n",
       "      <td>0.679430</td>\n",
       "      <td>0.353270</td>\n",
       "      <td>0.17672</td>\n",
       "      <td>0.258030</td>\n",
       "      <td>0.068445</td>\n",
       "      <td>-1.20160</td>\n",
       "      <td>-0.20168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ablaze</td>\n",
       "      <td>0.137010</td>\n",
       "      <td>-0.31349</td>\n",
       "      <td>-0.047427</td>\n",
       "      <td>-0.245820</td>\n",
       "      <td>0.76459</td>\n",
       "      <td>1.21330</td>\n",
       "      <td>0.25674</td>\n",
       "      <td>0.446160</td>\n",
       "      <td>1.21040</td>\n",
       "      <td>...</td>\n",
       "      <td>1.42780</td>\n",
       "      <td>-0.402050</td>\n",
       "      <td>-0.26682</td>\n",
       "      <td>-0.029039</td>\n",
       "      <td>-1.102300</td>\n",
       "      <td>0.20442</td>\n",
       "      <td>-0.064528</td>\n",
       "      <td>0.305040</td>\n",
       "      <td>0.42830</td>\n",
       "      <td>0.54531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>accident</td>\n",
       "      <td>-0.006329</td>\n",
       "      <td>-0.37913</td>\n",
       "      <td>0.409920</td>\n",
       "      <td>-0.003844</td>\n",
       "      <td>-0.81139</td>\n",
       "      <td>-0.67840</td>\n",
       "      <td>0.25995</td>\n",
       "      <td>1.090300</td>\n",
       "      <td>0.60039</td>\n",
       "      <td>...</td>\n",
       "      <td>0.49451</td>\n",
       "      <td>-0.308700</td>\n",
       "      <td>-0.18550</td>\n",
       "      <td>0.714090</td>\n",
       "      <td>0.198860</td>\n",
       "      <td>1.12760</td>\n",
       "      <td>-0.100960</td>\n",
       "      <td>-0.100000</td>\n",
       "      <td>0.21349</td>\n",
       "      <td>-1.24530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>aftershock</td>\n",
       "      <td>0.136920</td>\n",
       "      <td>1.02570</td>\n",
       "      <td>0.539610</td>\n",
       "      <td>0.275310</td>\n",
       "      <td>-0.91579</td>\n",
       "      <td>0.24287</td>\n",
       "      <td>0.77162</td>\n",
       "      <td>0.025242</td>\n",
       "      <td>0.47416</td>\n",
       "      <td>...</td>\n",
       "      <td>1.23600</td>\n",
       "      <td>0.126510</td>\n",
       "      <td>-0.93994</td>\n",
       "      <td>0.187410</td>\n",
       "      <td>0.712540</td>\n",
       "      <td>0.79876</td>\n",
       "      <td>-0.040149</td>\n",
       "      <td>-0.591220</td>\n",
       "      <td>-0.28051</td>\n",
       "      <td>-0.23293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>airplane accident</td>\n",
       "      <td>-0.175379</td>\n",
       "      <td>-0.10526</td>\n",
       "      <td>0.977860</td>\n",
       "      <td>-0.001856</td>\n",
       "      <td>-0.93397</td>\n",
       "      <td>-1.15404</td>\n",
       "      <td>0.79570</td>\n",
       "      <td>1.143708</td>\n",
       "      <td>0.94012</td>\n",
       "      <td>...</td>\n",
       "      <td>0.78136</td>\n",
       "      <td>-0.287935</td>\n",
       "      <td>0.23436</td>\n",
       "      <td>0.676289</td>\n",
       "      <td>0.262775</td>\n",
       "      <td>1.53821</td>\n",
       "      <td>-0.300710</td>\n",
       "      <td>-0.089367</td>\n",
       "      <td>0.77883</td>\n",
       "      <td>-2.21178</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 101 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            location        l0       l1        l2        l3       l4       l5  \\\n",
       "0               null  0.079432 -0.14054 -0.104620 -0.362590 -0.22721 -0.13612   \n",
       "1             ablaze  0.137010 -0.31349 -0.047427 -0.245820  0.76459  1.21330   \n",
       "2           accident -0.006329 -0.37913  0.409920 -0.003844 -0.81139 -0.67840   \n",
       "3         aftershock  0.136920  1.02570  0.539610  0.275310 -0.91579  0.24287   \n",
       "4  airplane accident -0.175379 -0.10526  0.977860 -0.001856 -0.93397 -1.15404   \n",
       "\n",
       "        l6        l7       l8  ...      l90       l91      l92       l93  \\\n",
       "0  0.74755  0.328090  0.54364  ... -1.21230  0.515730  0.16573  0.679430   \n",
       "1  0.25674  0.446160  1.21040  ...  1.42780 -0.402050 -0.26682 -0.029039   \n",
       "2  0.25995  1.090300  0.60039  ...  0.49451 -0.308700 -0.18550  0.714090   \n",
       "3  0.77162  0.025242  0.47416  ...  1.23600  0.126510 -0.93994  0.187410   \n",
       "4  0.79570  1.143708  0.94012  ...  0.78136 -0.287935  0.23436  0.676289   \n",
       "\n",
       "        l94      l95       l96       l97      l98      l99  \n",
       "0  0.353270  0.17672  0.258030  0.068445 -1.20160 -0.20168  \n",
       "1 -1.102300  0.20442 -0.064528  0.305040  0.42830  0.54531  \n",
       "2  0.198860  1.12760 -0.100960 -0.100000  0.21349 -1.24530  \n",
       "3  0.712540  0.79876 -0.040149 -0.591220 -0.28051 -0.23293  \n",
       "4  0.262775  1.53821 -0.300710 -0.089367  0.77883 -2.21178  \n",
       "\n",
       "[5 rows x 101 columns]"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keyword_vectors.columns = aux\n",
    "keyword_vectors.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keywords_to_merge = tweets.merge(keyword_vectors, how='left').drop(columns=['keyword', 'location', 'text', 'target'])\n",
    "keywords_to_merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keywords_merge_test = test.merge(keyword_vectors, how='left').drop(columns=['keyword', 'location', 'text'])\n",
    "keywords_merge_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run for files\n",
    "#keywords_to_merge.to_csv('keyword_features.csv', index=False)\n",
    "keywords_merge_test.to_csv('keyword_test_features.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Keywords one hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>null</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>null</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>null</td>\n",
       "      <td>NaN</td>\n",
       "      <td>All residents asked to 'shelter in place' are ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>null</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>null</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7604</th>\n",
       "      <td>10863</td>\n",
       "      <td>null</td>\n",
       "      <td>NaN</td>\n",
       "      <td>#WorldNews Fallen powerlines on G:link tram: U...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7605</th>\n",
       "      <td>10864</td>\n",
       "      <td>null</td>\n",
       "      <td>NaN</td>\n",
       "      <td>on the flip side I'm at Walmart and there is a...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7606</th>\n",
       "      <td>10866</td>\n",
       "      <td>null</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Suicide bomber kills 15 in Saudi security site...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7608</th>\n",
       "      <td>10869</td>\n",
       "      <td>null</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Two giant cranes holding a bridge collapse int...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7612</th>\n",
       "      <td>10873</td>\n",
       "      <td>null</td>\n",
       "      <td>NaN</td>\n",
       "      <td>The Latest: More Homes Razed by Northern Calif...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7434 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id keyword location  \\\n",
       "0         1    null      NaN   \n",
       "1         4    null      NaN   \n",
       "2         5    null      NaN   \n",
       "3         6    null      NaN   \n",
       "4         7    null      NaN   \n",
       "...     ...     ...      ...   \n",
       "7604  10863    null      NaN   \n",
       "7605  10864    null      NaN   \n",
       "7606  10866    null      NaN   \n",
       "7608  10869    null      NaN   \n",
       "7612  10873    null      NaN   \n",
       "\n",
       "                                                   text  target  \n",
       "0     Our Deeds are the Reason of this #earthquake M...       1  \n",
       "1                Forest fire near La Ronge Sask. Canada       1  \n",
       "2     All residents asked to 'shelter in place' are ...       1  \n",
       "3     13,000 people receive #wildfires evacuation or...       1  \n",
       "4     Just got sent this photo from Ruby #Alaska as ...       1  \n",
       "...                                                 ...     ...  \n",
       "7604  #WorldNews Fallen powerlines on G:link tram: U...       1  \n",
       "7605  on the flip side I'm at Walmart and there is a...       1  \n",
       "7606  Suicide bomber kills 15 in Saudi security site...       1  \n",
       "7608  Two giant cranes holding a bridge collapse int...       1  \n",
       "7612  The Latest: More Homes Razed by Northern Calif...       1  \n",
       "\n",
       "[7434 rows x 5 columns]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "disaster_list = list(tweets['keyword'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "crash = ['collide', 'collided', 'collision', 'crash', 'crashed', 'wreck', 'wreckage', 'wrecked']\n",
    "\n",
    "emergency = ['emergency', 'emergency plan']\n",
    "\n",
    "electricity = ['electrocute', 'electrocuted',]\n",
    "\n",
    "helpers = ['ambulance', 'police', 'siren', 'sirens', 'emergency services', 'first responders',\\\n",
    "           'stretcher', 'eyewitness', 'rescuers']\n",
    "\n",
    "panic = ['screamed', 'screaming', 'screams', 'panic', 'mayhem', 'riot', 'rioting', 'fear', 'panicking', 'trauma',\\\n",
    "         'trouble', 'hail', 'pandemonium']\n",
    "\n",
    "hostages = ['hostage', 'hostages', 'trapped']\n",
    "\n",
    "quarentine = ['quarantine', 'quarantined']\n",
    "\n",
    "colapse = ['bridge collapse', 'collapse', 'collapsed', 'demolish', 'demolished', 'demolition', 'structural failure']\n",
    "\n",
    "accident = ['accident', 'airplane accident', 'derail', 'derailed', 'derailment', 'oil spill']\n",
    "\n",
    "fire = ['ablaze', 'hellfire', 'smoke', 'wild fires', 'wildfire', 'buildings burning',\\\n",
    "        'buildings on fire', 'burned', 'burning', 'burning buildings', 'bush fires', 'fire',\\\n",
    "        'fire truck', 'flames', 'forest fire', 'forest fires', 'blaze', 'blazing', 'arson', 'arsonist']\n",
    "\n",
    "nuclear = ['nuclear disaster', 'nuclear reactor', 'radiation emergency', 'meltdown']\n",
    "\n",
    "explotion = ['explode', 'exploded', 'explosion', 'blown up', 'blew up', 'loud bang']\n",
    "\n",
    "survivor = ['survive', 'survived', 'rescue', 'rescued', 'survivors', 'evacuate', 'evacuated', 'evacuation', 'refugees']\n",
    "\n",
    "wounded = ['wounded', 'wounds', 'bleeding', 'bloody', 'injured', 'injuries', 'injury', 'traumatised', 'blood']\n",
    "\n",
    "bomb = ['suicide bomb', 'suicide bomber', 'suicide bombing', 'bomb', 'bombed', 'bombing', 'detonate', 'detonation']\n",
    "\n",
    "storm = ['storm', 'thunderstorm', 'thunder', 'rainstorm', 'violent storm', 'windstorm', 'lightning', 'hailstorm']\n",
    "\n",
    "water = ['flood', 'flooding', 'floods', 'inundated', 'inundation', 'sinking', 'drown', 'drowned', 'drowning', 'sunk']\n",
    "\n",
    "natural_disaster = ['heat wave','sandstorm', 'seismic' ,'avalanche', 'tsunami', 'twister',\\\n",
    "                    'typhoon',  'tornado', 'hurricane', 'natural disaster', 'cyclone', 'volcano',\\\n",
    "                    'drought', 'dust storm', 'earthquake',  'lava', 'aftershock', 'snowstorm', 'blizzard',\\\n",
    "                    'whirlwind', 'upheaval',  'landslide', 'cliff fall', 'mudslide', 'sinkhole', 'displaced',\\\n",
    "                    'epicentre']\n",
    "\n",
    "attack = ['attack', 'attacked']\n",
    "\n",
    "casualties = ['mass murder', 'mass murderer', 'massacre', 'fatal', 'fatalities', 'fatality', 'casualties',\\\n",
    "              'casualty', 'body bag', 'body bagging', 'body bags', 'dead', 'death', 'deaths',  'tragedy']\n",
    "\n",
    "terrorism = ['terrorism', 'terrorist', 'threat', 'hijack', 'hijacker', 'hijacking', 'bioterror', 'bioterrorism']\n",
    "\n",
    "destruction = ['destroyed', 'destruction', 'devastated',\\\n",
    "               'devastation', 'disaster', 'annihilated', 'annihilation', 'apocalypse',\\\n",
    "               'armageddon', 'catastrophe', 'catastrophic', 'obliterate', 'obliterated',\\\n",
    "               'obliteration', 'damage', 'destroy', 'desolate', 'desolation', 'blight',\\\n",
    "               'harm', 'hazard', 'hazardous', 'danger', 'ruin', 'engulfed', 'rubble', 'debris',\\\n",
    "               'razed', 'flattened', 'crush', 'crushed']\n",
    "\n",
    "warlike = ['war zone', 'weapon', 'weapons', 'military', 'army', 'battle', 'outbreak', 'chemical emergency', 'curfew']\n",
    "\n",
    "starvation = ['famine', 'deluge', 'deluged']\n",
    "\n",
    "\n",
    "null = ['null']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "disasters = {'crash' : crash, 'emergency' : emergency, 'electricity': electricity,\\\n",
    "             'helpers': helpers, 'panic' : panic,  'hostages' : hostages, 'quarentine' : quarentine,\\\n",
    "             'colapse' : colapse, 'accident' : accident, 'fire' : fire,\\\n",
    "             'nuclear' : nuclear, 'explotion' : explotion, 'survivor' : survivor,\\\n",
    "             'wounded' : wounded, 'bomb' : bomb, 'storm' : storm,\\\n",
    "             'water' : water, 'natural_disaster' : natural_disaster, 'attack' : attack,\\\n",
    "             'casualties' : casualties, 'terrorism' : terrorism, 'destruction' : destruction,\\\n",
    "             'warlike' : warlike, 'starvation' : starvation, 'null' : null}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_categories = len(disasters)\n",
    "n_categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_maps = {}\n",
    "count = 0\n",
    "for k in disasters.keys():\n",
    "    numeric_maps[k] = count\n",
    "    count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping = {}\n",
    "for k, v in disasters.items():\n",
    "    for w in v:\n",
    "        mapping[w] = k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping_df = pd.DataFrame.from_dict(mapping, orient='index').reset_index()\n",
    "mapping_df.columns = ['keyword', 'group']\n",
    "numeric_maps_df = pd.DataFrame.from_dict(numeric_maps, orient='index').reset_index()\n",
    "numeric_maps_df.columns = ['group', 'id']\n",
    "to_encode = mapping_df.merge(numeric_maps_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>keyword</th>\n",
       "      <th>group</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>collide</td>\n",
       "      <td>crash</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>collided</td>\n",
       "      <td>crash</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>collision</td>\n",
       "      <td>crash</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>crash</td>\n",
       "      <td>crash</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>crashed</td>\n",
       "      <td>crash</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>217</th>\n",
       "      <td>curfew</td>\n",
       "      <td>warlike</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>218</th>\n",
       "      <td>famine</td>\n",
       "      <td>starvation</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>219</th>\n",
       "      <td>deluge</td>\n",
       "      <td>starvation</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>220</th>\n",
       "      <td>deluged</td>\n",
       "      <td>starvation</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221</th>\n",
       "      <td>null</td>\n",
       "      <td>null</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>222 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       keyword       group  id\n",
       "0      collide       crash   0\n",
       "1     collided       crash   0\n",
       "2    collision       crash   0\n",
       "3        crash       crash   0\n",
       "4      crashed       crash   0\n",
       "..         ...         ...  ..\n",
       "217     curfew     warlike  22\n",
       "218     famine  starvation  23\n",
       "219     deluge  starvation  23\n",
       "220    deluged  starvation  23\n",
       "221       null        null  24\n",
       "\n",
       "[222 rows x 3 columns]"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_encode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LabelBinarizer()"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelBinarizer\n",
    "\n",
    "lb = preprocessing.LabelBinarizer()\n",
    "lb.fit(range(0, n_categories))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
       "       17, 18, 19, 20, 21, 22, 23, 24])"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lb.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_encode['encode'] = list(lb.transform(to_encode['id']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "expanded = to_encode.encode.apply(pd.Series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pd.concat([to_encode, expanded], axis=1, sort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.drop(columns=['encode', 'id'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>keyword</th>\n",
       "      <th>group</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>...</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>collide</td>\n",
       "      <td>crash</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>collided</td>\n",
       "      <td>crash</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>collision</td>\n",
       "      <td>crash</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>crash</td>\n",
       "      <td>crash</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>crashed</td>\n",
       "      <td>crash</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     keyword  group  0  1  2  3  4  5  6  7  ...  15  16  17  18  19  20  21  \\\n",
       "0    collide  crash  1  0  0  0  0  0  0  0  ...   0   0   0   0   0   0   0   \n",
       "1   collided  crash  1  0  0  0  0  0  0  0  ...   0   0   0   0   0   0   0   \n",
       "2  collision  crash  1  0  0  0  0  0  0  0  ...   0   0   0   0   0   0   0   \n",
       "3      crash  crash  1  0  0  0  0  0  0  0  ...   0   0   0   0   0   0   0   \n",
       "4    crashed  crash  1  0  0  0  0  0  0  0  ...   0   0   0   0   0   0   0   \n",
       "\n",
       "   22  23  24  \n",
       "0   0   0   0  \n",
       "1   0   0   0  \n",
       "2   0   0   0  \n",
       "3   0   0   0  \n",
       "4   0   0   0  \n",
       "\n",
       "[5 rows x 27 columns]"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "keyword_exp = tweets.loc[:, ['id', 'keyword']]\n",
    "keyword_exp_test = test.loc[:, ['id', 'keyword']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_train = keyword_exp.merge(result, left_on='keyword', right_on='keyword', how='left')\n",
    "merged_test = keyword_exp_test.merge(result, left_on='keyword', right_on='keyword', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_train.drop(columns=['keyword', 'group'], inplace=True)\n",
    "merged_test.drop(columns=['keyword', 'group'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run for file\n",
    "#merged_train.to_csv('keyword_mapping.csv', index=False)\n",
    "#merged_test.to_csv('keyword_mapping_test.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Location Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>location</th>\n",
       "      <th>address</th>\n",
       "      <th>point</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>glasgow</td>\n",
       "      <td>Glasgow, Glasgow City, Scotland, G2 9SA, Unite...</td>\n",
       "      <td>(55.8609825, -4.2488787, 0.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>melbourne, australia</td>\n",
       "      <td>City of Melbourne, Victoria, Australia</td>\n",
       "      <td>(-37.8142176, 144.9631608, 0.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>news</td>\n",
       "      <td>34375, Abbotsford Centre, Abbotsford, Fraser V...</td>\n",
       "      <td>(49.04172215, -122.27255349013137, 0.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>alberta</td>\n",
       "      <td>Alberta, Canada</td>\n",
       "      <td>(55.001251, -115.002136, 0.0)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 location                                            address  \\\n",
       "0                                                                        NaN   \n",
       "1                glasgow   Glasgow, Glasgow City, Scotland, G2 9SA, Unite...   \n",
       "2    melbourne, australia             City of Melbourne, Victoria, Australia   \n",
       "3                    news  34375, Abbotsford Centre, Abbotsford, Fraser V...   \n",
       "4                 alberta                                    Alberta, Canada   \n",
       "\n",
       "                                     point  \n",
       "0                                      NaN  \n",
       "1            (55.8609825, -4.2488787, 0.0)  \n",
       "2          (-37.8142176, 144.9631608, 0.0)  \n",
       "3  (49.04172215, -122.27255349013137, 0.0)  \n",
       "4            (55.001251, -115.002136, 0.0)  "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "locations = pd.read_csv(\"../TP1/locations.csv\", usecols=['location', 'address', 'point'])\n",
    "locations.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>location</th>\n",
       "      <th>address</th>\n",
       "      <th>point</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>null</td>\n",
       "      <td>null</td>\n",
       "      <td>null</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>glasgow</td>\n",
       "      <td>Glasgow, Glasgow City, Scotland, G2 9SA, Unite...</td>\n",
       "      <td>(55.8609825, -4.2488787, 0.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>melbourne, australia</td>\n",
       "      <td>City of Melbourne, Victoria, Australia</td>\n",
       "      <td>(-37.8142176, 144.9631608, 0.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>news</td>\n",
       "      <td>34375, Abbotsford Centre, Abbotsford, Fraser V...</td>\n",
       "      <td>(49.04172215, -122.27255349013137, 0.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>alberta</td>\n",
       "      <td>Alberta, Canada</td>\n",
       "      <td>(55.001251, -115.002136, 0.0)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 location                                            address  \\\n",
       "0                    null                                               null   \n",
       "1                glasgow   Glasgow, Glasgow City, Scotland, G2 9SA, Unite...   \n",
       "2    melbourne, australia             City of Melbourne, Victoria, Australia   \n",
       "3                    news  34375, Abbotsford Centre, Abbotsford, Fraser V...   \n",
       "4                 alberta                                    Alberta, Canada   \n",
       "\n",
       "                                     point  \n",
       "0                                     null  \n",
       "1            (55.8609825, -4.2488787, 0.0)  \n",
       "2          (-37.8142176, 144.9631608, 0.0)  \n",
       "3  (49.04172215, -122.27255349013137, 0.0)  \n",
       "4            (55.001251, -115.002136, 0.0)  "
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "locations.fillna('null', inplace=True)\n",
    "empty_loc = locations.loc[0, 'location']\n",
    "locations.replace(empty_loc, 'null', inplace=True)\n",
    "locations.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Coordinates X,Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets['location'] = tweets['location'].fillna('null')\n",
    "test['location'] = test['location'].fillna('null')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def point_to_list(point):\n",
    "    if point == 'null':\n",
    "        return [300.0, 300.0] # Arbitrary large number \n",
    "    \n",
    "    coordinates = []\n",
    "    aux = point[:]\n",
    "    row = aux.strip( '()' ).split(',')\n",
    "    coordinates.append(float(row[0]))\n",
    "    coordinates.append(float(row[1]))\n",
    "    return coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "locations['point'] = locations.point.apply(point_to_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "aux = locations.point.apply(pd.Series)\n",
    "aux.columns = ['x', 'y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "locations['x'] = aux['x']\n",
    "locations['y'] = aux['y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>location</th>\n",
       "      <th>address</th>\n",
       "      <th>point</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>null</td>\n",
       "      <td>null</td>\n",
       "      <td>[300.0, 300.0]</td>\n",
       "      <td>300.000000</td>\n",
       "      <td>300.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>glasgow</td>\n",
       "      <td>Glasgow, Glasgow City, Scotland, G2 9SA, Unite...</td>\n",
       "      <td>[55.8609825, -4.2488787]</td>\n",
       "      <td>55.860982</td>\n",
       "      <td>-4.248879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>melbourne, australia</td>\n",
       "      <td>City of Melbourne, Victoria, Australia</td>\n",
       "      <td>[-37.8142176, 144.9631608]</td>\n",
       "      <td>-37.814218</td>\n",
       "      <td>144.963161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>news</td>\n",
       "      <td>34375, Abbotsford Centre, Abbotsford, Fraser V...</td>\n",
       "      <td>[49.04172215, -122.27255349013137]</td>\n",
       "      <td>49.041722</td>\n",
       "      <td>-122.272553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>alberta</td>\n",
       "      <td>Alberta, Canada</td>\n",
       "      <td>[55.001251, -115.002136]</td>\n",
       "      <td>55.001251</td>\n",
       "      <td>-115.002136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2266</th>\n",
       "      <td>zac newsome loves me</td>\n",
       "      <td>null</td>\n",
       "      <td>[300.0, 300.0]</td>\n",
       "      <td>300.000000</td>\n",
       "      <td>300.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2267</th>\n",
       "      <td>zeerust, south africa</td>\n",
       "      <td>Zeerust, Ngaka Modiri Molema District Municipa...</td>\n",
       "      <td>[-25.537731, 26.074382]</td>\n",
       "      <td>-25.537731</td>\n",
       "      <td>26.074382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2268</th>\n",
       "      <td>zero branco</td>\n",
       "      <td>Zero Branco, Treviso, Veneto, 31059, Italia</td>\n",
       "      <td>[45.601701, 12.165212]</td>\n",
       "      <td>45.601701</td>\n",
       "      <td>12.165212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2269</th>\n",
       "      <td>ziam af</td>\n",
       "      <td>null</td>\n",
       "      <td>[300.0, 300.0]</td>\n",
       "      <td>300.000000</td>\n",
       "      <td>300.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2270</th>\n",
       "      <td>zimbabwe</td>\n",
       "      <td>Zimbabwe</td>\n",
       "      <td>[-18.4554963, 29.7468414]</td>\n",
       "      <td>-18.455496</td>\n",
       "      <td>29.746841</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2271 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    location  \\\n",
       "0                       null   \n",
       "1                   glasgow    \n",
       "2       melbourne, australia   \n",
       "3                       news   \n",
       "4                    alberta   \n",
       "...                      ...   \n",
       "2266    zac newsome loves me   \n",
       "2267   zeerust, south africa   \n",
       "2268             zero branco   \n",
       "2269                ziam af    \n",
       "2270                zimbabwe   \n",
       "\n",
       "                                                address  \\\n",
       "0                                                  null   \n",
       "1     Glasgow, Glasgow City, Scotland, G2 9SA, Unite...   \n",
       "2                City of Melbourne, Victoria, Australia   \n",
       "3     34375, Abbotsford Centre, Abbotsford, Fraser V...   \n",
       "4                                       Alberta, Canada   \n",
       "...                                                 ...   \n",
       "2266                                               null   \n",
       "2267  Zeerust, Ngaka Modiri Molema District Municipa...   \n",
       "2268        Zero Branco, Treviso, Veneto, 31059, Italia   \n",
       "2269                                               null   \n",
       "2270                                           Zimbabwe   \n",
       "\n",
       "                                   point           x           y  \n",
       "0                         [300.0, 300.0]  300.000000  300.000000  \n",
       "1               [55.8609825, -4.2488787]   55.860982   -4.248879  \n",
       "2             [-37.8142176, 144.9631608]  -37.814218  144.963161  \n",
       "3     [49.04172215, -122.27255349013137]   49.041722 -122.272553  \n",
       "4               [55.001251, -115.002136]   55.001251 -115.002136  \n",
       "...                                  ...         ...         ...  \n",
       "2266                      [300.0, 300.0]  300.000000  300.000000  \n",
       "2267             [-25.537731, 26.074382]  -25.537731   26.074382  \n",
       "2268              [45.601701, 12.165212]   45.601701   12.165212  \n",
       "2269                      [300.0, 300.0]  300.000000  300.000000  \n",
       "2270           [-18.4554963, 29.7468414]  -18.455496   29.746841  \n",
       "\n",
       "[2271 rows x 5 columns]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets['location'] = tweets['location'].apply(str.lower)\n",
    "test['location'] = test['location'].apply(str.lower)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "coordinates_train = tweets.merge(locations.loc[:, ['location', 'x', 'y']], left_on='location', right_on='location', how='left').loc[:, ['id', 'x', 'y']]\n",
    "coordinates_test = test.merge(locations.loc[:, ['location', 'x', 'y']], left_on='location', right_on='location', how='left').loc[:, ['id', 'x', 'y']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run for file\n",
    "coordinates_train.to_csv('coordinates_train.csv', index=False)\n",
    "coordinates_test.to_csv('coordinates_test.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Coordinates, vectors from words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>location</th>\n",
       "      <th>address</th>\n",
       "      <th>point</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>null</td>\n",
       "      <td>null</td>\n",
       "      <td>[300.0, 300.0]</td>\n",
       "      <td>300.000000</td>\n",
       "      <td>300.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>glasgow</td>\n",
       "      <td>Glasgow, Glasgow City, Scotland, G2 9SA, Unite...</td>\n",
       "      <td>[55.8609825, -4.2488787]</td>\n",
       "      <td>55.860982</td>\n",
       "      <td>-4.248879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>melbourne, australia</td>\n",
       "      <td>City of Melbourne, Victoria, Australia</td>\n",
       "      <td>[-37.8142176, 144.9631608]</td>\n",
       "      <td>-37.814218</td>\n",
       "      <td>144.963161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>news</td>\n",
       "      <td>34375, Abbotsford Centre, Abbotsford, Fraser V...</td>\n",
       "      <td>[49.04172215, -122.27255349013137]</td>\n",
       "      <td>49.041722</td>\n",
       "      <td>-122.272553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>alberta</td>\n",
       "      <td>Alberta, Canada</td>\n",
       "      <td>[55.001251, -115.002136]</td>\n",
       "      <td>55.001251</td>\n",
       "      <td>-115.002136</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 location                                            address  \\\n",
       "0                    null                                               null   \n",
       "1                glasgow   Glasgow, Glasgow City, Scotland, G2 9SA, Unite...   \n",
       "2    melbourne, australia             City of Melbourne, Victoria, Australia   \n",
       "3                    news  34375, Abbotsford Centre, Abbotsford, Fraser V...   \n",
       "4                 alberta                                    Alberta, Canada   \n",
       "\n",
       "                                point           x           y  \n",
       "0                      [300.0, 300.0]  300.000000  300.000000  \n",
       "1            [55.8609825, -4.2488787]   55.860982   -4.248879  \n",
       "2          [-37.8142176, 144.9631608]  -37.814218  144.963161  \n",
       "3  [49.04172215, -122.27255349013137]   49.041722 -122.272553  \n",
       "4            [55.001251, -115.002136]   55.001251 -115.002136  "
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "locations.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets['location'] = tweets['location'].fillna('null')\n",
    "test['location'] = test['location'].fillna('null')\n",
    "tweets['location'] = tweets['location'].str.replace(',','')\n",
    "test['location'] = test['location'].str.replace(',','')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "location_tokens = tweets.location.unique().tolist()\n",
    "location_test = test.location.unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in location_test:\n",
    "    if k not in location_tokens:\n",
    "        print(k) # Mismas palabras en ambos sets, jaja no."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 400000 word vectors.\n"
     ]
    }
   ],
   "source": [
    "embeddings_index = dict()\n",
    "f = open('Embeddings/glove.6B.100d.txt', encoding='utf8') # Vectores entrenados de 100 dimensiones\n",
    "for line in f:\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    coefs = np.asarray(values[1:], dtype='float32')\n",
    "    embeddings_index[word] = coefs\n",
    "f.close()\n",
    "print('Loaded %s word vectors.' % len(embeddings_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectors = {}\n",
    "for location in location_tokens:\n",
    "    words = location.split(' ')\n",
    "    n = len(words)\n",
    "    try:\n",
    "        if n == 1:\n",
    "            vectors[location] = embeddings_index[location]\n",
    "        else:\n",
    "            acum = np.zeros(100)\n",
    "            for w in words:\n",
    "                acum = np.sum([acum,embeddings_index[w]] , axis=0)\n",
    "    except KeyError:\n",
    "        continue\n",
    "        vectors[location] = acum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>...</th>\n",
       "      <th>90</th>\n",
       "      <th>91</th>\n",
       "      <th>92</th>\n",
       "      <th>93</th>\n",
       "      <th>94</th>\n",
       "      <th>95</th>\n",
       "      <th>96</th>\n",
       "      <th>97</th>\n",
       "      <th>98</th>\n",
       "      <th>99</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>null</td>\n",
       "      <td>0.079432</td>\n",
       "      <td>-0.14054</td>\n",
       "      <td>-0.10462</td>\n",
       "      <td>-0.36259</td>\n",
       "      <td>-0.227210</td>\n",
       "      <td>-0.13612</td>\n",
       "      <td>0.74755</td>\n",
       "      <td>0.32809</td>\n",
       "      <td>0.54364</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.21230</td>\n",
       "      <td>0.515730</td>\n",
       "      <td>0.16573</td>\n",
       "      <td>0.67943</td>\n",
       "      <td>0.353270</td>\n",
       "      <td>0.176720</td>\n",
       "      <td>0.25803</td>\n",
       "      <td>0.068445</td>\n",
       "      <td>-1.20160</td>\n",
       "      <td>-0.20168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>birmingham</td>\n",
       "      <td>0.473340</td>\n",
       "      <td>0.28810</td>\n",
       "      <td>-0.40206</td>\n",
       "      <td>-0.76942</td>\n",
       "      <td>0.505650</td>\n",
       "      <td>0.56655</td>\n",
       "      <td>0.15756</td>\n",
       "      <td>0.28222</td>\n",
       "      <td>-0.63076</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.45335</td>\n",
       "      <td>-0.588940</td>\n",
       "      <td>0.10209</td>\n",
       "      <td>1.43720</td>\n",
       "      <td>-0.396420</td>\n",
       "      <td>0.050214</td>\n",
       "      <td>0.57303</td>\n",
       "      <td>0.742570</td>\n",
       "      <td>0.65308</td>\n",
       "      <td>-0.56826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>africa</td>\n",
       "      <td>-0.286410</td>\n",
       "      <td>0.84050</td>\n",
       "      <td>1.11780</td>\n",
       "      <td>0.18766</td>\n",
       "      <td>0.073111</td>\n",
       "      <td>-0.24262</td>\n",
       "      <td>0.12002</td>\n",
       "      <td>0.90520</td>\n",
       "      <td>-0.77801</td>\n",
       "      <td>...</td>\n",
       "      <td>0.18550</td>\n",
       "      <td>-0.019433</td>\n",
       "      <td>0.64313</td>\n",
       "      <td>-0.22149</td>\n",
       "      <td>-0.372510</td>\n",
       "      <td>0.586410</td>\n",
       "      <td>-0.80282</td>\n",
       "      <td>-0.227080</td>\n",
       "      <td>0.29665</td>\n",
       "      <td>0.20128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>pretoria</td>\n",
       "      <td>-0.100460</td>\n",
       "      <td>-0.44136</td>\n",
       "      <td>0.66512</td>\n",
       "      <td>0.27777</td>\n",
       "      <td>-0.599210</td>\n",
       "      <td>0.29228</td>\n",
       "      <td>0.18710</td>\n",
       "      <td>1.24120</td>\n",
       "      <td>-0.70815</td>\n",
       "      <td>...</td>\n",
       "      <td>0.51562</td>\n",
       "      <td>-0.461100</td>\n",
       "      <td>-0.13979</td>\n",
       "      <td>0.35418</td>\n",
       "      <td>-0.058125</td>\n",
       "      <td>0.664700</td>\n",
       "      <td>-0.38143</td>\n",
       "      <td>0.084048</td>\n",
       "      <td>0.42608</td>\n",
       "      <td>0.40040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>india</td>\n",
       "      <td>-0.959670</td>\n",
       "      <td>0.30795</td>\n",
       "      <td>0.90052</td>\n",
       "      <td>1.03640</td>\n",
       "      <td>0.003491</td>\n",
       "      <td>-0.80758</td>\n",
       "      <td>-1.13900</td>\n",
       "      <td>0.81109</td>\n",
       "      <td>-0.67857</td>\n",
       "      <td>...</td>\n",
       "      <td>0.25884</td>\n",
       "      <td>-0.194630</td>\n",
       "      <td>-0.27582</td>\n",
       "      <td>-0.70492</td>\n",
       "      <td>-0.694540</td>\n",
       "      <td>0.706240</td>\n",
       "      <td>0.22830</td>\n",
       "      <td>0.081052</td>\n",
       "      <td>0.13510</td>\n",
       "      <td>0.14388</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 101 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        index         0        1        2        3         4        5  \\\n",
       "0        null  0.079432 -0.14054 -0.10462 -0.36259 -0.227210 -0.13612   \n",
       "1  birmingham  0.473340  0.28810 -0.40206 -0.76942  0.505650  0.56655   \n",
       "2      africa -0.286410  0.84050  1.11780  0.18766  0.073111 -0.24262   \n",
       "3    pretoria -0.100460 -0.44136  0.66512  0.27777 -0.599210  0.29228   \n",
       "4       india -0.959670  0.30795  0.90052  1.03640  0.003491 -0.80758   \n",
       "\n",
       "         6        7        8  ...       90        91       92       93  \\\n",
       "0  0.74755  0.32809  0.54364  ... -1.21230  0.515730  0.16573  0.67943   \n",
       "1  0.15756  0.28222 -0.63076  ... -0.45335 -0.588940  0.10209  1.43720   \n",
       "2  0.12002  0.90520 -0.77801  ...  0.18550 -0.019433  0.64313 -0.22149   \n",
       "3  0.18710  1.24120 -0.70815  ...  0.51562 -0.461100 -0.13979  0.35418   \n",
       "4 -1.13900  0.81109 -0.67857  ...  0.25884 -0.194630 -0.27582 -0.70492   \n",
       "\n",
       "         94        95       96        97       98       99  \n",
       "0  0.353270  0.176720  0.25803  0.068445 -1.20160 -0.20168  \n",
       "1 -0.396420  0.050214  0.57303  0.742570  0.65308 -0.56826  \n",
       "2 -0.372510  0.586410 -0.80282 -0.227080  0.29665  0.20128  \n",
       "3 -0.058125  0.664700 -0.38143  0.084048  0.42608  0.40040  \n",
       "4 -0.694540  0.706240  0.22830  0.081052  0.13510  0.14388  \n",
       "\n",
       "[5 rows x 101 columns]"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "location_vectors = pd.DataFrame.from_dict(vectors).T.reset_index()\n",
    "location_vectors.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "aux = []\n",
    "aux.append('location')\n",
    "for i in range (0, 100):\n",
    "    name = 'l' + str(i)\n",
    "    aux.append(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "location_vectors.columns = aux\n",
    "location_vectors.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "locations_to_merge = tweets.merge(location_vectors, on='location', how = 'outer')#.drop(columns=['keyword', 'location', 'text', 'target'])\n",
    "locations_to_merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "locations_test_merge = test.merge(location_vectors, how='left').drop(columns=['keyword', 'location', 'text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "locations_to_merge.to_csv('locations_vectors_train.csv', index = False)\n",
    "locations_test_merge.to_csv('locations_vectors_test.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge all things"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 501,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_w_features = pd.read_csv('../TP2/train_features.csv')\n",
    "test_w_features = pd.read_csv('../TP2/test_features.csv')\n",
    "keyword_features = pd.read_csv('../TP2/keyword_features.csv')\n",
    "keyword_test_features = pd.read_csv('../TP2/keyword_test_features.csv')\n",
    "train_processed_text = pd.read_csv('../TP2/processed_train.csv')\n",
    "test_processed_text = pd.read_csv('../TP2/processed_test.csv')\n",
    "location_train_xy = pd.read_csv('../TP2/coordinates_train.csv')\n",
    "location_test_xy = pd.read_csv('../TP2/coordinates_test.csv')\n",
    "location_train_vectors = pd.read_csv('../TP2/locations_vectors_train.csv')\n",
    "location_test_vectors = pd.read_csv('../TP2/locations_vectors_test.csv')\n",
    "\n",
    "train_w_features.insert(3,'target',train_processed_text['target'])\n",
    "train_features_and_kw = train_w_features.merge(keyword_features, on='id')\n",
    "train_features_and_kw.insert(3,'processed_text', train_processed_text['text'])\n",
    "\n",
    "test_features_and_kw = test_w_features.merge(keyword_test_features, on='id')\n",
    "test_features_and_kw.insert(3,'processed_text', test_processed_text['text'])\n",
    "\n",
    "train_features_and_kw['text_without_stopwords'] = train_features_and_kw['text_without_stopwords'].fillna('')\n",
    "test_features_and_kw['text_without_stopwords'] = test_features_and_kw['text_without_stopwords'].fillna('')\n",
    "\n",
    "locations_train = location_train_xy.merge(location_train_vectors, on = 'id')\n",
    "locations_test = location_test_xy.merge(location_test_vectors, on = 'id')\n",
    "\n",
    "train_complete = train_features_and_kw.merge(locations_train, on = 'id')\n",
    "test_complete = test_features_and_kw.merge(locations_test, on = 'id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 505,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_complete['x'] = train_complete['x'].fillna(300.0)\n",
    "test_complete['x'] = test_complete['x'].fillna(300.0)\n",
    "train_complete['y'] = train_complete['y'].fillna(300.0)\n",
    "test_complete['y'] = test_complete['y'].fillna(300.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 526,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "loc_values = locations_train.loc[0,'l0':].to_list()\n",
    "for column in train_complete.loc[:,'l0':].columns:\n",
    "    train_complete[column] = train_complete[column].fillna(loc_values[i])\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 530,
   "metadata": {},
   "outputs": [],
   "source": [
    "j = 0\n",
    "loc_values2 = locations_test.loc[0,'l0':].to_list()\n",
    "for column in test_complete.loc[:,'l0':].columns:\n",
    "    test_complete[column] = test_complete[column].fillna(loc_values2[j])\n",
    "    j+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_complete.to_csv('train_complete.csv', index = False)\n",
    "test_complete.to_csv('test_complete.csv', index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
