{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     /Users/matiascano/nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/matiascano/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/matiascano/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/matiascano/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import string\n",
    "#import xgboost as xgb\n",
    "import io\n",
    "import nltk\n",
    "import matplotlib\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn import preprocessing\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "nltk.download('vader_lexicon')\n",
    "nltk.download('stopwords')\n",
    "stopwords = stopwords.words('english')\n",
    "stemmer = SnowballStemmer('english')\n",
    "\n",
    "from textblob import TextBlob\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "pd.set_option('mode.chained_assignment', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = pd.read_csv(\"train.csv\")\n",
    "test = pd.read_csv(\"test.csv\")\n",
    "tweets['keyword'] = tweets.keyword.str.replace('%20',' ')\n",
    "test['keyword'] = test.keyword.str.replace('%20',' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 7434 entries, 0 to 7612\n",
      "Data columns (total 5 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   id        7434 non-null   int64 \n",
      " 1   keyword   7378 non-null   object\n",
      " 2   location  4982 non-null   object\n",
      " 3   text      7434 non-null   object\n",
      " 4   target    7434 non-null   int64 \n",
      "dtypes: int64(2), object(3)\n",
      "memory usage: 348.5+ KB\n"
     ]
    }
   ],
   "source": [
    "tweets.drop_duplicates(subset = 'text', keep = False, inplace = True)\n",
    "tweets.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    3243\n",
       "True       20\n",
       "Name: text, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test['text'].duplicated().value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extra Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sia = SentimentIntensityAnalyzer()\n",
    "def return_sia_compound_values(text):\n",
    "    return sia.polarity_scores(text)['compound']\n",
    "\n",
    "def remove_stopword(text):\n",
    "    new_text = []\n",
    "    for e in text:\n",
    "        if e not in stopwords and e.isalpha():\n",
    "            new_text.append(e)\n",
    "    text = new_text\n",
    "    return \" \".join(new_text)\n",
    "\n",
    "def stemm(text):\n",
    "    text = [stemmer.stem(word) for word in text.split()]\n",
    "    return \" \".join(text)\n",
    "\n",
    "def contains_punctuation(text):\n",
    "    punctuation = set(string.punctuation)\n",
    "    for character in text:\n",
    "        if character in punctuation:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "def amount_of_punctuation(text):\n",
    "    punctuation = set(string.punctuation)\n",
    "    amount = 0\n",
    "    for character in text:\n",
    "        if character in punctuation: amount += 1\n",
    "    return amount\n",
    "\n",
    "def get_adjectives(text):\n",
    "    blob = TextBlob(text)\n",
    "    return len([word for (word,tag) in blob.tags if tag.startswith(\"JJ\")])\n",
    "\n",
    "def get_nouns(text):\n",
    "    blob = TextBlob(text)\n",
    "    return len([word for (word,tag) in blob.tags if tag.startswith(\"NN\")])\n",
    "\n",
    "def get_verbs(text):\n",
    "    blob = TextBlob(text)\n",
    "    return len([word for (word,tag) in blob.tags if tag.startswith(\"VB\")])\n",
    "\n",
    "def get_adverbs(text):\n",
    "    blob = TextBlob(text)\n",
    "    return len([word for (word,tag) in blob.tags if tag.startswith(\"RB\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_metrics(df):\n",
    "    tweets_metrics = df[['id','text']]\n",
    "    tweets_metrics['text_without_stopwords'] = tweets_metrics['text'].str.split()\n",
    "    tweets_metrics['text_without_stopwords'] = tweets_metrics['text_without_stopwords'].apply(remove_stopword)\n",
    "    tweets_metrics['length'] = tweets_metrics['text'].apply(lambda x: len(x))\n",
    "    tweets_metrics['avg_word_length'] = tweets_metrics['text'].str.split().apply(lambda x: [len(y) for y in x]).transform(lambda x: np.mean(x))\n",
    "    tweets_metrics['amount_of_words'] = tweets_metrics['text'].str.split().transform(lambda x: len(x))\n",
    "    unique_words_by_tweet = tweets_metrics['text'].transform(lambda x: x.split()).transform(lambda x: pd.Series(x).unique()).transform(lambda x: len(x))\n",
    "    tweets_metrics['amount_of_unique_words'] = unique_words_by_tweet\n",
    "    tweets_metrics['sentiment'] = tweets_metrics['text'].apply(lambda x: return_sia_compound_values(x))\n",
    "    tweets_metrics['stopwords_count'] = tweets_metrics['text'].apply(lambda x: len([word for word in str(x).lower().split() if word in stopwords]))\n",
    "    tweets_metrics['punctuation_count'] = tweets_metrics['text'].apply(lambda x: amount_of_punctuation(x))\n",
    "    mentions = tweets_metrics['text'].str.findall(r'@.\\S*?(?=\\s|[:]|$)').to_frame()\n",
    "    tweets_metrics['mentions_count'] = mentions['text'].apply(lambda x: len(x))\n",
    "    hashtags = tweets_metrics['text'].str.findall(r'#[^?\\s].*?(?=\\s|$)')\n",
    "    tweets_metrics['hashtags_count'] = hashtags.apply(lambda x: len(x))\n",
    "    tweets_metrics['longest_word_length_without_stopwords'] = tweets_metrics['text_without_stopwords'].apply(lambda x: ([len(word) for word in str(x).lower().split() if not word.startswith('http')])).apply(lambda x: max(x) if len(x) > 0 else 0)\n",
    "    tweets_metrics['stopword_word_ratio'] = tweets_metrics['stopwords_count'] / tweets_metrics['amount_of_words']\n",
    "    tweets_metrics['adjectives_count'] = tweets_metrics['text'].apply(get_adjectives)\n",
    "    tweets_metrics['nouns_count'] = tweets_metrics['text'].apply(get_nouns)\n",
    "    tweets_metrics['verbs_count'] = tweets_metrics['text'].apply(get_verbs)\n",
    "    tweets_metrics['adverbs_count'] = tweets_metrics['text'].apply(get_adverbs)\n",
    "    return tweets_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_metrics = get_metrics(tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_metrics = get_metrics(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run for files\n",
    "#train_metrics.to_csv('train_features.csv', index=False)\n",
    "#test_metrics.to_csv('test_features.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mocks real tokenizer used in glove\n",
    "import re\n",
    "\n",
    "def tokenize_input(input_text):\n",
    "    to_tokens = input_text[:]\n",
    "    token_specification = [\n",
    "        ('url', r'https?:\\/\\/\\S+\\b|www\\.(\\w+\\.)+\\S*'),\n",
    "        (' / ', r'/'),\n",
    "        ('user', r'@\\w+'),            \n",
    "        ('smile', r'[8:=;][)d]+|[)d]+[\\'`\\-]?[8:=;]'),    \n",
    "        ('lolface', r'[8:=;][\\'`\\-]?p'),      \n",
    "        ('sadface', r'[8:=;][\\'`\\-]?\\(|\\)+[8:=;][\\'`\\-]?'),          \n",
    "        ('neutralface', r'[8:=;][\\'`\\-]?[\\/|l*]'),       \n",
    "        ('heart', r'<3'),   \n",
    "        ('number', r'[-+]?[.\\d]*[\\d]+[:,.\\d]*')\n",
    "    ]\n",
    "    for replacement, regex in token_specification:\n",
    "        to_tokens = re.sub(regex, replacement, to_tokens)\n",
    "    return to_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'url hola  /  smile heart lolface sadface  number user'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check\n",
    "tokenize_input('https://regexr.com hola / :) <3 :p :(  8888 @justin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "\n",
    "tweets['text'] = tweets['text'].apply(tokenize_input)\n",
    "test['text'] = test['text'].apply(tokenize_input)\n",
    "tweets['text'] = tweets['text'].apply(lambda x: x.translate({ord(i): ' ' for i in string.punctuation}))\n",
    "test['text'] = test['text'].apply(lambda x: x.translate({ord(i): ' ' for i in string.punctuation}))\n",
    "tweets['text'] = tweets['text'].apply(lambda x: x.lower())\n",
    "test['text'] = test['text'].apply(lambda x: x.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run for files\n",
    "#tweets.to_csv('processed_train.csv', index=False)\n",
    "#test.to_csv('processed_test.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vector encoding\n",
    "\n",
    "#### Keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets['keyword'] = tweets['keyword'].fillna('null')\n",
    "test['keyword'] = test['keyword'].fillna('null')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "keyword_tokens = tweets.keyword.unique().tolist()\n",
    "keyword_test = test.keyword.unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in keyword_test:\n",
    "    if k not in keyword_tokens:\n",
    "        print(k) # Mismas palabras en ambos sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 400001 word vectors.\n"
     ]
    }
   ],
   "source": [
    "embeddings_index = dict()\n",
    "f = open('glove.6B.100d.txt', encoding='utf8') # Vectores entrenados de 100 dimensiones\n",
    "for line in f:\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    coefs = np.asarray(values[1:], dtype='float32')\n",
    "    embeddings_index[word] = coefs\n",
    "f.close()\n",
    "print('Loaded %s word vectors.' % len(embeddings_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectors = {}\n",
    "for keyword in keyword_tokens:\n",
    "    words = keyword.split(' ')\n",
    "    n = len(words)\n",
    "    if n == 1:\n",
    "        vectors[keyword] = embeddings_index[keyword]\n",
    "    else:\n",
    "        acum = np.zeros(100)\n",
    "        for w in words:\n",
    "            acum = np.sum([acum,embeddings_index[w]] , axis=0)\n",
    "        vectors[keyword] = acum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>...</th>\n",
       "      <th>90</th>\n",
       "      <th>91</th>\n",
       "      <th>92</th>\n",
       "      <th>93</th>\n",
       "      <th>94</th>\n",
       "      <th>95</th>\n",
       "      <th>96</th>\n",
       "      <th>97</th>\n",
       "      <th>98</th>\n",
       "      <th>99</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>null</td>\n",
       "      <td>0.079432</td>\n",
       "      <td>-0.14054</td>\n",
       "      <td>-0.104620</td>\n",
       "      <td>-0.362590</td>\n",
       "      <td>-0.22721</td>\n",
       "      <td>-0.13612</td>\n",
       "      <td>0.74755</td>\n",
       "      <td>0.328090</td>\n",
       "      <td>0.54364</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.21230</td>\n",
       "      <td>0.515730</td>\n",
       "      <td>0.16573</td>\n",
       "      <td>0.679430</td>\n",
       "      <td>0.353270</td>\n",
       "      <td>0.17672</td>\n",
       "      <td>0.258030</td>\n",
       "      <td>0.068445</td>\n",
       "      <td>-1.20160</td>\n",
       "      <td>-0.20168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ablaze</td>\n",
       "      <td>0.137010</td>\n",
       "      <td>-0.31349</td>\n",
       "      <td>-0.047427</td>\n",
       "      <td>-0.245820</td>\n",
       "      <td>0.76459</td>\n",
       "      <td>1.21330</td>\n",
       "      <td>0.25674</td>\n",
       "      <td>0.446160</td>\n",
       "      <td>1.21040</td>\n",
       "      <td>...</td>\n",
       "      <td>1.42780</td>\n",
       "      <td>-0.402050</td>\n",
       "      <td>-0.26682</td>\n",
       "      <td>-0.029039</td>\n",
       "      <td>-1.102300</td>\n",
       "      <td>0.20442</td>\n",
       "      <td>-0.064528</td>\n",
       "      <td>0.305040</td>\n",
       "      <td>0.42830</td>\n",
       "      <td>0.54531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>accident</td>\n",
       "      <td>-0.006329</td>\n",
       "      <td>-0.37913</td>\n",
       "      <td>0.409920</td>\n",
       "      <td>-0.003844</td>\n",
       "      <td>-0.81139</td>\n",
       "      <td>-0.67840</td>\n",
       "      <td>0.25995</td>\n",
       "      <td>1.090300</td>\n",
       "      <td>0.60039</td>\n",
       "      <td>...</td>\n",
       "      <td>0.49451</td>\n",
       "      <td>-0.308700</td>\n",
       "      <td>-0.18550</td>\n",
       "      <td>0.714090</td>\n",
       "      <td>0.198860</td>\n",
       "      <td>1.12760</td>\n",
       "      <td>-0.100960</td>\n",
       "      <td>-0.100000</td>\n",
       "      <td>0.21349</td>\n",
       "      <td>-1.24530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>aftershock</td>\n",
       "      <td>0.136920</td>\n",
       "      <td>1.02570</td>\n",
       "      <td>0.539610</td>\n",
       "      <td>0.275310</td>\n",
       "      <td>-0.91579</td>\n",
       "      <td>0.24287</td>\n",
       "      <td>0.77162</td>\n",
       "      <td>0.025242</td>\n",
       "      <td>0.47416</td>\n",
       "      <td>...</td>\n",
       "      <td>1.23600</td>\n",
       "      <td>0.126510</td>\n",
       "      <td>-0.93994</td>\n",
       "      <td>0.187410</td>\n",
       "      <td>0.712540</td>\n",
       "      <td>0.79876</td>\n",
       "      <td>-0.040149</td>\n",
       "      <td>-0.591220</td>\n",
       "      <td>-0.28051</td>\n",
       "      <td>-0.23293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>airplane accident</td>\n",
       "      <td>-0.175379</td>\n",
       "      <td>-0.10526</td>\n",
       "      <td>0.977860</td>\n",
       "      <td>-0.001856</td>\n",
       "      <td>-0.93397</td>\n",
       "      <td>-1.15404</td>\n",
       "      <td>0.79570</td>\n",
       "      <td>1.143708</td>\n",
       "      <td>0.94012</td>\n",
       "      <td>...</td>\n",
       "      <td>0.78136</td>\n",
       "      <td>-0.287935</td>\n",
       "      <td>0.23436</td>\n",
       "      <td>0.676289</td>\n",
       "      <td>0.262775</td>\n",
       "      <td>1.53821</td>\n",
       "      <td>-0.300710</td>\n",
       "      <td>-0.089367</td>\n",
       "      <td>0.77883</td>\n",
       "      <td>-2.21178</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 101 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               index         0        1         2         3        4        5  \\\n",
       "0               null  0.079432 -0.14054 -0.104620 -0.362590 -0.22721 -0.13612   \n",
       "1             ablaze  0.137010 -0.31349 -0.047427 -0.245820  0.76459  1.21330   \n",
       "2           accident -0.006329 -0.37913  0.409920 -0.003844 -0.81139 -0.67840   \n",
       "3         aftershock  0.136920  1.02570  0.539610  0.275310 -0.91579  0.24287   \n",
       "4  airplane accident -0.175379 -0.10526  0.977860 -0.001856 -0.93397 -1.15404   \n",
       "\n",
       "         6         7        8  ...       90        91       92        93  \\\n",
       "0  0.74755  0.328090  0.54364  ... -1.21230  0.515730  0.16573  0.679430   \n",
       "1  0.25674  0.446160  1.21040  ...  1.42780 -0.402050 -0.26682 -0.029039   \n",
       "2  0.25995  1.090300  0.60039  ...  0.49451 -0.308700 -0.18550  0.714090   \n",
       "3  0.77162  0.025242  0.47416  ...  1.23600  0.126510 -0.93994  0.187410   \n",
       "4  0.79570  1.143708  0.94012  ...  0.78136 -0.287935  0.23436  0.676289   \n",
       "\n",
       "         94       95        96        97       98       99  \n",
       "0  0.353270  0.17672  0.258030  0.068445 -1.20160 -0.20168  \n",
       "1 -1.102300  0.20442 -0.064528  0.305040  0.42830  0.54531  \n",
       "2  0.198860  1.12760 -0.100960 -0.100000  0.21349 -1.24530  \n",
       "3  0.712540  0.79876 -0.040149 -0.591220 -0.28051 -0.23293  \n",
       "4  0.262775  1.53821 -0.300710 -0.089367  0.77883 -2.21178  \n",
       "\n",
       "[5 rows x 101 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keyword_vectors = pd.DataFrame.from_dict(vectors).T.reset_index()\n",
    "keyword_vectors.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "aux = []\n",
    "aux.append('keyword')\n",
    "for i in range (0, 100):\n",
    "    name = 'k' + str(i)\n",
    "    aux.append(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>keyword</th>\n",
       "      <th>k0</th>\n",
       "      <th>k1</th>\n",
       "      <th>k2</th>\n",
       "      <th>k3</th>\n",
       "      <th>k4</th>\n",
       "      <th>k5</th>\n",
       "      <th>k6</th>\n",
       "      <th>k7</th>\n",
       "      <th>k8</th>\n",
       "      <th>...</th>\n",
       "      <th>k90</th>\n",
       "      <th>k91</th>\n",
       "      <th>k92</th>\n",
       "      <th>k93</th>\n",
       "      <th>k94</th>\n",
       "      <th>k95</th>\n",
       "      <th>k96</th>\n",
       "      <th>k97</th>\n",
       "      <th>k98</th>\n",
       "      <th>k99</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>null</td>\n",
       "      <td>0.079432</td>\n",
       "      <td>-0.14054</td>\n",
       "      <td>-0.104620</td>\n",
       "      <td>-0.362590</td>\n",
       "      <td>-0.22721</td>\n",
       "      <td>-0.13612</td>\n",
       "      <td>0.74755</td>\n",
       "      <td>0.328090</td>\n",
       "      <td>0.54364</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.21230</td>\n",
       "      <td>0.515730</td>\n",
       "      <td>0.16573</td>\n",
       "      <td>0.679430</td>\n",
       "      <td>0.353270</td>\n",
       "      <td>0.17672</td>\n",
       "      <td>0.258030</td>\n",
       "      <td>0.068445</td>\n",
       "      <td>-1.20160</td>\n",
       "      <td>-0.20168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ablaze</td>\n",
       "      <td>0.137010</td>\n",
       "      <td>-0.31349</td>\n",
       "      <td>-0.047427</td>\n",
       "      <td>-0.245820</td>\n",
       "      <td>0.76459</td>\n",
       "      <td>1.21330</td>\n",
       "      <td>0.25674</td>\n",
       "      <td>0.446160</td>\n",
       "      <td>1.21040</td>\n",
       "      <td>...</td>\n",
       "      <td>1.42780</td>\n",
       "      <td>-0.402050</td>\n",
       "      <td>-0.26682</td>\n",
       "      <td>-0.029039</td>\n",
       "      <td>-1.102300</td>\n",
       "      <td>0.20442</td>\n",
       "      <td>-0.064528</td>\n",
       "      <td>0.305040</td>\n",
       "      <td>0.42830</td>\n",
       "      <td>0.54531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>accident</td>\n",
       "      <td>-0.006329</td>\n",
       "      <td>-0.37913</td>\n",
       "      <td>0.409920</td>\n",
       "      <td>-0.003844</td>\n",
       "      <td>-0.81139</td>\n",
       "      <td>-0.67840</td>\n",
       "      <td>0.25995</td>\n",
       "      <td>1.090300</td>\n",
       "      <td>0.60039</td>\n",
       "      <td>...</td>\n",
       "      <td>0.49451</td>\n",
       "      <td>-0.308700</td>\n",
       "      <td>-0.18550</td>\n",
       "      <td>0.714090</td>\n",
       "      <td>0.198860</td>\n",
       "      <td>1.12760</td>\n",
       "      <td>-0.100960</td>\n",
       "      <td>-0.100000</td>\n",
       "      <td>0.21349</td>\n",
       "      <td>-1.24530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>aftershock</td>\n",
       "      <td>0.136920</td>\n",
       "      <td>1.02570</td>\n",
       "      <td>0.539610</td>\n",
       "      <td>0.275310</td>\n",
       "      <td>-0.91579</td>\n",
       "      <td>0.24287</td>\n",
       "      <td>0.77162</td>\n",
       "      <td>0.025242</td>\n",
       "      <td>0.47416</td>\n",
       "      <td>...</td>\n",
       "      <td>1.23600</td>\n",
       "      <td>0.126510</td>\n",
       "      <td>-0.93994</td>\n",
       "      <td>0.187410</td>\n",
       "      <td>0.712540</td>\n",
       "      <td>0.79876</td>\n",
       "      <td>-0.040149</td>\n",
       "      <td>-0.591220</td>\n",
       "      <td>-0.28051</td>\n",
       "      <td>-0.23293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>airplane accident</td>\n",
       "      <td>-0.175379</td>\n",
       "      <td>-0.10526</td>\n",
       "      <td>0.977860</td>\n",
       "      <td>-0.001856</td>\n",
       "      <td>-0.93397</td>\n",
       "      <td>-1.15404</td>\n",
       "      <td>0.79570</td>\n",
       "      <td>1.143708</td>\n",
       "      <td>0.94012</td>\n",
       "      <td>...</td>\n",
       "      <td>0.78136</td>\n",
       "      <td>-0.287935</td>\n",
       "      <td>0.23436</td>\n",
       "      <td>0.676289</td>\n",
       "      <td>0.262775</td>\n",
       "      <td>1.53821</td>\n",
       "      <td>-0.300710</td>\n",
       "      <td>-0.089367</td>\n",
       "      <td>0.77883</td>\n",
       "      <td>-2.21178</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 101 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             keyword        k0       k1        k2        k3       k4       k5  \\\n",
       "0               null  0.079432 -0.14054 -0.104620 -0.362590 -0.22721 -0.13612   \n",
       "1             ablaze  0.137010 -0.31349 -0.047427 -0.245820  0.76459  1.21330   \n",
       "2           accident -0.006329 -0.37913  0.409920 -0.003844 -0.81139 -0.67840   \n",
       "3         aftershock  0.136920  1.02570  0.539610  0.275310 -0.91579  0.24287   \n",
       "4  airplane accident -0.175379 -0.10526  0.977860 -0.001856 -0.93397 -1.15404   \n",
       "\n",
       "        k6        k7       k8  ...      k90       k91      k92       k93  \\\n",
       "0  0.74755  0.328090  0.54364  ... -1.21230  0.515730  0.16573  0.679430   \n",
       "1  0.25674  0.446160  1.21040  ...  1.42780 -0.402050 -0.26682 -0.029039   \n",
       "2  0.25995  1.090300  0.60039  ...  0.49451 -0.308700 -0.18550  0.714090   \n",
       "3  0.77162  0.025242  0.47416  ...  1.23600  0.126510 -0.93994  0.187410   \n",
       "4  0.79570  1.143708  0.94012  ...  0.78136 -0.287935  0.23436  0.676289   \n",
       "\n",
       "        k94      k95       k96       k97      k98      k99  \n",
       "0  0.353270  0.17672  0.258030  0.068445 -1.20160 -0.20168  \n",
       "1 -1.102300  0.20442 -0.064528  0.305040  0.42830  0.54531  \n",
       "2  0.198860  1.12760 -0.100960 -0.100000  0.21349 -1.24530  \n",
       "3  0.712540  0.79876 -0.040149 -0.591220 -0.28051 -0.23293  \n",
       "4  0.262775  1.53821 -0.300710 -0.089367  0.77883 -2.21178  \n",
       "\n",
       "[5 rows x 101 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keyword_vectors.columns = aux\n",
    "keyword_vectors.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>k0</th>\n",
       "      <th>k1</th>\n",
       "      <th>k2</th>\n",
       "      <th>k3</th>\n",
       "      <th>k4</th>\n",
       "      <th>k5</th>\n",
       "      <th>k6</th>\n",
       "      <th>k7</th>\n",
       "      <th>k8</th>\n",
       "      <th>...</th>\n",
       "      <th>k90</th>\n",
       "      <th>k91</th>\n",
       "      <th>k92</th>\n",
       "      <th>k93</th>\n",
       "      <th>k94</th>\n",
       "      <th>k95</th>\n",
       "      <th>k96</th>\n",
       "      <th>k97</th>\n",
       "      <th>k98</th>\n",
       "      <th>k99</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.079432</td>\n",
       "      <td>-0.14054</td>\n",
       "      <td>-0.10462</td>\n",
       "      <td>-0.36259</td>\n",
       "      <td>-0.22721</td>\n",
       "      <td>-0.13612</td>\n",
       "      <td>0.74755</td>\n",
       "      <td>0.32809</td>\n",
       "      <td>0.54364</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.2123</td>\n",
       "      <td>0.51573</td>\n",
       "      <td>0.16573</td>\n",
       "      <td>0.67943</td>\n",
       "      <td>0.35327</td>\n",
       "      <td>0.17672</td>\n",
       "      <td>0.25803</td>\n",
       "      <td>0.068445</td>\n",
       "      <td>-1.2016</td>\n",
       "      <td>-0.20168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>0.079432</td>\n",
       "      <td>-0.14054</td>\n",
       "      <td>-0.10462</td>\n",
       "      <td>-0.36259</td>\n",
       "      <td>-0.22721</td>\n",
       "      <td>-0.13612</td>\n",
       "      <td>0.74755</td>\n",
       "      <td>0.32809</td>\n",
       "      <td>0.54364</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.2123</td>\n",
       "      <td>0.51573</td>\n",
       "      <td>0.16573</td>\n",
       "      <td>0.67943</td>\n",
       "      <td>0.35327</td>\n",
       "      <td>0.17672</td>\n",
       "      <td>0.25803</td>\n",
       "      <td>0.068445</td>\n",
       "      <td>-1.2016</td>\n",
       "      <td>-0.20168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>0.079432</td>\n",
       "      <td>-0.14054</td>\n",
       "      <td>-0.10462</td>\n",
       "      <td>-0.36259</td>\n",
       "      <td>-0.22721</td>\n",
       "      <td>-0.13612</td>\n",
       "      <td>0.74755</td>\n",
       "      <td>0.32809</td>\n",
       "      <td>0.54364</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.2123</td>\n",
       "      <td>0.51573</td>\n",
       "      <td>0.16573</td>\n",
       "      <td>0.67943</td>\n",
       "      <td>0.35327</td>\n",
       "      <td>0.17672</td>\n",
       "      <td>0.25803</td>\n",
       "      <td>0.068445</td>\n",
       "      <td>-1.2016</td>\n",
       "      <td>-0.20168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>0.079432</td>\n",
       "      <td>-0.14054</td>\n",
       "      <td>-0.10462</td>\n",
       "      <td>-0.36259</td>\n",
       "      <td>-0.22721</td>\n",
       "      <td>-0.13612</td>\n",
       "      <td>0.74755</td>\n",
       "      <td>0.32809</td>\n",
       "      <td>0.54364</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.2123</td>\n",
       "      <td>0.51573</td>\n",
       "      <td>0.16573</td>\n",
       "      <td>0.67943</td>\n",
       "      <td>0.35327</td>\n",
       "      <td>0.17672</td>\n",
       "      <td>0.25803</td>\n",
       "      <td>0.068445</td>\n",
       "      <td>-1.2016</td>\n",
       "      <td>-0.20168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>0.079432</td>\n",
       "      <td>-0.14054</td>\n",
       "      <td>-0.10462</td>\n",
       "      <td>-0.36259</td>\n",
       "      <td>-0.22721</td>\n",
       "      <td>-0.13612</td>\n",
       "      <td>0.74755</td>\n",
       "      <td>0.32809</td>\n",
       "      <td>0.54364</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.2123</td>\n",
       "      <td>0.51573</td>\n",
       "      <td>0.16573</td>\n",
       "      <td>0.67943</td>\n",
       "      <td>0.35327</td>\n",
       "      <td>0.17672</td>\n",
       "      <td>0.25803</td>\n",
       "      <td>0.068445</td>\n",
       "      <td>-1.2016</td>\n",
       "      <td>-0.20168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7429</th>\n",
       "      <td>10863</td>\n",
       "      <td>0.079432</td>\n",
       "      <td>-0.14054</td>\n",
       "      <td>-0.10462</td>\n",
       "      <td>-0.36259</td>\n",
       "      <td>-0.22721</td>\n",
       "      <td>-0.13612</td>\n",
       "      <td>0.74755</td>\n",
       "      <td>0.32809</td>\n",
       "      <td>0.54364</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.2123</td>\n",
       "      <td>0.51573</td>\n",
       "      <td>0.16573</td>\n",
       "      <td>0.67943</td>\n",
       "      <td>0.35327</td>\n",
       "      <td>0.17672</td>\n",
       "      <td>0.25803</td>\n",
       "      <td>0.068445</td>\n",
       "      <td>-1.2016</td>\n",
       "      <td>-0.20168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7430</th>\n",
       "      <td>10864</td>\n",
       "      <td>0.079432</td>\n",
       "      <td>-0.14054</td>\n",
       "      <td>-0.10462</td>\n",
       "      <td>-0.36259</td>\n",
       "      <td>-0.22721</td>\n",
       "      <td>-0.13612</td>\n",
       "      <td>0.74755</td>\n",
       "      <td>0.32809</td>\n",
       "      <td>0.54364</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.2123</td>\n",
       "      <td>0.51573</td>\n",
       "      <td>0.16573</td>\n",
       "      <td>0.67943</td>\n",
       "      <td>0.35327</td>\n",
       "      <td>0.17672</td>\n",
       "      <td>0.25803</td>\n",
       "      <td>0.068445</td>\n",
       "      <td>-1.2016</td>\n",
       "      <td>-0.20168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7431</th>\n",
       "      <td>10866</td>\n",
       "      <td>0.079432</td>\n",
       "      <td>-0.14054</td>\n",
       "      <td>-0.10462</td>\n",
       "      <td>-0.36259</td>\n",
       "      <td>-0.22721</td>\n",
       "      <td>-0.13612</td>\n",
       "      <td>0.74755</td>\n",
       "      <td>0.32809</td>\n",
       "      <td>0.54364</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.2123</td>\n",
       "      <td>0.51573</td>\n",
       "      <td>0.16573</td>\n",
       "      <td>0.67943</td>\n",
       "      <td>0.35327</td>\n",
       "      <td>0.17672</td>\n",
       "      <td>0.25803</td>\n",
       "      <td>0.068445</td>\n",
       "      <td>-1.2016</td>\n",
       "      <td>-0.20168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7432</th>\n",
       "      <td>10869</td>\n",
       "      <td>0.079432</td>\n",
       "      <td>-0.14054</td>\n",
       "      <td>-0.10462</td>\n",
       "      <td>-0.36259</td>\n",
       "      <td>-0.22721</td>\n",
       "      <td>-0.13612</td>\n",
       "      <td>0.74755</td>\n",
       "      <td>0.32809</td>\n",
       "      <td>0.54364</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.2123</td>\n",
       "      <td>0.51573</td>\n",
       "      <td>0.16573</td>\n",
       "      <td>0.67943</td>\n",
       "      <td>0.35327</td>\n",
       "      <td>0.17672</td>\n",
       "      <td>0.25803</td>\n",
       "      <td>0.068445</td>\n",
       "      <td>-1.2016</td>\n",
       "      <td>-0.20168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7433</th>\n",
       "      <td>10873</td>\n",
       "      <td>0.079432</td>\n",
       "      <td>-0.14054</td>\n",
       "      <td>-0.10462</td>\n",
       "      <td>-0.36259</td>\n",
       "      <td>-0.22721</td>\n",
       "      <td>-0.13612</td>\n",
       "      <td>0.74755</td>\n",
       "      <td>0.32809</td>\n",
       "      <td>0.54364</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.2123</td>\n",
       "      <td>0.51573</td>\n",
       "      <td>0.16573</td>\n",
       "      <td>0.67943</td>\n",
       "      <td>0.35327</td>\n",
       "      <td>0.17672</td>\n",
       "      <td>0.25803</td>\n",
       "      <td>0.068445</td>\n",
       "      <td>-1.2016</td>\n",
       "      <td>-0.20168</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7434 rows × 101 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id        k0       k1       k2       k3       k4       k5       k6  \\\n",
       "0         1  0.079432 -0.14054 -0.10462 -0.36259 -0.22721 -0.13612  0.74755   \n",
       "1         4  0.079432 -0.14054 -0.10462 -0.36259 -0.22721 -0.13612  0.74755   \n",
       "2         5  0.079432 -0.14054 -0.10462 -0.36259 -0.22721 -0.13612  0.74755   \n",
       "3         6  0.079432 -0.14054 -0.10462 -0.36259 -0.22721 -0.13612  0.74755   \n",
       "4         7  0.079432 -0.14054 -0.10462 -0.36259 -0.22721 -0.13612  0.74755   \n",
       "...     ...       ...      ...      ...      ...      ...      ...      ...   \n",
       "7429  10863  0.079432 -0.14054 -0.10462 -0.36259 -0.22721 -0.13612  0.74755   \n",
       "7430  10864  0.079432 -0.14054 -0.10462 -0.36259 -0.22721 -0.13612  0.74755   \n",
       "7431  10866  0.079432 -0.14054 -0.10462 -0.36259 -0.22721 -0.13612  0.74755   \n",
       "7432  10869  0.079432 -0.14054 -0.10462 -0.36259 -0.22721 -0.13612  0.74755   \n",
       "7433  10873  0.079432 -0.14054 -0.10462 -0.36259 -0.22721 -0.13612  0.74755   \n",
       "\n",
       "           k7       k8  ...     k90      k91      k92      k93      k94  \\\n",
       "0     0.32809  0.54364  ... -1.2123  0.51573  0.16573  0.67943  0.35327   \n",
       "1     0.32809  0.54364  ... -1.2123  0.51573  0.16573  0.67943  0.35327   \n",
       "2     0.32809  0.54364  ... -1.2123  0.51573  0.16573  0.67943  0.35327   \n",
       "3     0.32809  0.54364  ... -1.2123  0.51573  0.16573  0.67943  0.35327   \n",
       "4     0.32809  0.54364  ... -1.2123  0.51573  0.16573  0.67943  0.35327   \n",
       "...       ...      ...  ...     ...      ...      ...      ...      ...   \n",
       "7429  0.32809  0.54364  ... -1.2123  0.51573  0.16573  0.67943  0.35327   \n",
       "7430  0.32809  0.54364  ... -1.2123  0.51573  0.16573  0.67943  0.35327   \n",
       "7431  0.32809  0.54364  ... -1.2123  0.51573  0.16573  0.67943  0.35327   \n",
       "7432  0.32809  0.54364  ... -1.2123  0.51573  0.16573  0.67943  0.35327   \n",
       "7433  0.32809  0.54364  ... -1.2123  0.51573  0.16573  0.67943  0.35327   \n",
       "\n",
       "          k95      k96       k97     k98      k99  \n",
       "0     0.17672  0.25803  0.068445 -1.2016 -0.20168  \n",
       "1     0.17672  0.25803  0.068445 -1.2016 -0.20168  \n",
       "2     0.17672  0.25803  0.068445 -1.2016 -0.20168  \n",
       "3     0.17672  0.25803  0.068445 -1.2016 -0.20168  \n",
       "4     0.17672  0.25803  0.068445 -1.2016 -0.20168  \n",
       "...       ...      ...       ...     ...      ...  \n",
       "7429  0.17672  0.25803  0.068445 -1.2016 -0.20168  \n",
       "7430  0.17672  0.25803  0.068445 -1.2016 -0.20168  \n",
       "7431  0.17672  0.25803  0.068445 -1.2016 -0.20168  \n",
       "7432  0.17672  0.25803  0.068445 -1.2016 -0.20168  \n",
       "7433  0.17672  0.25803  0.068445 -1.2016 -0.20168  \n",
       "\n",
       "[7434 rows x 101 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keywords_to_merge = tweets.merge(keyword_vectors, how='left').drop(columns=['keyword', 'location', 'text', 'target'])\n",
    "keywords_to_merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>k0</th>\n",
       "      <th>k1</th>\n",
       "      <th>k2</th>\n",
       "      <th>k3</th>\n",
       "      <th>k4</th>\n",
       "      <th>k5</th>\n",
       "      <th>k6</th>\n",
       "      <th>k7</th>\n",
       "      <th>k8</th>\n",
       "      <th>...</th>\n",
       "      <th>k90</th>\n",
       "      <th>k91</th>\n",
       "      <th>k92</th>\n",
       "      <th>k93</th>\n",
       "      <th>k94</th>\n",
       "      <th>k95</th>\n",
       "      <th>k96</th>\n",
       "      <th>k97</th>\n",
       "      <th>k98</th>\n",
       "      <th>k99</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.079432</td>\n",
       "      <td>-0.14054</td>\n",
       "      <td>-0.10462</td>\n",
       "      <td>-0.36259</td>\n",
       "      <td>-0.22721</td>\n",
       "      <td>-0.13612</td>\n",
       "      <td>0.74755</td>\n",
       "      <td>0.32809</td>\n",
       "      <td>0.54364</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.2123</td>\n",
       "      <td>0.51573</td>\n",
       "      <td>0.16573</td>\n",
       "      <td>0.67943</td>\n",
       "      <td>0.35327</td>\n",
       "      <td>0.17672</td>\n",
       "      <td>0.25803</td>\n",
       "      <td>0.068445</td>\n",
       "      <td>-1.2016</td>\n",
       "      <td>-0.20168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.079432</td>\n",
       "      <td>-0.14054</td>\n",
       "      <td>-0.10462</td>\n",
       "      <td>-0.36259</td>\n",
       "      <td>-0.22721</td>\n",
       "      <td>-0.13612</td>\n",
       "      <td>0.74755</td>\n",
       "      <td>0.32809</td>\n",
       "      <td>0.54364</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.2123</td>\n",
       "      <td>0.51573</td>\n",
       "      <td>0.16573</td>\n",
       "      <td>0.67943</td>\n",
       "      <td>0.35327</td>\n",
       "      <td>0.17672</td>\n",
       "      <td>0.25803</td>\n",
       "      <td>0.068445</td>\n",
       "      <td>-1.2016</td>\n",
       "      <td>-0.20168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.079432</td>\n",
       "      <td>-0.14054</td>\n",
       "      <td>-0.10462</td>\n",
       "      <td>-0.36259</td>\n",
       "      <td>-0.22721</td>\n",
       "      <td>-0.13612</td>\n",
       "      <td>0.74755</td>\n",
       "      <td>0.32809</td>\n",
       "      <td>0.54364</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.2123</td>\n",
       "      <td>0.51573</td>\n",
       "      <td>0.16573</td>\n",
       "      <td>0.67943</td>\n",
       "      <td>0.35327</td>\n",
       "      <td>0.17672</td>\n",
       "      <td>0.25803</td>\n",
       "      <td>0.068445</td>\n",
       "      <td>-1.2016</td>\n",
       "      <td>-0.20168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>0.079432</td>\n",
       "      <td>-0.14054</td>\n",
       "      <td>-0.10462</td>\n",
       "      <td>-0.36259</td>\n",
       "      <td>-0.22721</td>\n",
       "      <td>-0.13612</td>\n",
       "      <td>0.74755</td>\n",
       "      <td>0.32809</td>\n",
       "      <td>0.54364</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.2123</td>\n",
       "      <td>0.51573</td>\n",
       "      <td>0.16573</td>\n",
       "      <td>0.67943</td>\n",
       "      <td>0.35327</td>\n",
       "      <td>0.17672</td>\n",
       "      <td>0.25803</td>\n",
       "      <td>0.068445</td>\n",
       "      <td>-1.2016</td>\n",
       "      <td>-0.20168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11</td>\n",
       "      <td>0.079432</td>\n",
       "      <td>-0.14054</td>\n",
       "      <td>-0.10462</td>\n",
       "      <td>-0.36259</td>\n",
       "      <td>-0.22721</td>\n",
       "      <td>-0.13612</td>\n",
       "      <td>0.74755</td>\n",
       "      <td>0.32809</td>\n",
       "      <td>0.54364</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.2123</td>\n",
       "      <td>0.51573</td>\n",
       "      <td>0.16573</td>\n",
       "      <td>0.67943</td>\n",
       "      <td>0.35327</td>\n",
       "      <td>0.17672</td>\n",
       "      <td>0.25803</td>\n",
       "      <td>0.068445</td>\n",
       "      <td>-1.2016</td>\n",
       "      <td>-0.20168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3258</th>\n",
       "      <td>10861</td>\n",
       "      <td>0.079432</td>\n",
       "      <td>-0.14054</td>\n",
       "      <td>-0.10462</td>\n",
       "      <td>-0.36259</td>\n",
       "      <td>-0.22721</td>\n",
       "      <td>-0.13612</td>\n",
       "      <td>0.74755</td>\n",
       "      <td>0.32809</td>\n",
       "      <td>0.54364</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.2123</td>\n",
       "      <td>0.51573</td>\n",
       "      <td>0.16573</td>\n",
       "      <td>0.67943</td>\n",
       "      <td>0.35327</td>\n",
       "      <td>0.17672</td>\n",
       "      <td>0.25803</td>\n",
       "      <td>0.068445</td>\n",
       "      <td>-1.2016</td>\n",
       "      <td>-0.20168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3259</th>\n",
       "      <td>10865</td>\n",
       "      <td>0.079432</td>\n",
       "      <td>-0.14054</td>\n",
       "      <td>-0.10462</td>\n",
       "      <td>-0.36259</td>\n",
       "      <td>-0.22721</td>\n",
       "      <td>-0.13612</td>\n",
       "      <td>0.74755</td>\n",
       "      <td>0.32809</td>\n",
       "      <td>0.54364</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.2123</td>\n",
       "      <td>0.51573</td>\n",
       "      <td>0.16573</td>\n",
       "      <td>0.67943</td>\n",
       "      <td>0.35327</td>\n",
       "      <td>0.17672</td>\n",
       "      <td>0.25803</td>\n",
       "      <td>0.068445</td>\n",
       "      <td>-1.2016</td>\n",
       "      <td>-0.20168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3260</th>\n",
       "      <td>10868</td>\n",
       "      <td>0.079432</td>\n",
       "      <td>-0.14054</td>\n",
       "      <td>-0.10462</td>\n",
       "      <td>-0.36259</td>\n",
       "      <td>-0.22721</td>\n",
       "      <td>-0.13612</td>\n",
       "      <td>0.74755</td>\n",
       "      <td>0.32809</td>\n",
       "      <td>0.54364</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.2123</td>\n",
       "      <td>0.51573</td>\n",
       "      <td>0.16573</td>\n",
       "      <td>0.67943</td>\n",
       "      <td>0.35327</td>\n",
       "      <td>0.17672</td>\n",
       "      <td>0.25803</td>\n",
       "      <td>0.068445</td>\n",
       "      <td>-1.2016</td>\n",
       "      <td>-0.20168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3261</th>\n",
       "      <td>10874</td>\n",
       "      <td>0.079432</td>\n",
       "      <td>-0.14054</td>\n",
       "      <td>-0.10462</td>\n",
       "      <td>-0.36259</td>\n",
       "      <td>-0.22721</td>\n",
       "      <td>-0.13612</td>\n",
       "      <td>0.74755</td>\n",
       "      <td>0.32809</td>\n",
       "      <td>0.54364</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.2123</td>\n",
       "      <td>0.51573</td>\n",
       "      <td>0.16573</td>\n",
       "      <td>0.67943</td>\n",
       "      <td>0.35327</td>\n",
       "      <td>0.17672</td>\n",
       "      <td>0.25803</td>\n",
       "      <td>0.068445</td>\n",
       "      <td>-1.2016</td>\n",
       "      <td>-0.20168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3262</th>\n",
       "      <td>10875</td>\n",
       "      <td>0.079432</td>\n",
       "      <td>-0.14054</td>\n",
       "      <td>-0.10462</td>\n",
       "      <td>-0.36259</td>\n",
       "      <td>-0.22721</td>\n",
       "      <td>-0.13612</td>\n",
       "      <td>0.74755</td>\n",
       "      <td>0.32809</td>\n",
       "      <td>0.54364</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.2123</td>\n",
       "      <td>0.51573</td>\n",
       "      <td>0.16573</td>\n",
       "      <td>0.67943</td>\n",
       "      <td>0.35327</td>\n",
       "      <td>0.17672</td>\n",
       "      <td>0.25803</td>\n",
       "      <td>0.068445</td>\n",
       "      <td>-1.2016</td>\n",
       "      <td>-0.20168</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3263 rows × 101 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id        k0       k1       k2       k3       k4       k5       k6  \\\n",
       "0         0  0.079432 -0.14054 -0.10462 -0.36259 -0.22721 -0.13612  0.74755   \n",
       "1         2  0.079432 -0.14054 -0.10462 -0.36259 -0.22721 -0.13612  0.74755   \n",
       "2         3  0.079432 -0.14054 -0.10462 -0.36259 -0.22721 -0.13612  0.74755   \n",
       "3         9  0.079432 -0.14054 -0.10462 -0.36259 -0.22721 -0.13612  0.74755   \n",
       "4        11  0.079432 -0.14054 -0.10462 -0.36259 -0.22721 -0.13612  0.74755   \n",
       "...     ...       ...      ...      ...      ...      ...      ...      ...   \n",
       "3258  10861  0.079432 -0.14054 -0.10462 -0.36259 -0.22721 -0.13612  0.74755   \n",
       "3259  10865  0.079432 -0.14054 -0.10462 -0.36259 -0.22721 -0.13612  0.74755   \n",
       "3260  10868  0.079432 -0.14054 -0.10462 -0.36259 -0.22721 -0.13612  0.74755   \n",
       "3261  10874  0.079432 -0.14054 -0.10462 -0.36259 -0.22721 -0.13612  0.74755   \n",
       "3262  10875  0.079432 -0.14054 -0.10462 -0.36259 -0.22721 -0.13612  0.74755   \n",
       "\n",
       "           k7       k8  ...     k90      k91      k92      k93      k94  \\\n",
       "0     0.32809  0.54364  ... -1.2123  0.51573  0.16573  0.67943  0.35327   \n",
       "1     0.32809  0.54364  ... -1.2123  0.51573  0.16573  0.67943  0.35327   \n",
       "2     0.32809  0.54364  ... -1.2123  0.51573  0.16573  0.67943  0.35327   \n",
       "3     0.32809  0.54364  ... -1.2123  0.51573  0.16573  0.67943  0.35327   \n",
       "4     0.32809  0.54364  ... -1.2123  0.51573  0.16573  0.67943  0.35327   \n",
       "...       ...      ...  ...     ...      ...      ...      ...      ...   \n",
       "3258  0.32809  0.54364  ... -1.2123  0.51573  0.16573  0.67943  0.35327   \n",
       "3259  0.32809  0.54364  ... -1.2123  0.51573  0.16573  0.67943  0.35327   \n",
       "3260  0.32809  0.54364  ... -1.2123  0.51573  0.16573  0.67943  0.35327   \n",
       "3261  0.32809  0.54364  ... -1.2123  0.51573  0.16573  0.67943  0.35327   \n",
       "3262  0.32809  0.54364  ... -1.2123  0.51573  0.16573  0.67943  0.35327   \n",
       "\n",
       "          k95      k96       k97     k98      k99  \n",
       "0     0.17672  0.25803  0.068445 -1.2016 -0.20168  \n",
       "1     0.17672  0.25803  0.068445 -1.2016 -0.20168  \n",
       "2     0.17672  0.25803  0.068445 -1.2016 -0.20168  \n",
       "3     0.17672  0.25803  0.068445 -1.2016 -0.20168  \n",
       "4     0.17672  0.25803  0.068445 -1.2016 -0.20168  \n",
       "...       ...      ...       ...     ...      ...  \n",
       "3258  0.17672  0.25803  0.068445 -1.2016 -0.20168  \n",
       "3259  0.17672  0.25803  0.068445 -1.2016 -0.20168  \n",
       "3260  0.17672  0.25803  0.068445 -1.2016 -0.20168  \n",
       "3261  0.17672  0.25803  0.068445 -1.2016 -0.20168  \n",
       "3262  0.17672  0.25803  0.068445 -1.2016 -0.20168  \n",
       "\n",
       "[3263 rows x 101 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keywords_merge_test = test.merge(keyword_vectors, how='left').drop(columns=['keyword', 'location', 'text'])\n",
    "keywords_merge_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run for files\n",
    "keywords_to_merge.to_csv('keyword_features.csv', index=False)\n",
    "keywords_merge_test.to_csv('keyword_test_features.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Keywords one hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>null</td>\n",
       "      <td>NaN</td>\n",
       "      <td>our deeds are the reason of this  earthquake m...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>null</td>\n",
       "      <td>NaN</td>\n",
       "      <td>forest fire near la ronge sask  canada</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>null</td>\n",
       "      <td>NaN</td>\n",
       "      <td>all residents asked to  shelter in place  are ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>null</td>\n",
       "      <td>NaN</td>\n",
       "      <td>number people receive  wildfires evacuation or...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>null</td>\n",
       "      <td>NaN</td>\n",
       "      <td>just got sent this photo from ruby  alaska as ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7604</th>\n",
       "      <td>10863</td>\n",
       "      <td>null</td>\n",
       "      <td>NaN</td>\n",
       "      <td>worldnews fallen powerlines on gneutralfacein...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7605</th>\n",
       "      <td>10864</td>\n",
       "      <td>null</td>\n",
       "      <td>NaN</td>\n",
       "      <td>on the flip side i m at walmart and there is a...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7606</th>\n",
       "      <td>10866</td>\n",
       "      <td>null</td>\n",
       "      <td>NaN</td>\n",
       "      <td>suicide bomber kills number in saudi security ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7608</th>\n",
       "      <td>10869</td>\n",
       "      <td>null</td>\n",
       "      <td>NaN</td>\n",
       "      <td>two giant cranes holding a bridge collapse int...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7612</th>\n",
       "      <td>10873</td>\n",
       "      <td>null</td>\n",
       "      <td>NaN</td>\n",
       "      <td>the latest  more homes razed by northern calif...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7434 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id keyword location  \\\n",
       "0         1    null      NaN   \n",
       "1         4    null      NaN   \n",
       "2         5    null      NaN   \n",
       "3         6    null      NaN   \n",
       "4         7    null      NaN   \n",
       "...     ...     ...      ...   \n",
       "7604  10863    null      NaN   \n",
       "7605  10864    null      NaN   \n",
       "7606  10866    null      NaN   \n",
       "7608  10869    null      NaN   \n",
       "7612  10873    null      NaN   \n",
       "\n",
       "                                                   text  target  \n",
       "0     our deeds are the reason of this  earthquake m...       1  \n",
       "1                forest fire near la ronge sask  canada       1  \n",
       "2     all residents asked to  shelter in place  are ...       1  \n",
       "3     number people receive  wildfires evacuation or...       1  \n",
       "4     just got sent this photo from ruby  alaska as ...       1  \n",
       "...                                                 ...     ...  \n",
       "7604   worldnews fallen powerlines on gneutralfacein...       1  \n",
       "7605  on the flip side i m at walmart and there is a...       1  \n",
       "7606  suicide bomber kills number in saudi security ...       1  \n",
       "7608  two giant cranes holding a bridge collapse int...       1  \n",
       "7612  the latest  more homes razed by northern calif...       1  \n",
       "\n",
       "[7434 rows x 5 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "disaster_list = list(tweets['keyword'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "crash = ['collide', 'collided', 'collision', 'crash', 'crashed', 'wreck', 'wreckage', 'wrecked']\n",
    "\n",
    "emergency = ['emergency', 'emergency plan']\n",
    "\n",
    "electricity = ['electrocute', 'electrocuted',]\n",
    "\n",
    "helpers = ['ambulance', 'police', 'siren', 'sirens', 'emergency services', 'first responders',\\\n",
    "           'stretcher', 'eyewitness', 'rescuers']\n",
    "\n",
    "panic = ['screamed', 'screaming', 'screams', 'panic', 'mayhem', 'riot', 'rioting', 'fear', 'panicking', 'trauma',\\\n",
    "         'trouble', 'hail', 'pandemonium']\n",
    "\n",
    "hostages = ['hostage', 'hostages', 'trapped']\n",
    "\n",
    "quarentine = ['quarantine', 'quarantined']\n",
    "\n",
    "colapse = ['bridge collapse', 'collapse', 'collapsed', 'demolish', 'demolished', 'demolition', 'structural failure']\n",
    "\n",
    "accident = ['accident', 'airplane accident', 'derail', 'derailed', 'derailment', 'oil spill']\n",
    "\n",
    "fire = ['ablaze', 'hellfire', 'smoke', 'wild fires', 'wildfire', 'buildings burning',\\\n",
    "        'buildings on fire', 'burned', 'burning', 'burning buildings', 'bush fires', 'fire',\\\n",
    "        'fire truck', 'flames', 'forest fire', 'forest fires', 'blaze', 'blazing', 'arson', 'arsonist']\n",
    "\n",
    "nuclear = ['nuclear disaster', 'nuclear reactor', 'radiation emergency', 'meltdown']\n",
    "\n",
    "explotion = ['explode', 'exploded', 'explosion', 'blown up', 'blew up', 'loud bang']\n",
    "\n",
    "survivor = ['survive', 'survived', 'rescue', 'rescued', 'survivors', 'evacuate', 'evacuated', 'evacuation', 'refugees']\n",
    "\n",
    "wounded = ['wounded', 'wounds', 'bleeding', 'bloody', 'injured', 'injuries', 'injury', 'traumatised', 'blood']\n",
    "\n",
    "bomb = ['suicide bomb', 'suicide bomber', 'suicide bombing', 'bomb', 'bombed', 'bombing', 'detonate', 'detonation']\n",
    "\n",
    "storm = ['storm', 'thunderstorm', 'thunder', 'rainstorm', 'violent storm', 'windstorm', 'lightning', 'hailstorm']\n",
    "\n",
    "water = ['flood', 'flooding', 'floods', 'inundated', 'inundation', 'sinking', 'drown', 'drowned', 'drowning', 'sunk']\n",
    "\n",
    "natural_disaster = ['heat wave','sandstorm', 'seismic' ,'avalanche', 'tsunami', 'twister',\\\n",
    "                    'typhoon',  'tornado', 'hurricane', 'natural disaster', 'cyclone', 'volcano',\\\n",
    "                    'drought', 'dust storm', 'earthquake',  'lava', 'aftershock', 'snowstorm', 'blizzard',\\\n",
    "                    'whirlwind', 'upheaval',  'landslide', 'cliff fall', 'mudslide', 'sinkhole', 'displaced',\\\n",
    "                    'epicentre']\n",
    "\n",
    "attack = ['attack', 'attacked']\n",
    "\n",
    "casualties = ['mass murder', 'mass murderer', 'massacre', 'fatal', 'fatalities', 'fatality', 'casualties',\\\n",
    "              'casualty', 'body bag', 'body bagging', 'body bags', 'dead', 'death', 'deaths',  'tragedy']\n",
    "\n",
    "terrorism = ['terrorism', 'terrorist', 'threat', 'hijack', 'hijacker', 'hijacking', 'bioterror', 'bioterrorism']\n",
    "\n",
    "destruction = ['destroyed', 'destruction', 'devastated',\\\n",
    "               'devastation', 'disaster', 'annihilated', 'annihilation', 'apocalypse',\\\n",
    "               'armageddon', 'catastrophe', 'catastrophic', 'obliterate', 'obliterated',\\\n",
    "               'obliteration', 'damage', 'destroy', 'desolate', 'desolation', 'blight',\\\n",
    "               'harm', 'hazard', 'hazardous', 'danger', 'ruin', 'engulfed', 'rubble', 'debris',\\\n",
    "               'razed', 'flattened', 'crush', 'crushed']\n",
    "\n",
    "warlike = ['war zone', 'weapon', 'weapons', 'military', 'army', 'battle', 'outbreak', 'chemical emergency', 'curfew']\n",
    "\n",
    "starvation = ['famine', 'deluge', 'deluged']\n",
    "\n",
    "\n",
    "null = ['null']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "disasters = {'crash' : crash, 'emergency' : emergency, 'electricity': electricity,\\\n",
    "             'helpers': helpers, 'panic' : panic,  'hostages' : hostages, 'quarentine' : quarentine,\\\n",
    "             'colapse' : colapse, 'accident' : accident, 'fire' : fire,\\\n",
    "             'nuclear' : nuclear, 'explotion' : explotion, 'survivor' : survivor,\\\n",
    "             'wounded' : wounded, 'bomb' : bomb, 'storm' : storm,\\\n",
    "             'water' : water, 'natural_disaster' : natural_disaster, 'attack' : attack,\\\n",
    "             'casualties' : casualties, 'terrorism' : terrorism, 'destruction' : destruction,\\\n",
    "             'warlike' : warlike, 'starvation' : starvation, 'null' : null}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_categories = len(disasters)\n",
    "n_categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_maps = {}\n",
    "count = 0\n",
    "for k in disasters.keys():\n",
    "    numeric_maps[k] = count\n",
    "    count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping = {}\n",
    "for k, v in disasters.items():\n",
    "    for w in v:\n",
    "        mapping[w] = k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping_df = pd.DataFrame.from_dict(mapping, orient='index').reset_index()\n",
    "mapping_df.columns = ['keyword', 'group']\n",
    "numeric_maps_df = pd.DataFrame.from_dict(numeric_maps, orient='index').reset_index()\n",
    "numeric_maps_df.columns = ['group', 'id']\n",
    "to_encode = mapping_df.merge(numeric_maps_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>keyword</th>\n",
       "      <th>group</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>collide</td>\n",
       "      <td>crash</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>collided</td>\n",
       "      <td>crash</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>collision</td>\n",
       "      <td>crash</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>crash</td>\n",
       "      <td>crash</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>crashed</td>\n",
       "      <td>crash</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>217</th>\n",
       "      <td>curfew</td>\n",
       "      <td>warlike</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>218</th>\n",
       "      <td>famine</td>\n",
       "      <td>starvation</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>219</th>\n",
       "      <td>deluge</td>\n",
       "      <td>starvation</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>220</th>\n",
       "      <td>deluged</td>\n",
       "      <td>starvation</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221</th>\n",
       "      <td>null</td>\n",
       "      <td>null</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>222 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       keyword       group  id\n",
       "0      collide       crash   0\n",
       "1     collided       crash   0\n",
       "2    collision       crash   0\n",
       "3        crash       crash   0\n",
       "4      crashed       crash   0\n",
       "..         ...         ...  ..\n",
       "217     curfew     warlike  22\n",
       "218     famine  starvation  23\n",
       "219     deluge  starvation  23\n",
       "220    deluged  starvation  23\n",
       "221       null        null  24\n",
       "\n",
       "[222 rows x 3 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_encode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LabelBinarizer()"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelBinarizer\n",
    "\n",
    "lb = preprocessing.LabelBinarizer()\n",
    "lb.fit(range(0, n_categories))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
       "       17, 18, 19, 20, 21, 22, 23, 24])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lb.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_encode['encode'] = list(lb.transform(to_encode['id']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "expanded = to_encode.encode.apply(pd.Series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pd.concat([to_encode, expanded], axis=1, sort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.drop(columns=['encode', 'id'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>keyword</th>\n",
       "      <th>group</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>...</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>collide</td>\n",
       "      <td>crash</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>collided</td>\n",
       "      <td>crash</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>collision</td>\n",
       "      <td>crash</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>crash</td>\n",
       "      <td>crash</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>crashed</td>\n",
       "      <td>crash</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     keyword  group  0  1  2  3  4  5  6  7  ...  15  16  17  18  19  20  21  \\\n",
       "0    collide  crash  1  0  0  0  0  0  0  0  ...   0   0   0   0   0   0   0   \n",
       "1   collided  crash  1  0  0  0  0  0  0  0  ...   0   0   0   0   0   0   0   \n",
       "2  collision  crash  1  0  0  0  0  0  0  0  ...   0   0   0   0   0   0   0   \n",
       "3      crash  crash  1  0  0  0  0  0  0  0  ...   0   0   0   0   0   0   0   \n",
       "4    crashed  crash  1  0  0  0  0  0  0  0  ...   0   0   0   0   0   0   0   \n",
       "\n",
       "   22  23  24  \n",
       "0   0   0   0  \n",
       "1   0   0   0  \n",
       "2   0   0   0  \n",
       "3   0   0   0  \n",
       "4   0   0   0  \n",
       "\n",
       "[5 rows x 27 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "keyword_exp = tweets.loc[:, ['id', 'keyword']]\n",
    "keyword_exp_test = test.loc[:, ['id', 'keyword']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_train = keyword_exp.merge(result, left_on='keyword', right_on='keyword', how='left')\n",
    "merged_test = keyword_exp_test.merge(result, left_on='keyword', right_on='keyword', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_train.drop(columns=['keyword', 'group'], inplace=True)\n",
    "merged_test.drop(columns=['keyword', 'group'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run for file\n",
    "#merged_train.to_csv('keyword_mapping.csv', index=False)\n",
    "#merged_test.to_csv('keyword_mapping_test.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Location Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>location</th>\n",
       "      <th>address</th>\n",
       "      <th>point</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>glasgow</td>\n",
       "      <td>Glasgow, Glasgow City, Scotland, G2 9SA, Unite...</td>\n",
       "      <td>(55.8609825, -4.2488787, 0.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>melbourne, australia</td>\n",
       "      <td>City of Melbourne, Victoria, Australia</td>\n",
       "      <td>(-37.8142176, 144.9631608, 0.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>news</td>\n",
       "      <td>34375, Abbotsford Centre, Abbotsford, Fraser V...</td>\n",
       "      <td>(49.04172215, -122.27255349013137, 0.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>alberta</td>\n",
       "      <td>Alberta, Canada</td>\n",
       "      <td>(55.001251, -115.002136, 0.0)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 location                                            address  \\\n",
       "0                                                                        NaN   \n",
       "1                glasgow   Glasgow, Glasgow City, Scotland, G2 9SA, Unite...   \n",
       "2    melbourne, australia             City of Melbourne, Victoria, Australia   \n",
       "3                    news  34375, Abbotsford Centre, Abbotsford, Fraser V...   \n",
       "4                 alberta                                    Alberta, Canada   \n",
       "\n",
       "                                     point  \n",
       "0                                      NaN  \n",
       "1            (55.8609825, -4.2488787, 0.0)  \n",
       "2          (-37.8142176, 144.9631608, 0.0)  \n",
       "3  (49.04172215, -122.27255349013137, 0.0)  \n",
       "4            (55.001251, -115.002136, 0.0)  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "locations = pd.read_csv(\"../TP1/locations.csv\", usecols=['location', 'address', 'point'])\n",
    "locations.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>location</th>\n",
       "      <th>address</th>\n",
       "      <th>point</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>null</td>\n",
       "      <td>null</td>\n",
       "      <td>null</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>glasgow</td>\n",
       "      <td>Glasgow, Glasgow City, Scotland, G2 9SA, Unite...</td>\n",
       "      <td>(55.8609825, -4.2488787, 0.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>melbourne, australia</td>\n",
       "      <td>City of Melbourne, Victoria, Australia</td>\n",
       "      <td>(-37.8142176, 144.9631608, 0.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>news</td>\n",
       "      <td>34375, Abbotsford Centre, Abbotsford, Fraser V...</td>\n",
       "      <td>(49.04172215, -122.27255349013137, 0.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>alberta</td>\n",
       "      <td>Alberta, Canada</td>\n",
       "      <td>(55.001251, -115.002136, 0.0)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 location                                            address  \\\n",
       "0                    null                                               null   \n",
       "1                glasgow   Glasgow, Glasgow City, Scotland, G2 9SA, Unite...   \n",
       "2    melbourne, australia             City of Melbourne, Victoria, Australia   \n",
       "3                    news  34375, Abbotsford Centre, Abbotsford, Fraser V...   \n",
       "4                 alberta                                    Alberta, Canada   \n",
       "\n",
       "                                     point  \n",
       "0                                     null  \n",
       "1            (55.8609825, -4.2488787, 0.0)  \n",
       "2          (-37.8142176, 144.9631608, 0.0)  \n",
       "3  (49.04172215, -122.27255349013137, 0.0)  \n",
       "4            (55.001251, -115.002136, 0.0)  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "locations.fillna('null', inplace=True)\n",
    "empty_loc = locations.loc[0, 'location']\n",
    "locations.replace(empty_loc, 'null', inplace=True)\n",
    "locations.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Coordinates X,Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets['location'] = tweets['location'].fillna('null')\n",
    "test['location'] = test['location'].fillna('null')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def point_to_list(point):\n",
    "    if point == 'null':\n",
    "        return [300.0, 300.0] # Arbitrary large number \n",
    "    \n",
    "    coordinates = []\n",
    "    aux = point[:]\n",
    "    row = aux.strip( '()' ).split(',')\n",
    "    coordinates.append(float(row[0]))\n",
    "    coordinates.append(float(row[1]))\n",
    "    return coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "locations['point'] = locations.point.apply(point_to_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "aux = locations.point.apply(pd.Series)\n",
    "aux.columns = ['x', 'y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "locations['x'] = aux['x']\n",
    "locations['y'] = aux['y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>location</th>\n",
       "      <th>address</th>\n",
       "      <th>point</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>null</td>\n",
       "      <td>null</td>\n",
       "      <td>[300.0, 300.0]</td>\n",
       "      <td>300.000000</td>\n",
       "      <td>300.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>glasgow</td>\n",
       "      <td>Glasgow, Glasgow City, Scotland, G2 9SA, Unite...</td>\n",
       "      <td>[55.8609825, -4.2488787]</td>\n",
       "      <td>55.860982</td>\n",
       "      <td>-4.248879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>melbourne, australia</td>\n",
       "      <td>City of Melbourne, Victoria, Australia</td>\n",
       "      <td>[-37.8142176, 144.9631608]</td>\n",
       "      <td>-37.814218</td>\n",
       "      <td>144.963161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>news</td>\n",
       "      <td>34375, Abbotsford Centre, Abbotsford, Fraser V...</td>\n",
       "      <td>[49.04172215, -122.27255349013137]</td>\n",
       "      <td>49.041722</td>\n",
       "      <td>-122.272553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>alberta</td>\n",
       "      <td>Alberta, Canada</td>\n",
       "      <td>[55.001251, -115.002136]</td>\n",
       "      <td>55.001251</td>\n",
       "      <td>-115.002136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2266</th>\n",
       "      <td>zac newsome loves me</td>\n",
       "      <td>null</td>\n",
       "      <td>[300.0, 300.0]</td>\n",
       "      <td>300.000000</td>\n",
       "      <td>300.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2267</th>\n",
       "      <td>zeerust, south africa</td>\n",
       "      <td>Zeerust, Ngaka Modiri Molema District Municipa...</td>\n",
       "      <td>[-25.537731, 26.074382]</td>\n",
       "      <td>-25.537731</td>\n",
       "      <td>26.074382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2268</th>\n",
       "      <td>zero branco</td>\n",
       "      <td>Zero Branco, Treviso, Veneto, 31059, Italia</td>\n",
       "      <td>[45.601701, 12.165212]</td>\n",
       "      <td>45.601701</td>\n",
       "      <td>12.165212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2269</th>\n",
       "      <td>ziam af</td>\n",
       "      <td>null</td>\n",
       "      <td>[300.0, 300.0]</td>\n",
       "      <td>300.000000</td>\n",
       "      <td>300.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2270</th>\n",
       "      <td>zimbabwe</td>\n",
       "      <td>Zimbabwe</td>\n",
       "      <td>[-18.4554963, 29.7468414]</td>\n",
       "      <td>-18.455496</td>\n",
       "      <td>29.746841</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2271 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    location  \\\n",
       "0                       null   \n",
       "1                   glasgow    \n",
       "2       melbourne, australia   \n",
       "3                       news   \n",
       "4                    alberta   \n",
       "...                      ...   \n",
       "2266    zac newsome loves me   \n",
       "2267   zeerust, south africa   \n",
       "2268             zero branco   \n",
       "2269                ziam af    \n",
       "2270                zimbabwe   \n",
       "\n",
       "                                                address  \\\n",
       "0                                                  null   \n",
       "1     Glasgow, Glasgow City, Scotland, G2 9SA, Unite...   \n",
       "2                City of Melbourne, Victoria, Australia   \n",
       "3     34375, Abbotsford Centre, Abbotsford, Fraser V...   \n",
       "4                                       Alberta, Canada   \n",
       "...                                                 ...   \n",
       "2266                                               null   \n",
       "2267  Zeerust, Ngaka Modiri Molema District Municipa...   \n",
       "2268        Zero Branco, Treviso, Veneto, 31059, Italia   \n",
       "2269                                               null   \n",
       "2270                                           Zimbabwe   \n",
       "\n",
       "                                   point           x           y  \n",
       "0                         [300.0, 300.0]  300.000000  300.000000  \n",
       "1               [55.8609825, -4.2488787]   55.860982   -4.248879  \n",
       "2             [-37.8142176, 144.9631608]  -37.814218  144.963161  \n",
       "3     [49.04172215, -122.27255349013137]   49.041722 -122.272553  \n",
       "4               [55.001251, -115.002136]   55.001251 -115.002136  \n",
       "...                                  ...         ...         ...  \n",
       "2266                      [300.0, 300.0]  300.000000  300.000000  \n",
       "2267             [-25.537731, 26.074382]  -25.537731   26.074382  \n",
       "2268              [45.601701, 12.165212]   45.601701   12.165212  \n",
       "2269                      [300.0, 300.0]  300.000000  300.000000  \n",
       "2270           [-18.4554963, 29.7468414]  -18.455496   29.746841  \n",
       "\n",
       "[2271 rows x 5 columns]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets['location'] = tweets['location'].apply(str.lower)\n",
    "test['location'] = test['location'].apply(str.lower)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "coordinates_train = tweets.merge(locations.loc[:, ['location', 'x', 'y']], left_on='location', right_on='location', how='left').loc[:, ['id', 'x', 'y']]\n",
    "coordinates_test = test.merge(locations.loc[:, ['location', 'x', 'y']], left_on='location', right_on='location', how='left').loc[:, ['id', 'x', 'y']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run for file\n",
    "coordinates_train.to_csv('coordinates_train.csv', index=False)\n",
    "coordinates_test.to_csv('coordinates_test.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Vectors from words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>location</th>\n",
       "      <th>address</th>\n",
       "      <th>point</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>null</td>\n",
       "      <td>null</td>\n",
       "      <td>[300.0, 300.0]</td>\n",
       "      <td>300.000000</td>\n",
       "      <td>300.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>glasgow</td>\n",
       "      <td>Glasgow, Glasgow City, Scotland, G2 9SA, Unite...</td>\n",
       "      <td>[55.8609825, -4.2488787]</td>\n",
       "      <td>55.860982</td>\n",
       "      <td>-4.248879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>melbourne, australia</td>\n",
       "      <td>City of Melbourne, Victoria, Australia</td>\n",
       "      <td>[-37.8142176, 144.9631608]</td>\n",
       "      <td>-37.814218</td>\n",
       "      <td>144.963161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>news</td>\n",
       "      <td>34375, Abbotsford Centre, Abbotsford, Fraser V...</td>\n",
       "      <td>[49.04172215, -122.27255349013137]</td>\n",
       "      <td>49.041722</td>\n",
       "      <td>-122.272553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>alberta</td>\n",
       "      <td>Alberta, Canada</td>\n",
       "      <td>[55.001251, -115.002136]</td>\n",
       "      <td>55.001251</td>\n",
       "      <td>-115.002136</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 location                                            address  \\\n",
       "0                    null                                               null   \n",
       "1                glasgow   Glasgow, Glasgow City, Scotland, G2 9SA, Unite...   \n",
       "2    melbourne, australia             City of Melbourne, Victoria, Australia   \n",
       "3                    news  34375, Abbotsford Centre, Abbotsford, Fraser V...   \n",
       "4                 alberta                                    Alberta, Canada   \n",
       "\n",
       "                                point           x           y  \n",
       "0                      [300.0, 300.0]  300.000000  300.000000  \n",
       "1            [55.8609825, -4.2488787]   55.860982   -4.248879  \n",
       "2          [-37.8142176, 144.9631608]  -37.814218  144.963161  \n",
       "3  [49.04172215, -122.27255349013137]   49.041722 -122.272553  \n",
       "4            [55.001251, -115.002136]   55.001251 -115.002136  "
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "locations.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets['location'] = tweets['location'].fillna('null')\n",
    "test['location'] = test['location'].fillna('null')\n",
    "tweets['location'] = tweets['location'].str.replace(',','')\n",
    "test['location'] = test['location'].str.replace(',','')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "location_tokens = tweets.location.unique().tolist()\n",
    "location_test = test.location.unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "niall's place | saf 12 squad |\n",
      "live on webcam\n",
      "los angeles califnordia\n",
      "threeonefive. \n",
      "whoop ass georgia\n",
      "scarborough ontario\n",
      "121 n la salle st suite 500\n",
      "wandering\n",
      "homewood pa\n",
      "bexhill\n",
      "anime world\n",
      "cowtown caliii !!\n",
      "all motorways uk\n",
      "frankfurt germany\n",
      "gresham or\n",
      "las vegas \n",
      "midland mi\n",
      "sì£o vicente sì£o paulo\n",
      "vault 101 fallout\n",
      "davis ca\n",
      "in your hearts and minds\n",
      "runcorn\n",
      "lake charles la\n",
      "inland empire ca\n",
      "muscat\n",
      "usa - global online sales \n",
      "istanbul tì_rkiye\n",
      "high in prague with aya\n",
      "born on september 1st\n",
      "new orleans\n",
      "eileenborutwebster tx\n",
      "upstate ny\n",
      "salem ma\n",
      "high desert\n",
      "plovdiv bulgaria\n",
      "rhode island usa\n",
      "u.s.a.\n",
      "wayne nj\n",
      "wheelerwis.\n",
      "spring lake park mn\n",
      "dmz az\n",
      "instagram:marissatunis\n",
      "akron ohio \n",
      "currently somewhere on earth\n",
      "irvine ca\n",
      "somewhere in the internet...\n",
      "arlington\n",
      "1996???????????\n",
      "northwest\n",
      "phuket\n",
      "west covina ca\n",
      "#capulets #5sosfam #5quadfam \n",
      "bowling green ky\n",
      "logansport indiana\n",
      "rexburg id\n",
      "west michigan\n",
      "itunes radio [hiphop/rap]\n",
      "saginaw mich.\n",
      "lawrence ks\n",
      "duo lane\n",
      "reality based world\n",
      "3rd terrestrial planet sun\n",
      "nanaimo bc\n",
      "san luis obispo california\n",
      "chi town        \n",
      "indianapolis\n",
      "my own little world.\n",
      "twitter\n",
      "between here and there\n",
      "revolutionary road usa\n",
      "lucknow\n",
      "1937 germany \n",
      "n.y.c\n",
      "superior wi\n",
      "down down baby...sc.\n",
      "turin\n",
      "saint andrews scotland\n",
      "katong plaza #02-10\n",
      "valusia\n",
      "seraphim vault cosmodrone\n",
      "gislaved\n",
      "usa!\n",
      "south of boston\n",
      "baltimore \n",
      "east texas\n",
      "springfield tn\n",
      "jacksonville florida\n",
      "amsterdam nl or greenwich usa\n",
      "denverco usa\n",
      "the forbidden forest\n",
      "capitol hill washington\n",
      "fargo nd | north of normal \n",
      "philippines :)\n",
      "missoula mt\n",
      "strathmore california\n",
      "lithgow nsw australia\n",
      "north hollywood ca. (socal)\n",
      "newburgh ny\n",
      "new bedford ma\n",
      "paradise \n",
      "outer rim\n",
      "bkk\n",
      "zikko's hq\n",
      "crawley england\n",
      "on the net\n",
      "montrealqc\n",
      "dublinireland\n",
      "??????????? :p\n",
      "mass.\n",
      "sherbrooke & montrì©al\n",
      "northeast ohio\n",
      "outworld\n",
      "terre haute\n",
      "psalms 27:1\n",
      "slytherin /\n",
      "windy city land of the snakes\n",
      "35% gay. 65% water. \n",
      "oh.\n",
      "cucumber squad | she/her | \n",
      "8.27.14 & 7.28.15\n",
      "she/her \n",
      "texas forever \n",
      "coos bay or\n",
      "romans 1:16\n",
      "your girl's pussy\n",
      "twitch.tv/dgn_esports\n",
      "eldora ia\n",
      "bridgetown barbados\n",
      "stamford ct\n",
      "upper dicker england\n",
      "centre of attention\n",
      "highlands ranch co\n",
      "the other side of the mirror\n",
      "metro detroit\n",
      "sporting capital of the world\n",
      "mn |7-18-13|8-27-14|7-26-15|\n",
      "st. charles mo\n",
      "sunny florida\n",
      "that place\n",
      "qui tacet consentire videtur\n",
      "edwardsville il\n",
      "the land of pleasant living\n",
      "crescent moon w/ wook\n",
      "st marys oh\n",
      "305 but i'm so st. louis...\n",
      "williamsport pa\n",
      "quezon city national capital region\n",
      "xix | 5sos | ed sheeran |\n",
      "             waiheke island\n",
      "northampton\n",
      "earthrealm\n",
      "beacon hills ~ the glade\n",
      "ig: xbougiebri\n",
      "scout team \n",
      "? the foothills of sc ?\n",
      "somewhere or other\n",
      "toledo oh \n",
      "22714 ventura blvd. whills ca\n",
      "northern scandinavia\n",
      "salt lake city\n",
      "dalton\n",
      "rowlett tx\n",
      "bloemfontein free state\n",
      "don't stalk me- thanks\n",
      "north west\n",
      "on the island: nassau bahamas\n",
      "university fl\n",
      "harlem\n",
      "wolfgangmuzic@gmail.com\n",
      "o-town  the left end\n",
      "botswana gaborone\n",
      "dirty bay ca\n",
      "broward miami tally\n",
      "10 hours from pluto\n",
      "west monroe louisiana\n",
      "cleveland\n",
      "yemen\n",
      "alexandria va \n",
      "nyc ?? van\n",
      "n 51å¡25' 0'' / w 0å¡45' 0''\n",
      "tinley park il\n",
      "long beach dublin amsterdam\n",
      "vi~d[m]v\n",
      "shibuya tokyo japan\n",
      "ventura county\n",
      "jaipur rajasthan\n",
      "#uniteblue\n",
      "vernal utah\n",
      " birmingham.\n",
      "jon bellion | luke christopher\n",
      "these united states\n",
      "tokyo japan\n",
      "south east asia\n",
      "kill devil hills\n",
      "derbyshire england\n",
      "somewhere on the earth\n",
      "saint-petersburg\n",
      "new york city & mpls/st. paul\n",
      "minneapolis st. paul minnesota\n",
      "liverpool england\n",
      "las baegas\n",
      "sunshine coast of bc\n",
      "cin city\n",
      "us of eh\n",
      "mighty tempe arizona\n",
      "ig: 94fijiwater\n",
      "?arsehole squad?\n",
      "wherever the music takes me \n",
      "fallen tx\n",
      "????????? ?????-?????????\n",
      "ìït: 41.373061-71.942237\n",
      "taiz - yemen\n",
      "new hampshire û¢ wmur \n",
      "yorkshire and london\n",
      "kalispell montana\n",
      "557619\n",
      "dallas texas\n",
      "poyth wesssterrrnnoystrayahhh\n",
      "ecruteak city johto\n",
      "ann arbor mi\n",
      "north bellmore ny\n",
      "hutchinson mn\n",
      "who fuckin knows\n",
      "nyc ?? pa\n",
      "pasadena ca\n",
      "conover nc\n",
      "los angeles/ las vegas/ boston\n",
      "gateway regional hs\n",
      "daily ? 18 ? ?\n",
      "tìáchira venezuela\n",
      "faisalabad\n",
      "austin texas ontario canada\n",
      "epic city bb.\n",
      "sw london (rbk)\n",
      "san diegohhjhhhhhghghpjg\n",
      "squ\\/d uk\n",
      "$$$\n",
      ";)\n",
      "ellixton london's 33rd borough\n",
      "ngayogyakarta hadiningrat \n",
      "san francisco los angeles\n",
      "arizona usa\n",
      "canada | #lux\n",
      "among the socially awkward ?\n",
      "west hampstead london nw6\n",
      "paranaque city national capital region\n",
      "toronto  #6ixsidemafia\n",
      "jonas/lovato/bieber/5sos\n",
      "carrboro nc\n",
      "#bvstrong\n",
      "blackfield england\n",
      "cape coral fl\n",
      "leanbox?\n",
      "mechanicsville va\n",
      "edmonton\n",
      "www.facebook.com/randirobics\n",
      "? in your head ?\n",
      "hyejeong?taehyung\n",
      "emirate\n",
      "twin cities mn\n",
      "kampala uganda\n",
      "narbin city  \n",
      "leeds england united kingdom\n",
      "burger king with usher\n",
      "greece\n",
      "batam\n",
      "cramerton nc\n",
      "san antone\n",
      "(queer trans he/him black)\n",
      "eugene or.\n",
      "everywhere usa\n",
      "tampa bay\n",
      "sending rude things to heather\n",
      "conway ar\n",
      "ham ham clubhouse\n",
      "luisa's heart\n",
      "lehigh acres fl\n",
      "#izzoworld\n",
      "capital federal argentina\n",
      "inequity  is  injustice || nj\n",
      "wellington fl\n",
      "parkway ca\n",
      "ppcc \n",
      "the open road!\n",
      "the new way to surf!\n",
      "ponyvilleequestria \n",
      "highway to hell\n",
      "indian trail north carolina\n",
      "kentucky\n",
      "pleasantville ny\n",
      "arlington va (dc area)\n",
      "swat pakistan\n",
      "edinburgh/ west yorkshire\n",
      "?illinois?\n",
      "dreamville | hoolagan\n",
      "mnl philippines\n",
      "lawn pa\n",
      "nopa san francisco\n",
      "war drobe spare oom\n",
      "motown wv\n",
      "fredericton nb\n",
      "downriver.\n",
      "ottawa on canada\n",
      "house of el\n",
      "piscataway nj\n",
      "fl/nj\n",
      "hodesto cuntlifornia\n",
      "jammu kashmir \n",
      "lufkin.texasusa\n",
      "mississauga\n",
      "ohio land of no sun\n",
      "nor cal\n",
      "770 to benedict college \n",
      "isabel beatriz paras de leon\n",
      "waraq\n",
      "winchester uk\n",
      "comox valley courtenay bc  \n",
      "sittwe\n",
      "seoul republic of korea\n",
      "vineland nj usa\n",
      "mansfield ohio\n",
      "downtown new york\n",
      "toronto ontario canada\n",
      "queens\n",
      "bgsu\n",
      "buzz city \n",
      "in outer space\n",
      "trujillo peru\n",
      "huntington beach ca\n",
      "leeds \n",
      "n 32å¡39' 0'' / w 97å¡16' 0''\n",
      "brinscall england\n",
      "it was yesterday :(\n",
      "monaghan ireland\n",
      "dancer - peter pan panto 2015 \n",
      "my world\n",
      "65 skelmersdale lane\n",
      "wolverhampton low hill\n",
      "bristol \n",
      "colwyn bay wales\n",
      "death city nevada\n",
      "manchesterengland\n",
      "in my baby with pie\n",
      "ico arkansas\n",
      "prague cz the planet of fans\n",
      "uae\n",
      "georgetownguyana\n",
      "elko nevada\n",
      "rochester minnesota\n",
      "eastbourne east sussex \n",
      "uk.\n",
      "calabasas ca\n",
      "montana\n",
      "south wairarapa/wellington \n",
      "hartford ct\n",
      "west powelton philadelphia\n",
      "republic of harper \n",
      "aragua\n",
      "'schland\n",
      "venice sweden\n",
      "camberville (bostonish)\n",
      "nr great missenden bucks\n",
      "southend-on-sea england\n",
      "garland texas\n",
      "your backyard\n",
      "htx innerverse\n",
      "pridelands in\n",
      "connecticut usa\n",
      "ankeny\n",
      "hiding in a cardboard box.\n",
      "melbourne vic australia\n",
      "bolton england\n",
      "to your chosen destination\n",
      "carthage oh\n",
      "cyberspace\n",
      "wherever the #sooners are\n",
      "cheltenham\n",
      "w/ @_ridabot probably\n",
      "accrington lancashire\n",
      "washington dc and on planes\n",
      "dc & moco\n",
      "district of columbia usa\n",
      "pg\n",
      "waterloo ontario canada\n",
      "woodbridge va \n",
      "/ kattappana kerala \n",
      "twin falls idaho 83301\n",
      "michigander usa\n",
      "from harlem to duke ! \n",
      "cardiff/london/nyc/warwick\n",
      "outreach africa\n",
      "usawashingtonseattle\n",
      "lanì¼s\n",
      "quezon city\n",
      "#global\n",
      "phoenix az \n",
      "between manchester and lille.\n",
      "globetrotter\n",
      "raleigh\n",
      "curitiba-pr\n",
      "|elsmere| wilmington de.\n",
      "at grandmother willow's\n",
      "festaclagosnigeria\n",
      "cape town south africa\n",
      "@argentinaliars ?| willbradley\n",
      "dunedin new zealand\n",
      "norton \n",
      "l.a\n",
      "north korea\n",
      "hounslow london\n",
      "lake worth fl\n",
      "the floor\n",
      "piedmont ca\n",
      "the interwebs!\n",
      "nashville music city usa\n",
      "amsterdam worldwide\n",
      "detroit mi \n",
      "texas hill country\n",
      "morioh japan\n",
      "d.c.\n",
      " aomori\n",
      "boulder via dc\n",
      "palacio madrid\n",
      "shlomotion\n",
      "poughkeepsie ny\n",
      "please follow and rt! :)\n",
      "dam squad 4 lyf\n",
      "astral plane\n",
      "south wales valleys\n",
      "toronto û¢ unicorn island \n",
      "wherever wolf blitzer is\n",
      "polska\n",
      "fort worth tx\n",
      "espaì±a/catalunya/girona\n",
      "greer sc\n",
      "kansas usa\n",
      "ottawa\n",
      "crying\n",
      "uitm shah alam\n",
      "nyc/li/nj/lhv\n",
      "pedophile hunting ground\n",
      "magodo\n",
      "beaumont texas\n",
      "cary north carolina\n",
      "san gabriel valley ca\n",
      "windsor ??ct \n",
      "portugal-spain-indonesia\n",
      "hustle flow nation\n",
      "rock hill  sc \n",
      "#name?\n",
      "under ya skin\n",
      "land-where-everything-sucks\n",
      "england uk\n",
      "my own little corner\n",
      "3-jan\n",
      "east coast \n",
      "manhattan new york\n",
      "east carolina university'19 ??\n",
      "bogotìá colombia\n",
      "chillin\n",
      "id where potatoes grow\n",
      "fema region 2\n",
      "almonds\n",
      "ex astris scientia. tssadid.\n",
      "johnstown ny\n",
      "doo doo boy island\n",
      "real world\n",
      "130515 û¢ gallavich.\n",
      "bangaloreindia\n",
      "pico rivera ca\n",
      "playing: hl2: ep1 dust: aet\n",
      "mtl\n",
      "east la mirada ca\n",
      "jeddah makkah al mukarrama\n",
      "do not follow me am i a bot.\n",
      "bay area california \n",
      "rocky mountains colorado\n",
      "san bernardo - chile\n",
      "duel academia\n",
      "   manchester/nantwich\n",
      "under the rain...\n",
      "clearlake\n",
      "twitter.\n",
      "beyond time and space\n",
      "jds \n",
      "milan lombardy\n",
      "metro lampung ~ balikpapan\n",
      "bieber fever uk\n",
      "32935\n",
      "301|804\n",
      "gap\n",
      "stone ridge va\n",
      "staffordshire\n",
      "central #ohio\n",
      "hayling \n",
      "mullingar ireland\n",
      "nap town\n",
      "south park  ??????????????????\n",
      "isle of patmos\n",
      "modesto ca\n",
      "ton's ì¡ead town åè tx\n",
      "ocsf\n",
      "paonia colorado\n",
      "tampa florida\n",
      "the great white north\n",
      "fishkill ny\n",
      "in erotic world \n",
      "lismore new south wales\n",
      "sunny south africa\n",
      "greenwich london\n",
      "lansing mi usa\n",
      "#viewsaremyown #ibacktheblue\n",
      "antioch ca\n",
      "issaquah wa\n",
      "bodmin cornwall\n",
      "hagerstown md 21742\n",
      "?? | pittsburgh \n",
      "berkeley ca 94703 usa ? \n",
      "west baltimore \n",
      "hollywood california\n",
      "sydney - australia\n",
      "az ? tx ? ca ? il ?\n",
      "kurdistan \n",
      "foothills\n",
      "she/her? û¢ tr û¢ jordan\n",
      "oregon & sw washington\n",
      "seattle/snohomish/redlands\n",
      "grand rapids mich.\n",
      "state of jefferson\n",
      "auckland nz\n",
      "chicagoland and the world!\n",
      "everywhere.. \n",
      "on canada\n",
      "west palm beach fl\n",
      "the dalles oregon\n",
      "edmonton alberta canada\n",
      "pea ridge wv\n",
      "sam\n",
      "~always in motion~\n",
      "redding \n",
      "concord north carolina\n",
      "alexander iowa\n",
      "ìït: 39.168519-119.766123\n",
      "ittihad .f.c\n",
      "canaduh\n",
      "ìth cliath ìäire\n",
      "my house probably\n",
      "lost angeles lol\n",
      "youtube channel\n",
      "free palestine | save gaza\n",
      "land of the free\n",
      "be earth\n",
      "west virginia\n",
      "hudson valleyny\n",
      "blog\n",
      "punjab pakistan\n",
      "kyiv (kiev) ukraine (???? ???? ???????)\n",
      "somewhere in time\n",
      "dublin ireland. \n",
      "kyiv. ukraine\n",
      "cincinnati\n",
      "gurgaon\n",
      "nj amerikkka\n",
      "baroda\n",
      "greenville sc\n",
      "vh1 soul in a bet world \n",
      "sericita minas gerais\n",
      "bobba island \n",
      "mainer missing guatemala\n",
      "planet earth (mainly) #neuland\n",
      "amosquebeccanada\n",
      "??????????\n",
      "windsor on canada\n",
      "garbage disposal bc im trash\n",
      "sherman ave south bronx #stf\n",
      "free hanseatic city of bremen germany\n",
      "a pool of my own tears\n",
      "san jose state university \n",
      "outerspace\n",
      "sea of green\n",
      "san antonio\n",
      "lakeland fl\n",
      "wonderland\n",
      "tulsa\n",
      "lampe mo\n",
      "fredericksburg va\n",
      "indianapolis indiana\n",
      "columbia mo\n",
      "stuck in traffic\n",
      "serving oklahoma\n",
      "from boston for new england\n",
      "goldsboro nc\n",
      "nevada\n",
      "hull ma\n",
      "cedar city utah\n",
      "live from the low end\n",
      "little rock\n",
      "bestatriz û¢29/4 û¢ #askdemigod \n",
      "fargo nd\n",
      "here there & everywhere..\n",
      "support all girls!\n",
      "swansea\n",
      "derbyshire\n",
      "hawkes bay new zealand\n",
      "salford greater manchester\n",
      "whitley bay england\n",
      "worldwalking\n",
      "hermiston oregon\n",
      "desloge mo\n",
      "yakima wa\n",
      "36702 state road 52 dade city\n",
      "miami - support navy #seals \n",
      "montana misery\n",
      " elizabeth nj\n",
      "guayaquil ecuador\n",
      "brooksville florida\n",
      "forest grove or\n",
      "babylon up-on hudson\n",
      "west coast \n",
      "muskegon mi\n",
      "panama city beach florida\n",
      "kruibeke belgiìç\n",
      "sales specialist~ worldwide  \n",
      "stgo chile\n",
      "qwuank\n",
      "townsville\n",
      "ontario ca\n",
      "british columbia\n",
      "st louis\n",
      "rapid city & the black hills\n",
      "bending the elements.\n",
      "north east america\n",
      "sudbury\n",
      "calgary \n",
      "golden british columbia canada\n",
      "calgary and usa\n",
      "blue nation naija\n",
      "hamptonroads virginia\n",
      "karma \n",
      "mystic falls\n",
      "oro valley az\n",
      "android land\n",
      "dark night. ???? ??\n",
      "el cerrito ca\n",
      "sunderland/the saaf\n",
      "mobile al\n",
      "minnesota\n",
      "yellowknife nt canada\n",
      "for a healthier happier you!\n",
      "vb/norfolkva\n",
      "rahway nj\n",
      "stockport uk\n",
      "deerfield beach florida\n",
      "milan italy\n",
      "chibavery close to tokyo.\n",
      "beal feirste northern ireland\n",
      "out and about \n",
      "in my head.....\n",
      "delta nigeria\n",
      "uk & oversees\n",
      "???/??\n",
      "????? ?? ?????? -????? ????\n",
      "#hdynation\n",
      "saint petersburg fl\n",
      "over the hills and far away\n",
      "roermond\n",
      "amman\n",
      "california central valley\n",
      "the court of public opinion.\n",
      "chinade nigeria\n",
      "http://wingssilverwork.com\n",
      "darwins au \n",
      "moncton nb\n",
      " way way way up ??\n",
      "limerick ireland.\n",
      "long island new york\n",
      "lahore pakistan\n",
      "niels groeneveld / redsocks\n",
      "behavioral analysis unit (bau)\n",
      " cairo\n",
      "brentwood uk\n",
      "hubli karnataka\n",
      "my usa åµ???? ?aìù? \n",
      "melbs 1/2 #rham\n",
      "astoria ny\n",
      "tuscumbia al\n",
      "ms\n",
      "tacompton washington \n",
      "south africa braamfontein\n",
      "the north coast\n",
      "united states ohio\n",
      "nj ?? az \n",
      "richmond va usa\n",
      "| india |\n",
      "pune\n",
      "chapel hill cary n.c.\n",
      "glendale az\n",
      "covering the u.s.a.\n",
      "fantasy land\n",
      "kibworth beauchamp england\n",
      "3/12 + jake miller\n",
      "www.dorsavi.com\n",
      "all round the world\n",
      "bellingham wa\n",
      "searching for rivendell\n",
      "shrewsbury england\n",
      "groìùdeutsches reich\n",
      "beijingchina\n",
      "release the reis  \n",
      "that london\n",
      "#roshanpakistan\n",
      "wickford\n",
      "central new jersey\n",
      "shangri-la\n",
      "morgantown wv\n",
      "upper st. clair\n",
      "trinity nc\n",
      "budgam kashmir\n",
      "somewhere over the rainbow\n",
      "northwest arkansas\n",
      "staten island ny\n",
      "nwa & river valley\n",
      "winston salem nc\n",
      "nashville tenn.\n",
      "in your dreams\n",
      "santa cruz \n",
      "raleigh north carolina usa\n",
      "the three broomsticks \n",
      "17 year old anti-theist.\n",
      "albany western australia\n",
      "the real world\n",
      "islamabad pakistan\n",
      "pedophilia\n",
      "reaching for the stars \n",
      "still on my laptop\n",
      "fukushima japan\n",
      "los angeles via pittsburgh\n",
      "university of maryland\n",
      "santos sì£o paulo\n",
      "house of the rising sun\n",
      "@keytnc3 @kcoy\n",
      "wales cymru\n",
      "perth scotland\n",
      "sweizyland\n",
      "ohio...yep we said it.\n",
      "dili. east timor\n",
      "the woodlands tx\n",
      "central jersey\n",
      "boston/ny/montreal/london\n",
      "iowa\n",
      "wouldn't u like to know\n",
      "north vernon in\n",
      "manisto trap house \n",
      "st. catherine jamaica w.i.\n",
      "tuksa ok\n",
      "fl.co.hi.nj\n",
      "princetonave\n",
      "west coast canada\n",
      "syracuse ny\n",
      "boca raton fl\n",
      "merseyside\n",
      "kocaeli-izmit\n",
      "laporte in\n",
      "tarn et garonne/lot et garonne\n",
      "1/11 numberjacks squad\n",
      "sandbach cheshire uk \n",
      "ìït: 58.193556-5.334943\n",
      "st albans\n",
      "california most of the time\n",
      "nepal\n",
      "bishop amat\n",
      "canberra (mostly)\n",
      "u.a.e.\n",
      "modishthaan\n",
      "washington dc area\n",
      "interwebs\n",
      "thessaloniki greece\n",
      "almost there \n",
      "japan \n",
      " stah-koomi-tapii-akii\n",
      "brussels\n",
      "tokio / tokyo\n",
      "haifa israel\n",
      "washington dc region\n",
      "head of the family\n",
      "lemon grove ca\n",
      "orlando fl \n",
      "cape coral fl usa\n",
      "denver|boulder|ft. collins co\n",
      "trashcan somewhere in hell\n",
      " ? they/them ?\n",
      "bucks\n",
      "rhyming\n",
      "nanda parbat\n",
      "mia\n",
      "lastlevelpress.com\n",
      "metropolis tx\n",
      "uchiha\n",
      "nigeriawest african\n",
      "the best side of middlesbrough\n",
      "port townsend wa\n",
      "u.s.a. \n",
      "knoxville tn usa\n",
      "virginia (usa)\n",
      "utopia \n",
      "arlington\n",
      "\n",
      "dallas\n",
      "lagosnigeria\n",
      "lnd greatest city in the world\n",
      "loreto college mullingar\n",
      "jabalpur\n",
      "nigeria|| lagos\n",
      "sad\n",
      "st. louie\n",
      "louisiana the real la\n",
      "they/them or she/her\n",
      "north devon uk \n",
      "italia\n",
      "omaha neblastya\n",
      "home is wherever i am \n",
      "9.25.14?8.5.15?10.6.15 | gen?\n",
      "bedford\n",
      "wolverhampton \n",
      "philadelphia & worldwide\n",
      "uganda l africa l worldwide. \n",
      "colorado the mile high city\n",
      "2014.02.14~ing\n",
      "milano\n",
      "johnson county kansas\n",
      "#bitcoinland\n",
      "mumbai  india\n",
      "ìït: 41.106046-80.657836\n",
      "springfield mo\n",
      "someplace safe\n",
      "pretoria south africa\n",
      "?x??p = ?/2\n",
      "morganton ga\n",
      "salem or\n",
      "nipple squad makes me happy\n",
      "secane pa\n",
      "keffi\n",
      "kent united kingdom\n",
      "banner elk nc\n",
      "south east florida\n",
      "harare\n",
      "kaneville\n",
      "try looking at the map?\n",
      "digitosphere\n",
      "university of alabama\n",
      "kansas  ks\n",
      "toulouse haute-garonne france\n",
      "hannover\n",
      "shellharbour wollongong\n",
      "lbtidronegirlshell \n",
      "europa\n",
      "chillicothe oh\n",
      "lexington ky\n",
      " kaijo high school\n",
      "summerside\n",
      "niger state\n",
      "burnley lancashire\n",
      "pembroke dock wales\n",
      "bath england\n",
      "ìït: 50.953278-113.978785\n",
      "rome it\n",
      "los angeles ca 90045\n",
      "orange county california \n",
      "9 benua ltd.\n",
      "ìït: 7.3845593.8793718\n",
      "manadosulawesi utara\n",
      "wakefield england\n",
      "#sundaunited\n",
      "go bucks!\n",
      "cali\n",
      "tri-state\n",
      "#dcjacobin\n",
      "davis\n",
      "å©hicago\n",
      "portland\n",
      "uberlì¢ndia - mg - brasil\n",
      "diantara temlen laksani\n",
      "huston texas 1-844-360-wise\n",
      "west coast\n",
      "management multimedia\n",
      "globally 1-844-360-wise\n",
      "55 wall street\n",
      "teen top ? jongsuk ? exo ? bts\n",
      "in ma daddy nd mummy's. hart..\n",
      "albequerque\n",
      "monroe oh\n",
      "bang bang bang\n",
      "west midlands england\n",
      "warning: i tweet nsfw and nsfl\n",
      "quantico\n",
      "hollandmi\n",
      "fairly local\n",
      "started acc 1.9.15 2:25 pm\n",
      "she/her û¢ 19 û¢ poland\n",
      "rice lake wi/toronto on\n",
      "trust none..\n",
      "atlanta ga (kind of)\n",
      "ireland \n",
      "with my music and air heads\n",
      "honeymoon tour 03.26.15?\n",
      "hype ressha hype ressha\n",
      "trapin'\n",
      "moon \n",
      "#allblacklivesmatter\n",
      "north druid hills ga\n",
      "stars/pens/caps/hawks\n",
      "in a multi-fandom\n",
      "malta; gozo\n",
      "kanto japan\n",
      "mombasa\n",
      "university of oklahoma\n",
      "georgia/florida  \n",
      "london / herts\n",
      "maryland/myrtle beach ccu'19\n",
      "#teamhkngang \n",
      "palm spraangs\n",
      "berisso argentina\n",
      "texas united states\n",
      "62\n",
      "atrapada en el mundo.\n",
      "probably bargos\n",
      "moreno city - buenos aires\n",
      "salem oregon\n",
      "franklinton - br - houston\n",
      "roseland\n",
      "barnsley\n",
      "il?mi\n",
      "your mom\n",
      " \n",
      "bliss\n",
      "@rejxctedmgc is my harry?\n",
      "ig: j.nessaa\n",
      "nj usa\n",
      "the land of make believe\n",
      "saint john n.b canada \n",
      "northeast united states \n",
      "new england ????\n",
      "florence sc\n",
      "sunmy melbourne england\n",
      "424 n. fairfax ave. 90036\n",
      "fairbanks alaska\n",
      "where is my mind?\n",
      "north coast of o-h-i-o\n",
      "oman \n",
      "blf (mp)/ pta (gp)/ phb(limps)\n",
      "bedford stuyvesant brooklyn\n",
      "sp - brasil #1\n",
      "lakerland\n",
      "utica  new york (upstate) \n",
      "washington dc an airport \n",
      "st.louis\n",
      "stone mountain ga\n",
      "virginia beach va usa\n",
      "burbank ca\n",
      "fano (italy)\n",
      "swaggdad irock\n",
      "lagos  usa\n",
      "seek for light today!!!\n",
      "london/lagos\n",
      "yesnaija.com\n",
      "netherverse\n",
      "vienna austria europe\n",
      "sussex uk\n",
      "{daughter of ares} {eighteen}\n",
      "tweets by david \n",
      "vine: woah stelena \n",
      "  ?becky?chloe?\n",
      "st. catharines\n",
      "sarah's dreads\n",
      "kearney (area) nebraska\n",
      "???û¢???û¢s??û¢????û¢????????s\n",
      "m a a l k \n",
      "6/24/12 7/21/13 8/22/14 7/17/15\n",
      "portsmouth \n",
      "behind them oranges\n",
      "london. \n",
      "paddington london\n",
      "uncanny valley\n",
      "gornal - england\n",
      "eugene or\n",
      "keeper of the triforce \n",
      "cardiff\n",
      "carlow ireland\n",
      "bangkok thailand.\n",
      "sdf-1 macross s. ataria island\n",
      "santibaì±ez de vidriales zamora\n",
      "temple ga\n",
      "last legs new zealand\n",
      "greater boston area\n",
      "udaipur\n",
      "                           fla\n",
      "citizen of the world\n",
      "(socal)\n",
      "kurnool\n",
      "tampa bay. fire the cannons\n",
      "lagos nigeria.\n",
      "patna\n",
      "bharat.\n",
      "portland oregon usa\n",
      "phx az\n",
      "@kiarakardashhh | fayetteville\n",
      "michigan ?? south carolina\n",
      "journey \n",
      "ny || ga\n",
      "red deer alberta canada\n",
      "okc\n",
      "lake hefner bike trail\n",
      "cambridge \n",
      "finland \n",
      "florence south carolina\n",
      "336\n",
      "ìït: 35.353272-78.553744\n",
      "mumbai india.\n",
      "any town usa\n",
      "riverwest milw \n",
      "bucky barnes hell\n",
      "sì©te france (foto c.1968)\n",
      "berkeley ca\n",
      "sheeps clothing\n",
      "jefferson ga\n",
      "namma bengaluru\n",
      "instagram- joeyparmenterr\n",
      "ur baq\n",
      "a glass case of emotions\n",
      "n.e.ohio\n",
      "austintx\n",
      "brooklyn ny and norfolk va\n",
      "s.p.brasil\n",
      "53.337853-6.288693\n",
      "makoharu hell\n",
      "time for non violent dissent! \n",
      "halifax nova scotia canada\n",
      "bideford england\n",
      "unauthentically british uk\n",
      "free and democratic britain\n",
      "southeast michigan (hoth)\n",
      "city of bacoor calabarzon phl\n",
      "seattie\n",
      "lawrence ma\n",
      "lansing ?? ypsilanti \n",
      "kansas \n",
      "rest easy angel @datboiiharri.\n",
      "siuc | 618\n",
      "okinawa\n",
      "http://t.co/moy6lmu\n",
      "quezon philippines\n",
      "boca raton\n",
      "flat rock\n",
      "bengaluru india\n",
      "id\n",
      "bhubaneswar\n",
      "no\n",
      "andhra pradesh india\n",
      "surrey bc\n",
      "bentonville arkansas\n",
      "philadelphia; world war i\n",
      "shanatic/ggian/srkian\n",
      "harvard square cambridge ma\n",
      "greater vancouver british columbia\n",
      "herbville\n",
      "richmond va & bristow va\n",
      "algonquin il\n",
      "worcester\n",
      "sawangan 1 central java\n",
      "baker louisiana\n",
      "enemy of the state \n",
      "baltimore maryland\n",
      "wellington city new zealand\n",
      "mds af ?\n",
      "canton ohio\n",
      "in range \n",
      "sky's the limit (b.i.g) ????\n",
      "monroela\n",
      "pnw\n",
      "????????\n",
      "pune maharashtra india\n",
      "?orth sg. \n",
      "garrus?\n",
      "sheffield.?\n",
      "northwest jersey\n",
      "yyc\n",
      "north tonawanda ny\n",
      "where e'er the mood takes me\n",
      "montana/north carolina\n",
      "frm jerz living in dade county\n",
      "brantford ontario\n",
      "tucson arizona\n",
      "west virginia \n",
      "408 n. western wenatchee wa \n",
      "28.709672-97.376514\n",
      "pasadena tx\n",
      "?? newport  ri ??\n",
      "chicago illinois  \n",
      "mii facebook\n",
      "southern cali\n",
      "626 - 702\n",
      "gauteng heidelbergratanda\n",
      "back of the beyond lesotho\n",
      "clt via nola via mo via mn\n",
      "the beautiful northwest (usa)\n",
      "washington d.c. / istanbul\n",
      "vancouver \n",
      "k-town \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#kashmir\n",
      "sam's town\n",
      "probably in hell \n",
      "st. petersburg. fla.\n",
      "inwood ontario\n",
      "would rather be in my room\n",
      "philippians 4:13\n",
      "our galaxy\n",
      "sunny southern california\n",
      "plymouth england\n",
      "deep in the heart of libland\n",
      "canadaontario\n",
      "love reiss\n",
      "acey mountain islanddåçtorontoåè\n",
      "brussels belgium\n"
     ]
    }
   ],
   "source": [
    "for k in location_test:\n",
    "    if k not in location_tokens:\n",
    "        print(k) # Mismas palabras en ambos sets, jaja no."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 400001 word vectors.\n"
     ]
    }
   ],
   "source": [
    "embeddings_index = dict()\n",
    "f = open('glove.6B.100d.txt', encoding='utf8') # Vectores entrenados de 100 dimensiones\n",
    "for line in f:\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    coefs = np.asarray(values[1:], dtype='float32')\n",
    "    embeddings_index[word] = coefs\n",
    "f.close()\n",
    "print('Loaded %s word vectors.' % len(embeddings_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectors = {}\n",
    "for location in location_tokens:\n",
    "    words = location.split(' ')\n",
    "    n = len(words)\n",
    "    try:\n",
    "        if n == 1:\n",
    "            vectors[location] = embeddings_index[location]\n",
    "        else:\n",
    "            acum = np.zeros(100)\n",
    "            for w in words:\n",
    "                acum = np.sum([acum,embeddings_index[w]] , axis=0)\n",
    "    except KeyError:\n",
    "        continue\n",
    "        vectors[location] = acum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>...</th>\n",
       "      <th>90</th>\n",
       "      <th>91</th>\n",
       "      <th>92</th>\n",
       "      <th>93</th>\n",
       "      <th>94</th>\n",
       "      <th>95</th>\n",
       "      <th>96</th>\n",
       "      <th>97</th>\n",
       "      <th>98</th>\n",
       "      <th>99</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>null</td>\n",
       "      <td>0.079432</td>\n",
       "      <td>-0.14054</td>\n",
       "      <td>-0.10462</td>\n",
       "      <td>-0.36259</td>\n",
       "      <td>-0.227210</td>\n",
       "      <td>-0.13612</td>\n",
       "      <td>0.74755</td>\n",
       "      <td>0.32809</td>\n",
       "      <td>0.54364</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.21230</td>\n",
       "      <td>0.515730</td>\n",
       "      <td>0.16573</td>\n",
       "      <td>0.67943</td>\n",
       "      <td>0.353270</td>\n",
       "      <td>0.176720</td>\n",
       "      <td>0.25803</td>\n",
       "      <td>0.068445</td>\n",
       "      <td>-1.20160</td>\n",
       "      <td>-0.20168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>birmingham</td>\n",
       "      <td>0.473340</td>\n",
       "      <td>0.28810</td>\n",
       "      <td>-0.40206</td>\n",
       "      <td>-0.76942</td>\n",
       "      <td>0.505650</td>\n",
       "      <td>0.56655</td>\n",
       "      <td>0.15756</td>\n",
       "      <td>0.28222</td>\n",
       "      <td>-0.63076</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.45335</td>\n",
       "      <td>-0.588940</td>\n",
       "      <td>0.10209</td>\n",
       "      <td>1.43720</td>\n",
       "      <td>-0.396420</td>\n",
       "      <td>0.050214</td>\n",
       "      <td>0.57303</td>\n",
       "      <td>0.742570</td>\n",
       "      <td>0.65308</td>\n",
       "      <td>-0.56826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>africa</td>\n",
       "      <td>-0.286410</td>\n",
       "      <td>0.84050</td>\n",
       "      <td>1.11780</td>\n",
       "      <td>0.18766</td>\n",
       "      <td>0.073111</td>\n",
       "      <td>-0.24262</td>\n",
       "      <td>0.12002</td>\n",
       "      <td>0.90520</td>\n",
       "      <td>-0.77801</td>\n",
       "      <td>...</td>\n",
       "      <td>0.18550</td>\n",
       "      <td>-0.019433</td>\n",
       "      <td>0.64313</td>\n",
       "      <td>-0.22149</td>\n",
       "      <td>-0.372510</td>\n",
       "      <td>0.586410</td>\n",
       "      <td>-0.80282</td>\n",
       "      <td>-0.227080</td>\n",
       "      <td>0.29665</td>\n",
       "      <td>0.20128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>pretoria</td>\n",
       "      <td>-0.100460</td>\n",
       "      <td>-0.44136</td>\n",
       "      <td>0.66512</td>\n",
       "      <td>0.27777</td>\n",
       "      <td>-0.599210</td>\n",
       "      <td>0.29228</td>\n",
       "      <td>0.18710</td>\n",
       "      <td>1.24120</td>\n",
       "      <td>-0.70815</td>\n",
       "      <td>...</td>\n",
       "      <td>0.51562</td>\n",
       "      <td>-0.461100</td>\n",
       "      <td>-0.13979</td>\n",
       "      <td>0.35418</td>\n",
       "      <td>-0.058125</td>\n",
       "      <td>0.664700</td>\n",
       "      <td>-0.38143</td>\n",
       "      <td>0.084048</td>\n",
       "      <td>0.42608</td>\n",
       "      <td>0.40040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>india</td>\n",
       "      <td>-0.959670</td>\n",
       "      <td>0.30795</td>\n",
       "      <td>0.90052</td>\n",
       "      <td>1.03640</td>\n",
       "      <td>0.003491</td>\n",
       "      <td>-0.80758</td>\n",
       "      <td>-1.13900</td>\n",
       "      <td>0.81109</td>\n",
       "      <td>-0.67857</td>\n",
       "      <td>...</td>\n",
       "      <td>0.25884</td>\n",
       "      <td>-0.194630</td>\n",
       "      <td>-0.27582</td>\n",
       "      <td>-0.70492</td>\n",
       "      <td>-0.694540</td>\n",
       "      <td>0.706240</td>\n",
       "      <td>0.22830</td>\n",
       "      <td>0.081052</td>\n",
       "      <td>0.13510</td>\n",
       "      <td>0.14388</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 101 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        index         0        1        2        3         4        5  \\\n",
       "0        null  0.079432 -0.14054 -0.10462 -0.36259 -0.227210 -0.13612   \n",
       "1  birmingham  0.473340  0.28810 -0.40206 -0.76942  0.505650  0.56655   \n",
       "2      africa -0.286410  0.84050  1.11780  0.18766  0.073111 -0.24262   \n",
       "3    pretoria -0.100460 -0.44136  0.66512  0.27777 -0.599210  0.29228   \n",
       "4       india -0.959670  0.30795  0.90052  1.03640  0.003491 -0.80758   \n",
       "\n",
       "         6        7        8  ...       90        91       92       93  \\\n",
       "0  0.74755  0.32809  0.54364  ... -1.21230  0.515730  0.16573  0.67943   \n",
       "1  0.15756  0.28222 -0.63076  ... -0.45335 -0.588940  0.10209  1.43720   \n",
       "2  0.12002  0.90520 -0.77801  ...  0.18550 -0.019433  0.64313 -0.22149   \n",
       "3  0.18710  1.24120 -0.70815  ...  0.51562 -0.461100 -0.13979  0.35418   \n",
       "4 -1.13900  0.81109 -0.67857  ...  0.25884 -0.194630 -0.27582 -0.70492   \n",
       "\n",
       "         94        95       96        97       98       99  \n",
       "0  0.353270  0.176720  0.25803  0.068445 -1.20160 -0.20168  \n",
       "1 -0.396420  0.050214  0.57303  0.742570  0.65308 -0.56826  \n",
       "2 -0.372510  0.586410 -0.80282 -0.227080  0.29665  0.20128  \n",
       "3 -0.058125  0.664700 -0.38143  0.084048  0.42608  0.40040  \n",
       "4 -0.694540  0.706240  0.22830  0.081052  0.13510  0.14388  \n",
       "\n",
       "[5 rows x 101 columns]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "location_vectors = pd.DataFrame.from_dict(vectors).T.reset_index()\n",
    "location_vectors.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "aux = []\n",
    "aux.append('location')\n",
    "for i in range (0, 100):\n",
    "    name = 'l' + str(i)\n",
    "    aux.append(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>location</th>\n",
       "      <th>l0</th>\n",
       "      <th>l1</th>\n",
       "      <th>l2</th>\n",
       "      <th>l3</th>\n",
       "      <th>l4</th>\n",
       "      <th>l5</th>\n",
       "      <th>l6</th>\n",
       "      <th>l7</th>\n",
       "      <th>l8</th>\n",
       "      <th>...</th>\n",
       "      <th>l90</th>\n",
       "      <th>l91</th>\n",
       "      <th>l92</th>\n",
       "      <th>l93</th>\n",
       "      <th>l94</th>\n",
       "      <th>l95</th>\n",
       "      <th>l96</th>\n",
       "      <th>l97</th>\n",
       "      <th>l98</th>\n",
       "      <th>l99</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>null</td>\n",
       "      <td>0.079432</td>\n",
       "      <td>-0.14054</td>\n",
       "      <td>-0.10462</td>\n",
       "      <td>-0.36259</td>\n",
       "      <td>-0.227210</td>\n",
       "      <td>-0.13612</td>\n",
       "      <td>0.74755</td>\n",
       "      <td>0.32809</td>\n",
       "      <td>0.54364</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.21230</td>\n",
       "      <td>0.515730</td>\n",
       "      <td>0.16573</td>\n",
       "      <td>0.67943</td>\n",
       "      <td>0.353270</td>\n",
       "      <td>0.176720</td>\n",
       "      <td>0.25803</td>\n",
       "      <td>0.068445</td>\n",
       "      <td>-1.20160</td>\n",
       "      <td>-0.20168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>birmingham</td>\n",
       "      <td>0.473340</td>\n",
       "      <td>0.28810</td>\n",
       "      <td>-0.40206</td>\n",
       "      <td>-0.76942</td>\n",
       "      <td>0.505650</td>\n",
       "      <td>0.56655</td>\n",
       "      <td>0.15756</td>\n",
       "      <td>0.28222</td>\n",
       "      <td>-0.63076</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.45335</td>\n",
       "      <td>-0.588940</td>\n",
       "      <td>0.10209</td>\n",
       "      <td>1.43720</td>\n",
       "      <td>-0.396420</td>\n",
       "      <td>0.050214</td>\n",
       "      <td>0.57303</td>\n",
       "      <td>0.742570</td>\n",
       "      <td>0.65308</td>\n",
       "      <td>-0.56826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>africa</td>\n",
       "      <td>-0.286410</td>\n",
       "      <td>0.84050</td>\n",
       "      <td>1.11780</td>\n",
       "      <td>0.18766</td>\n",
       "      <td>0.073111</td>\n",
       "      <td>-0.24262</td>\n",
       "      <td>0.12002</td>\n",
       "      <td>0.90520</td>\n",
       "      <td>-0.77801</td>\n",
       "      <td>...</td>\n",
       "      <td>0.18550</td>\n",
       "      <td>-0.019433</td>\n",
       "      <td>0.64313</td>\n",
       "      <td>-0.22149</td>\n",
       "      <td>-0.372510</td>\n",
       "      <td>0.586410</td>\n",
       "      <td>-0.80282</td>\n",
       "      <td>-0.227080</td>\n",
       "      <td>0.29665</td>\n",
       "      <td>0.20128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>pretoria</td>\n",
       "      <td>-0.100460</td>\n",
       "      <td>-0.44136</td>\n",
       "      <td>0.66512</td>\n",
       "      <td>0.27777</td>\n",
       "      <td>-0.599210</td>\n",
       "      <td>0.29228</td>\n",
       "      <td>0.18710</td>\n",
       "      <td>1.24120</td>\n",
       "      <td>-0.70815</td>\n",
       "      <td>...</td>\n",
       "      <td>0.51562</td>\n",
       "      <td>-0.461100</td>\n",
       "      <td>-0.13979</td>\n",
       "      <td>0.35418</td>\n",
       "      <td>-0.058125</td>\n",
       "      <td>0.664700</td>\n",
       "      <td>-0.38143</td>\n",
       "      <td>0.084048</td>\n",
       "      <td>0.42608</td>\n",
       "      <td>0.40040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>india</td>\n",
       "      <td>-0.959670</td>\n",
       "      <td>0.30795</td>\n",
       "      <td>0.90052</td>\n",
       "      <td>1.03640</td>\n",
       "      <td>0.003491</td>\n",
       "      <td>-0.80758</td>\n",
       "      <td>-1.13900</td>\n",
       "      <td>0.81109</td>\n",
       "      <td>-0.67857</td>\n",
       "      <td>...</td>\n",
       "      <td>0.25884</td>\n",
       "      <td>-0.194630</td>\n",
       "      <td>-0.27582</td>\n",
       "      <td>-0.70492</td>\n",
       "      <td>-0.694540</td>\n",
       "      <td>0.706240</td>\n",
       "      <td>0.22830</td>\n",
       "      <td>0.081052</td>\n",
       "      <td>0.13510</td>\n",
       "      <td>0.14388</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 101 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     location        l0       l1       l2       l3        l4       l5  \\\n",
       "0        null  0.079432 -0.14054 -0.10462 -0.36259 -0.227210 -0.13612   \n",
       "1  birmingham  0.473340  0.28810 -0.40206 -0.76942  0.505650  0.56655   \n",
       "2      africa -0.286410  0.84050  1.11780  0.18766  0.073111 -0.24262   \n",
       "3    pretoria -0.100460 -0.44136  0.66512  0.27777 -0.599210  0.29228   \n",
       "4       india -0.959670  0.30795  0.90052  1.03640  0.003491 -0.80758   \n",
       "\n",
       "        l6       l7       l8  ...      l90       l91      l92      l93  \\\n",
       "0  0.74755  0.32809  0.54364  ... -1.21230  0.515730  0.16573  0.67943   \n",
       "1  0.15756  0.28222 -0.63076  ... -0.45335 -0.588940  0.10209  1.43720   \n",
       "2  0.12002  0.90520 -0.77801  ...  0.18550 -0.019433  0.64313 -0.22149   \n",
       "3  0.18710  1.24120 -0.70815  ...  0.51562 -0.461100 -0.13979  0.35418   \n",
       "4 -1.13900  0.81109 -0.67857  ...  0.25884 -0.194630 -0.27582 -0.70492   \n",
       "\n",
       "        l94       l95      l96       l97      l98      l99  \n",
       "0  0.353270  0.176720  0.25803  0.068445 -1.20160 -0.20168  \n",
       "1 -0.396420  0.050214  0.57303  0.742570  0.65308 -0.56826  \n",
       "2 -0.372510  0.586410 -0.80282 -0.227080  0.29665  0.20128  \n",
       "3 -0.058125  0.664700 -0.38143  0.084048  0.42608  0.40040  \n",
       "4 -0.694540  0.706240  0.22830  0.081052  0.13510  0.14388  \n",
       "\n",
       "[5 rows x 101 columns]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "location_vectors.columns = aux\n",
    "location_vectors.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>l0</th>\n",
       "      <th>l1</th>\n",
       "      <th>l2</th>\n",
       "      <th>l3</th>\n",
       "      <th>l4</th>\n",
       "      <th>...</th>\n",
       "      <th>l90</th>\n",
       "      <th>l91</th>\n",
       "      <th>l92</th>\n",
       "      <th>l93</th>\n",
       "      <th>l94</th>\n",
       "      <th>l95</th>\n",
       "      <th>l96</th>\n",
       "      <th>l97</th>\n",
       "      <th>l98</th>\n",
       "      <th>l99</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>null</td>\n",
       "      <td>null</td>\n",
       "      <td>our deeds are the reason of this  earthquake m...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.079432</td>\n",
       "      <td>-0.14054</td>\n",
       "      <td>-0.10462</td>\n",
       "      <td>-0.362590</td>\n",
       "      <td>-0.22721</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.21230</td>\n",
       "      <td>0.51573</td>\n",
       "      <td>0.16573</td>\n",
       "      <td>0.67943</td>\n",
       "      <td>0.35327</td>\n",
       "      <td>0.17672</td>\n",
       "      <td>0.25803</td>\n",
       "      <td>0.068445</td>\n",
       "      <td>-1.20160</td>\n",
       "      <td>-0.20168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>null</td>\n",
       "      <td>null</td>\n",
       "      <td>forest fire near la ronge sask  canada</td>\n",
       "      <td>1</td>\n",
       "      <td>0.079432</td>\n",
       "      <td>-0.14054</td>\n",
       "      <td>-0.10462</td>\n",
       "      <td>-0.362590</td>\n",
       "      <td>-0.22721</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.21230</td>\n",
       "      <td>0.51573</td>\n",
       "      <td>0.16573</td>\n",
       "      <td>0.67943</td>\n",
       "      <td>0.35327</td>\n",
       "      <td>0.17672</td>\n",
       "      <td>0.25803</td>\n",
       "      <td>0.068445</td>\n",
       "      <td>-1.20160</td>\n",
       "      <td>-0.20168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>null</td>\n",
       "      <td>null</td>\n",
       "      <td>all residents asked to  shelter in place  are ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.079432</td>\n",
       "      <td>-0.14054</td>\n",
       "      <td>-0.10462</td>\n",
       "      <td>-0.362590</td>\n",
       "      <td>-0.22721</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.21230</td>\n",
       "      <td>0.51573</td>\n",
       "      <td>0.16573</td>\n",
       "      <td>0.67943</td>\n",
       "      <td>0.35327</td>\n",
       "      <td>0.17672</td>\n",
       "      <td>0.25803</td>\n",
       "      <td>0.068445</td>\n",
       "      <td>-1.20160</td>\n",
       "      <td>-0.20168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>null</td>\n",
       "      <td>null</td>\n",
       "      <td>number people receive  wildfires evacuation or...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.079432</td>\n",
       "      <td>-0.14054</td>\n",
       "      <td>-0.10462</td>\n",
       "      <td>-0.362590</td>\n",
       "      <td>-0.22721</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.21230</td>\n",
       "      <td>0.51573</td>\n",
       "      <td>0.16573</td>\n",
       "      <td>0.67943</td>\n",
       "      <td>0.35327</td>\n",
       "      <td>0.17672</td>\n",
       "      <td>0.25803</td>\n",
       "      <td>0.068445</td>\n",
       "      <td>-1.20160</td>\n",
       "      <td>-0.20168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>null</td>\n",
       "      <td>null</td>\n",
       "      <td>just got sent this photo from ruby  alaska as ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.079432</td>\n",
       "      <td>-0.14054</td>\n",
       "      <td>-0.10462</td>\n",
       "      <td>-0.362590</td>\n",
       "      <td>-0.22721</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.21230</td>\n",
       "      <td>0.51573</td>\n",
       "      <td>0.16573</td>\n",
       "      <td>0.67943</td>\n",
       "      <td>0.35327</td>\n",
       "      <td>0.17672</td>\n",
       "      <td>0.25803</td>\n",
       "      <td>0.068445</td>\n",
       "      <td>-1.20160</td>\n",
       "      <td>-0.20168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7429</th>\n",
       "      <td>10822</td>\n",
       "      <td>wrecked</td>\n",
       "      <td>glasgow</td>\n",
       "      <td>user see u the night wee barra to get absolute...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7430</th>\n",
       "      <td>10824</td>\n",
       "      <td>wrecked</td>\n",
       "      <td>denton texas</td>\n",
       "      <td>had an awesome time gettin wrecked at bowling ...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7431</th>\n",
       "      <td>10829</td>\n",
       "      <td>wrecked</td>\n",
       "      <td>#newcastleupontyne #uk</td>\n",
       "      <td>user     he s gone  you can relax  i thought t...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7432</th>\n",
       "      <td>10832</td>\n",
       "      <td>wrecked</td>\n",
       "      <td>london</td>\n",
       "      <td>fx  forex  trading cramer  iger s number word...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7433</th>\n",
       "      <td>10833</td>\n",
       "      <td>wrecked</td>\n",
       "      <td>lincoln</td>\n",
       "      <td>user great atmosphere at the british lion gig ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.025206</td>\n",
       "      <td>0.46574</td>\n",
       "      <td>-0.15421</td>\n",
       "      <td>-0.071269</td>\n",
       "      <td>0.47114</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.05322</td>\n",
       "      <td>-0.46613</td>\n",
       "      <td>0.44270</td>\n",
       "      <td>0.96169</td>\n",
       "      <td>-1.06060</td>\n",
       "      <td>-0.30270</td>\n",
       "      <td>0.32299</td>\n",
       "      <td>0.289500</td>\n",
       "      <td>0.26598</td>\n",
       "      <td>-0.30889</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7434 rows × 105 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id  keyword                location  \\\n",
       "0         1     null                    null   \n",
       "1         4     null                    null   \n",
       "2         5     null                    null   \n",
       "3         6     null                    null   \n",
       "4         7     null                    null   \n",
       "...     ...      ...                     ...   \n",
       "7429  10822  wrecked                glasgow    \n",
       "7430  10824  wrecked            denton texas   \n",
       "7431  10829  wrecked  #newcastleupontyne #uk   \n",
       "7432  10832  wrecked                 london    \n",
       "7433  10833  wrecked                 lincoln   \n",
       "\n",
       "                                                   text  target        l0  \\\n",
       "0     our deeds are the reason of this  earthquake m...       1  0.079432   \n",
       "1                forest fire near la ronge sask  canada       1  0.079432   \n",
       "2     all residents asked to  shelter in place  are ...       1  0.079432   \n",
       "3     number people receive  wildfires evacuation or...       1  0.079432   \n",
       "4     just got sent this photo from ruby  alaska as ...       1  0.079432   \n",
       "...                                                 ...     ...       ...   \n",
       "7429  user see u the night wee barra to get absolute...       0       NaN   \n",
       "7430  had an awesome time gettin wrecked at bowling ...       0       NaN   \n",
       "7431  user     he s gone  you can relax  i thought t...       0       NaN   \n",
       "7432   fx  forex  trading cramer  iger s number word...       0       NaN   \n",
       "7433  user great atmosphere at the british lion gig ...       0  0.025206   \n",
       "\n",
       "           l1       l2        l3       l4  ...      l90      l91      l92  \\\n",
       "0    -0.14054 -0.10462 -0.362590 -0.22721  ... -1.21230  0.51573  0.16573   \n",
       "1    -0.14054 -0.10462 -0.362590 -0.22721  ... -1.21230  0.51573  0.16573   \n",
       "2    -0.14054 -0.10462 -0.362590 -0.22721  ... -1.21230  0.51573  0.16573   \n",
       "3    -0.14054 -0.10462 -0.362590 -0.22721  ... -1.21230  0.51573  0.16573   \n",
       "4    -0.14054 -0.10462 -0.362590 -0.22721  ... -1.21230  0.51573  0.16573   \n",
       "...       ...      ...       ...      ...  ...      ...      ...      ...   \n",
       "7429      NaN      NaN       NaN      NaN  ...      NaN      NaN      NaN   \n",
       "7430      NaN      NaN       NaN      NaN  ...      NaN      NaN      NaN   \n",
       "7431      NaN      NaN       NaN      NaN  ...      NaN      NaN      NaN   \n",
       "7432      NaN      NaN       NaN      NaN  ...      NaN      NaN      NaN   \n",
       "7433  0.46574 -0.15421 -0.071269  0.47114  ... -0.05322 -0.46613  0.44270   \n",
       "\n",
       "          l93      l94      l95      l96       l97      l98      l99  \n",
       "0     0.67943  0.35327  0.17672  0.25803  0.068445 -1.20160 -0.20168  \n",
       "1     0.67943  0.35327  0.17672  0.25803  0.068445 -1.20160 -0.20168  \n",
       "2     0.67943  0.35327  0.17672  0.25803  0.068445 -1.20160 -0.20168  \n",
       "3     0.67943  0.35327  0.17672  0.25803  0.068445 -1.20160 -0.20168  \n",
       "4     0.67943  0.35327  0.17672  0.25803  0.068445 -1.20160 -0.20168  \n",
       "...       ...      ...      ...      ...       ...      ...      ...  \n",
       "7429      NaN      NaN      NaN      NaN       NaN      NaN      NaN  \n",
       "7430      NaN      NaN      NaN      NaN       NaN      NaN      NaN  \n",
       "7431      NaN      NaN      NaN      NaN       NaN      NaN      NaN  \n",
       "7432      NaN      NaN      NaN      NaN       NaN      NaN      NaN  \n",
       "7433  0.96169 -1.06060 -0.30270  0.32299  0.289500  0.26598 -0.30889  \n",
       "\n",
       "[7434 rows x 105 columns]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "locations_to_merge = tweets.merge(location_vectors, on='location', how = 'outer')#.drop(columns=['keyword', 'location', 'text', 'target'])\n",
    "locations_to_merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "locations_test_merge = test.merge(location_vectors, how='left').drop(columns=['keyword', 'location', 'text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "locations_to_merge.to_csv('locations_vectors_train.csv', index = False)\n",
    "locations_test_merge.to_csv('locations_vectors_test.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge all things"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_w_features = pd.read_csv('../TP2/train_features.csv')\n",
    "test_w_features = pd.read_csv('../TP2/test_features.csv')\n",
    "keyword_features = pd.read_csv('../TP2/keyword_features.csv')\n",
    "keyword_test_features = pd.read_csv('../TP2/keyword_test_features.csv')\n",
    "train_processed_text = pd.read_csv('../TP2/processed_train.csv')\n",
    "test_processed_text = pd.read_csv('../TP2/processed_test.csv')\n",
    "location_train_xy = pd.read_csv('../TP2/coordinates_train.csv')\n",
    "location_test_xy = pd.read_csv('../TP2/coordinates_test.csv')\n",
    "location_train_vectors = pd.read_csv('../TP2/locations_vectors_train.csv')\n",
    "location_test_vectors = pd.read_csv('../TP2/locations_vectors_test.csv')\n",
    "\n",
    "train_w_features.insert(3,'target',train_processed_text['target'])\n",
    "train_features_and_kw = train_w_features.merge(keyword_features, on='id')\n",
    "train_features_and_kw.insert(3,'processed_text', train_processed_text['text'])\n",
    "\n",
    "test_features_and_kw = test_w_features.merge(keyword_test_features, on='id')\n",
    "test_features_and_kw.insert(3,'processed_text', test_processed_text['text'])\n",
    "\n",
    "train_features_and_kw['text_without_stopwords'] = train_features_and_kw['text_without_stopwords'].fillna('')\n",
    "test_features_and_kw['text_without_stopwords'] = test_features_and_kw['text_without_stopwords'].fillna('')\n",
    "\n",
    "locations_train = location_train_xy.merge(location_train_vectors, on = 'id')\n",
    "locations_test = location_test_xy.merge(location_test_vectors, on = 'id')\n",
    "\n",
    "train_complete = train_features_and_kw.merge(locations_train, on = 'id')\n",
    "test_complete = test_features_and_kw.merge(locations_test, on = 'id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_complete['x'] = train_complete['x'].fillna(300.0)\n",
    "test_complete['x'] = test_complete['x'].fillna(300.0)\n",
    "train_complete['y'] = train_complete['y'].fillna(300.0)\n",
    "test_complete['y'] = test_complete['y'].fillna(300.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "loc_values = locations_train.loc[0,'l0':].to_list()\n",
    "for column in train_complete.loc[:,'l0':].columns:\n",
    "    train_complete[column] = train_complete[column].fillna(loc_values[i])\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "j = 0\n",
    "loc_values2 = locations_test.loc[0,'l0':].to_list()\n",
    "for column in test_complete.loc[:,'l0':].columns:\n",
    "    test_complete[column] = test_complete[column].fillna(loc_values2[j])\n",
    "    j+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_complete.drop(columns=['text_x', 'text_without_stopwords', 'processed_text','target_x', 'keyword', 'location', 'text_y', 'target_y'], inplace=True)\n",
    "test_complete.drop(columns=['text_without_stopwords', 'processed_text'], inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_complete.to_csv('train_complete.csv', index = False)\n",
    "test_complete.to_csv('test_complete.csv', index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
