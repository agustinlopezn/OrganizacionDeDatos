{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     /Users/matiascano/nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/matiascano/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/matiascano/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/matiascano/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import string\n",
    "#import xgboost as xgb\n",
    "import io\n",
    "import nltk\n",
    "import matplotlib\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn import preprocessing\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "nltk.download('vader_lexicon')\n",
    "nltk.download('stopwords')\n",
    "stopwords = stopwords.words('english')\n",
    "stemmer = SnowballStemmer('english')\n",
    "\n",
    "from textblob import TextBlob\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sia = SentimentIntensityAnalyzer()\n",
    "def return_sia_compound_values(text):\n",
    "    return sia.polarity_scores(text)['compound']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopword(text):\n",
    "    new_text = []\n",
    "    for e in text:\n",
    "        if e not in stopwords and e.isalpha():\n",
    "            new_text.append(e)\n",
    "    text = new_text\n",
    "    return \" \".join(new_text)\n",
    "\n",
    "def stemm(text):\n",
    "    text = [stemmer.stem(word) for word in text.split()]\n",
    "    return \" \".join(text)\n",
    "\n",
    "def contains_punctuation(text):\n",
    "    punctuation = set(string.punctuation)\n",
    "    for character in text:\n",
    "        if character in punctuation:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "def amount_of_punctuation(text):\n",
    "    punctuation = set(string.punctuation)\n",
    "    amount = 0\n",
    "    for character in text:\n",
    "        if character in punctuation: amount += 1\n",
    "    return amount\n",
    "\n",
    "def get_adjectives(text):\n",
    "    blob = TextBlob(text)\n",
    "    return len([word for (word,tag) in blob.tags if tag.startswith(\"JJ\")])\n",
    "\n",
    "def get_nouns(text):\n",
    "    blob = TextBlob(text)\n",
    "    return len([word for (word,tag) in blob.tags if tag.startswith(\"NN\")])\n",
    "\n",
    "def get_verbs(text):\n",
    "    blob = TextBlob(text)\n",
    "    return len([word for (word,tag) in blob.tags if tag.startswith(\"VB\")])\n",
    "\n",
    "def get_adverbs(text):\n",
    "    blob = TextBlob(text)\n",
    "    return len([word for (word,tag) in blob.tags if tag.startswith(\"RB\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = pd.read_csv(\"train.csv\")\n",
    "test = pd.read_csv(\"test.csv\")\n",
    "tweets['keyword'] = tweets.keyword.str.replace('%20',' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 7434 entries, 0 to 7612\n",
      "Data columns (total 5 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   id        7434 non-null   int64 \n",
      " 1   keyword   7378 non-null   object\n",
      " 2   location  4982 non-null   object\n",
      " 3   text      7434 non-null   object\n",
      " 4   target    7434 non-null   int64 \n",
      "dtypes: int64(2), object(3)\n",
      "memory usage: 348.5+ KB\n"
     ]
    }
   ],
   "source": [
    "tweets.drop_duplicates(subset = 'text', keep = False, inplace = True)\n",
    "tweets.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    3243\n",
       "True       20\n",
       "Name: text, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test['text'].duplicated().value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_metrics = tweets[['id','text','target']]\n",
    "tweets_metrics['text_without_stopwords'] = tweets_metrics['text'].str.split()\n",
    "tweets_metrics['text_without_stopwords'] = tweets_metrics['text_without_stopwords'].apply(remove_stopword)\n",
    "\n",
    "tweets_metrics['length'] = tweets_metrics['text'].apply(lambda x: len(x))\n",
    "tweets_metrics['avg_word_length'] = tweets_metrics['text'].str.split().apply(lambda x: [len(y) for y in x]).transform(lambda x: np.mean(x))\n",
    "tweets_metrics['amount_of_words'] = tweets_metrics['text'].str.split().transform(lambda x: len(x))\n",
    "unique_words_by_tweet = tweets_metrics['text'].transform(lambda x: x.split()).transform(lambda x: pd.Series(x).unique()).transform(lambda x: len(x))\n",
    "tweets_metrics['amount_of_unique_words'] = unique_words_by_tweet\n",
    "tweets_metrics['sentiment'] = tweets_metrics['text'].apply(lambda x: return_sia_compound_values(x))\n",
    "tweets_metrics['stopwords_count'] = tweets_metrics['text'].apply(lambda x: len([word for word in str(x).lower().split() if word in stopwords]))\n",
    "tweets_metrics['punctuation_count'] = tweets_metrics['text'].apply(lambda x: amount_of_punctuation(x))\n",
    "mentions = tweets_metrics['text'].str.findall(r'@.\\S*?(?=\\s|[:]|$)').to_frame()\n",
    "tweets_metrics['mentions_count'] = mentions['text'].apply(lambda x: len(x))\n",
    "hashtags = tweets_metrics['text'].str.findall(r'#[^?\\s].*?(?=\\s|$)')\n",
    "tweets_metrics['hashtags_count'] = hashtags.apply(lambda x: len(x))\n",
    "tweets_metrics['longest_word_length_without_stopwords'] = tweets_metrics['text_without_stopwords'].apply(lambda x: ([len(word) for word in str(x).lower().split() if not word.startswith('http')])).apply(lambda x: max(x) if len(x) > 0 else 0)\n",
    "tweets_metrics['stopword_word_ratio'] = tweets_metrics['stopwords_count'] / tweets_metrics['amount_of_words']\n",
    "\n",
    "tweets_metrics['adjectives_count'] = tweets_metrics['text'].apply(get_adjectives)\n",
    "tweets_metrics['nouns_count'] = tweets_metrics['text'].apply(get_nouns)\n",
    "tweets_metrics['verbs_count'] = tweets_metrics['text'].apply(get_verbs)\n",
    "tweets_metrics['adverbs_count'] = tweets_metrics['text'].apply(get_adverbs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_metrics.to_csv('train_features.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_metrics = test[['id','text']]\n",
    "test_metrics['text_without_stopwords'] = test_metrics['text'].str.split()\n",
    "test_metrics['text_without_stopwords'] = test_metrics['text_without_stopwords'].apply(remove_stopword)\n",
    "\n",
    "test_metrics['length'] = test_metrics['text'].apply(lambda x: len(x))\n",
    "test_metrics['avg_word_length'] = test_metrics['text'].str.split().apply(lambda x: [len(y) for y in x]).transform(lambda x: np.mean(x))\n",
    "test_metrics['amount_of_words'] = test_metrics['text'].str.split().transform(lambda x: len(x))\n",
    "unique_words_by_tweet = test_metrics['text'].transform(lambda x: x.split()).transform(lambda x: pd.Series(x).unique()).transform(lambda x: len(x))\n",
    "test_metrics['amount_of_unique_words'] = unique_words_by_tweet\n",
    "test_metrics['sentiment'] = test_metrics['text'].apply(lambda x: return_sia_compound_values(x))\n",
    "test_metrics['stopwords_count'] = test_metrics['text'].apply(lambda x: len([word for word in str(x).lower().split() if word in stopwords]))\n",
    "test_metrics['punctuation_count'] = test_metrics['text'].apply(lambda x: amount_of_punctuation(x))\n",
    "mentions = test_metrics['text'].str.findall(r'@.\\S*?(?=\\s|[:]|$)').to_frame()\n",
    "test_metrics['mentions_count'] = mentions['text'].apply(lambda x: len(x))\n",
    "hashtags = test_metrics['text'].str.findall(r'#[^?\\s].*?(?=\\s|$)')\n",
    "test_metrics['hashtags_count'] = hashtags.apply(lambda x: len(x))\n",
    "test_metrics['longest_word_length_without_stopwords'] = test_metrics['text_without_stopwords'].apply(lambda x: ([len(word) for word in str(x).lower().split() if not word.startswith('http')])).apply(lambda x: max(x) if len(x) > 0 else 0)\n",
    "test_metrics['stopword_word_ratio'] = test_metrics['stopwords_count'] / test_metrics['amount_of_words']\n",
    "\n",
    "test_metrics['adjectives_count'] = test_metrics['text'].apply(get_adjectives)\n",
    "test_metrics['nouns_count'] = test_metrics['text'].apply(get_nouns)\n",
    "test_metrics['verbs_count'] = test_metrics['text'].apply(get_verbs)\n",
    "test_metrics['adverbs_count'] = test_metrics['text'].apply(get_adverbs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.to_csv('test_features.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word2Vec\n",
    "\n",
    "#### Keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets['keyword'] = tweets['keyword'].fillna('NULL')\n",
    "test['keyword'] = test['keyword'].fillna('NULL')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keywords = tweets[['keyword', 'id']]\n",
    "keywords.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keyword_tokens = keywords.keyword.unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "keyword_tokens[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(keyword_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "\n",
    "# Parameters\n",
    "# sg ({0, 1}, optional) - Training algorithm: 1 for skip-gram; otherwise CBOW.\n",
    "\n",
    "keyword_vectors = Word2Vec([keyword_tokens], min_count=1, size= 100, workers=3, window =3, sg=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Sanity check\n",
    "keyword_vectors['ablaze']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_vector_matrix = {}\n",
    "\n",
    "for k in keyword_tokens:\n",
    "    to_vector_matrix[k] = keyword_vectors[k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keyword_w2v = pd.DataFrame.from_dict(to_vector_matrix).T.reset_index()\n",
    "keyword_w2v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aux = []\n",
    "aux.append('keyword')\n",
    "for i in range (0, 100):\n",
    "    name = 'v' + str(i)\n",
    "    aux.append(name)\n",
    "len(aux)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keyword_w2v.columns = aux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keyword_w2v.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keyword_w2v.to_csv('keyword_features.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "locations = pd.read_csv(\"../TP1/locations.csv\", usecols=['location', 'address'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>location</th>\n",
       "      <th>address</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>glasgow</td>\n",
       "      <td>Glasgow, Glasgow City, Scotland, G2 9SA, Unite...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>melbourne, australia</td>\n",
       "      <td>City of Melbourne, Victoria, Australia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>news</td>\n",
       "      <td>34375, Abbotsford Centre, Abbotsford, Fraser V...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>alberta</td>\n",
       "      <td>Alberta, Canada</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 location                                            address\n",
       "0                                                                        NaN\n",
       "1                glasgow   Glasgow, Glasgow City, Scotland, G2 9SA, Unite...\n",
       "2    melbourne, australia             City of Melbourne, Victoria, Australia\n",
       "3                    news  34375, Abbotsford Centre, Abbotsford, Fraser V...\n",
       "4                 alberta                                    Alberta, Canada"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "locations.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "locations.loc[0, 'location'] = 'NULL'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>location</th>\n",
       "      <th>address</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NULL</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>glasgow</td>\n",
       "      <td>Glasgow, Glasgow City, Scotland, G2 9SA, Unite...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>melbourne, australia</td>\n",
       "      <td>City of Melbourne, Victoria, Australia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>news</td>\n",
       "      <td>34375, Abbotsford Centre, Abbotsford, Fraser V...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>alberta</td>\n",
       "      <td>Alberta, Canada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2266</th>\n",
       "      <td>zac newsome loves me</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2267</th>\n",
       "      <td>zeerust, south africa</td>\n",
       "      <td>Zeerust, Ngaka Modiri Molema District Municipa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2268</th>\n",
       "      <td>zero branco</td>\n",
       "      <td>Zero Branco, Treviso, Veneto, 31059, Italia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2269</th>\n",
       "      <td>ziam af</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2270</th>\n",
       "      <td>zimbabwe</td>\n",
       "      <td>Zimbabwe</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2271 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    location  \\\n",
       "0                       NULL   \n",
       "1                   glasgow    \n",
       "2       melbourne, australia   \n",
       "3                       news   \n",
       "4                    alberta   \n",
       "...                      ...   \n",
       "2266    zac newsome loves me   \n",
       "2267   zeerust, south africa   \n",
       "2268             zero branco   \n",
       "2269                ziam af    \n",
       "2270                zimbabwe   \n",
       "\n",
       "                                                address  \n",
       "0                                                   NaN  \n",
       "1     Glasgow, Glasgow City, Scotland, G2 9SA, Unite...  \n",
       "2                City of Melbourne, Victoria, Australia  \n",
       "3     34375, Abbotsford Centre, Abbotsford, Fraser V...  \n",
       "4                                       Alberta, Canada  \n",
       "...                                                 ...  \n",
       "2266                                                NaN  \n",
       "2267  Zeerust, Ngaka Modiri Molema District Municipa...  \n",
       "2268        Zero Branco, Treviso, Veneto, 31059, Italia  \n",
       "2269                                                NaN  \n",
       "2270                                           Zimbabwe  \n",
       "\n",
       "[2271 rows x 2 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "for_location = tweets[['id', 'location']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matiascano/.pyenv/versions/3.7.7/lib/python3.7/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "for_location['location'] = for_location['location'].map(lambda x: x if x is np.nan else x.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matiascano/.pyenv/versions/3.7.7/lib/python3.7/site-packages/pandas/core/frame.py:4153: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  downcast=downcast,\n"
     ]
    }
   ],
   "source": [
    "for_location.fillna(\"NULL\", inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matiascano/.pyenv/versions/3.7.7/lib/python3.7/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "import re \n",
    "for_location['location'] = for_location['location'].map(lambda x: x if re.match(r'^([a-zA-Z,\\s])*$', x) else 'NULL')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "to_vectorize = for_location.merge(locations).loc[:, ['id', 'address']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_vectorize.fillna('NULL', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_vectorize['address'] = to_vectorize['address'].str.replace('\\d+', '') # No le gustan los numeros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 7433 entries, 0 to 7432\n",
      "Data columns (total 2 columns):\n",
      " #   Column   Non-Null Count  Dtype \n",
      "---  ------   --------------  ----- \n",
      " 0   id       7433 non-null   int64 \n",
      " 1   address  7433 non-null   object\n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 174.2+ KB\n"
     ]
    }
   ],
   "source": [
    "to_vectorize.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "\n",
    "t = Tokenizer()\n",
    "t.fit_on_texts(to_vectorize['address'])\n",
    "vocab_size = len(t.word_index) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'null': 1,\n",
       " 'united': 2,\n",
       " 'of': 3,\n",
       " 'states': 4,\n",
       " 'america': 5,\n",
       " 'county': 6,\n",
       " 'england': 7,\n",
       " 'kingdom': 8,\n",
       " 'new': 9,\n",
       " 'york': 10,\n",
       " 'canada': 11,\n",
       " 'california': 12,\n",
       " 'london': 13,\n",
       " 'city': 14,\n",
       " 'north': 15,\n",
       " 'west': 16,\n",
       " 'south': 17,\n",
       " 'texas': 18,\n",
       " 'greater': 19,\n",
       " 'district': 20,\n",
       " 'de': 21,\n",
       " 'san': 22,\n",
       " 'australia': 23,\n",
       " 'los': 24,\n",
       " 'angeles': 25,\n",
       " 'east': 26,\n",
       " 'india': 27,\n",
       " 'florida': 28,\n",
       " 'washington': 29,\n",
       " 'ontario': 30,\n",
       " 'and': 31,\n",
       " 'columbia': 32,\n",
       " 'carolina': 33,\n",
       " 'swa': 34,\n",
       " 'dx': 35,\n",
       " 'the': 36,\n",
       " 'francisco': 37,\n",
       " 'illinois': 38,\n",
       " 'del': 39,\n",
       " 'santo': 40,\n",
       " 'domingo': 41,\n",
       " 'nigeria': 42,\n",
       " 'midlands': 43,\n",
       " 'france': 44,\n",
       " 'georgia': 45,\n",
       " 'mumbai': 46,\n",
       " 'pennsylvania': 47,\n",
       " 'street': 48,\n",
       " 'road': 49,\n",
       " 'colorado': 50,\n",
       " 'jersey': 51,\n",
       " 'wellington': 52,\n",
       " 'park': 53,\n",
       " 'golden': 54,\n",
       " 'horseshoe': 55,\n",
       " 'manchester': 56,\n",
       " 'ohio': 57,\n",
       " 'tennessee': 58,\n",
       " 'buenos': 59,\n",
       " 'aires': 60,\n",
       " 'cook': 61,\n",
       " 'oklahoma': 62,\n",
       " 'massachusetts': 63,\n",
       " 'chicago': 64,\n",
       " 'british': 65,\n",
       " 'kenya': 66,\n",
       " 'virginia': 67,\n",
       " 'victoria': 68,\n",
       " 'regional': 69,\n",
       " 'philippines': 70,\n",
       " 'região': 71,\n",
       " 'central': 72,\n",
       " 'denver': 73,\n",
       " 'africa': 74,\n",
       " 'alberta': 75,\n",
       " 'toronto': 76,\n",
       " 'avenue': 77,\n",
       " 'vancouver': 78,\n",
       " 'wales': 79,\n",
       " 'yorkshire': 80,\n",
       " 'oregon': 81,\n",
       " 'maharashtra': 82,\n",
       " 'italia': 83,\n",
       " 'distrito': 84,\n",
       " 'scotland': 85,\n",
       " 'metro': 86,\n",
       " 'region': 87,\n",
       " 'república': 88,\n",
       " 'dominicana': 89,\n",
       " 'maryland': 90,\n",
       " 'este': 91,\n",
       " 'michigan': 92,\n",
       " 'diego': 93,\n",
       " 'arizona': 94,\n",
       " 'sacramento': 95,\n",
       " 'worldwide': 96,\n",
       " 'calle': 97,\n",
       " 'guzmán': 98,\n",
       " 'nacional': 99,\n",
       " 'atlanta': 100,\n",
       " 'king': 101,\n",
       " 'davidson': 102,\n",
       " 'indonesia': 103,\n",
       " 'vientos': 104,\n",
       " 'mirador': 105,\n",
       " 'dallas': 106,\n",
       " 'ireland': 107,\n",
       " 'island': 108,\n",
       " 'lagos': 109,\n",
       " 'philadelphia': 110,\n",
       " 'santa': 111,\n",
       " 'fulton': 112,\n",
       " 'world': 113,\n",
       " 'lake': 114,\n",
       " 'orange': 115,\n",
       " 'la': 116,\n",
       " 'seattle': 117,\n",
       " 'zealand': 118,\n",
       " 'municipality': 119,\n",
       " 'n': 120,\n",
       " 'nederland': 121,\n",
       " 'भारत': 122,\n",
       " 'vaudreuil': 123,\n",
       " 'suffolk': 124,\n",
       " 'métropolitaine': 125,\n",
       " 'wisconsin': 126,\n",
       " 'earth': 127,\n",
       " 'township': 128,\n",
       " 'area': 129,\n",
       " 'calgary': 130,\n",
       " 'پاکستان': 131,\n",
       " 'humber': 132,\n",
       " 'românia': 133,\n",
       " 'orlando': 134,\n",
       " 'sydney': 135,\n",
       " 'saint': 136,\n",
       " 'tyne': 137,\n",
       " 'combined': 138,\n",
       " 'authority': 139,\n",
       " 'brasil': 140,\n",
       " 'clark': 141,\n",
       " 'nevada': 142,\n",
       " 'town': 143,\n",
       " 'rio': 144,\n",
       " 'everywhere': 145,\n",
       " 'harris': 146,\n",
       " 'cape': 147,\n",
       " 'capital': 148,\n",
       " 'don': 149,\n",
       " 'charlotte': 150,\n",
       " 'beach': 151,\n",
       " 'bangalore': 152,\n",
       " 'miami': 153,\n",
       " 'janeiro': 154,\n",
       " 'narrow': 155,\n",
       " 'path': 156,\n",
       " 'thorn': 157,\n",
       " 'sântelec': 158,\n",
       " 'bihor': 159,\n",
       " 'queensland': 160,\n",
       " 'western': 161,\n",
       " 'indiana': 162,\n",
       " 'valley': 163,\n",
       " 'm': 164,\n",
       " 'port': 165,\n",
       " 'houston': 166,\n",
       " 'manila': 167,\n",
       " 'council': 168,\n",
       " 'nova': 169,\n",
       " 'clara': 170,\n",
       " 'mh': 171,\n",
       " 'argentina': 172,\n",
       " 'melbourne': 173,\n",
       " 'delhi': 174,\n",
       " 'boulevard': 175,\n",
       " 'kings': 176,\n",
       " 'glasgow': 177,\n",
       " 'missouri': 178,\n",
       " 'scotia': 179,\n",
       " 'alabama': 180,\n",
       " 'do': 181,\n",
       " 'kansas': 182,\n",
       " 'metropolitan': 183,\n",
       " 'geográfica': 184,\n",
       " 'louisiana': 185,\n",
       " 'québec': 186,\n",
       " 'españa': 187,\n",
       " 'austin': 188,\n",
       " '日本': 189,\n",
       " 'montgomery': 190,\n",
       " 'sa': 191,\n",
       " '中国': 192,\n",
       " 'nashville': 193,\n",
       " 'deutschland': 194,\n",
       " 'hampshire': 195,\n",
       " 'c': 196,\n",
       " 'mecklenburg': 197,\n",
       " 'parish': 198,\n",
       " 'maricopa': 199,\n",
       " 'travis': 200,\n",
       " 'airport': 201,\n",
       " 'brooklyn': 202,\n",
       " 'e': 203,\n",
       " 'a': 204,\n",
       " 'roma': 205,\n",
       " 'birmingham': 206,\n",
       " 'cymru': 207,\n",
       " 'lamb': 208,\n",
       " 'portland': 209,\n",
       " 'mitchelltown': 210,\n",
       " 'te': 211,\n",
       " 'aro': 212,\n",
       " 'dublin': 213,\n",
       " 'hong': 214,\n",
       " 'kong': 215,\n",
       " 'borough': 216,\n",
       " 'el': 217,\n",
       " 'são': 218,\n",
       " 'paulo': 219,\n",
       " 'metropolitana': 220,\n",
       " 'joseph': 221,\n",
       " 'montérégie': 222,\n",
       " 'jackson': 223,\n",
       " 'boston': 224,\n",
       " 'bay': 225,\n",
       " 'connecticut': 226,\n",
       " 'norge': 227,\n",
       " 'drive': 228,\n",
       " 'fort': 229,\n",
       " 'international': 230,\n",
       " 'iowa': 231,\n",
       " 'lane': 232,\n",
       " 'newcastle': 233,\n",
       " 'thornton': 234,\n",
       " 'madison': 235,\n",
       " 'hillsborough': 236,\n",
       " 'nairobi': 237,\n",
       " 'laflèche': 238,\n",
       " 'terrasse': 239,\n",
       " 'pincourt': 240,\n",
       " 'soulanges': 241,\n",
       " 'jv': 242,\n",
       " 'hamilton': 243,\n",
       " 'shelby': 244,\n",
       " 'manhattan': 245,\n",
       " 'st': 246,\n",
       " 'adelaide': 247,\n",
       " 'multnomah': 248,\n",
       " 'th': 249,\n",
       " 'praha': 250,\n",
       " 'roskilde': 251,\n",
       " 'hawaii': 252,\n",
       " 'puerto': 253,\n",
       " 'village': 254,\n",
       " 'chester': 255,\n",
       " 'winnipeg': 256,\n",
       " 'ncr': 257,\n",
       " 'intermediária': 258,\n",
       " 'arlington': 259,\n",
       " 'tarrant': 260,\n",
       " 'eastern': 261,\n",
       " 'urban': 262,\n",
       " 'karnataka': 263,\n",
       " 'orleans': 264,\n",
       " 'middlesex': 265,\n",
       " 'kentucky': 266,\n",
       " 'oakland': 267,\n",
       " 'las': 268,\n",
       " 'japan': 269,\n",
       " 'g': 270,\n",
       " 'great': 271,\n",
       " 'britain': 272,\n",
       " 'cuyahoga': 273,\n",
       " 'johannesburg': 274,\n",
       " 'wayne': 275,\n",
       " 'jefferson': 276,\n",
       " 'lincoln': 277,\n",
       " 'b': 278,\n",
       " 'rico': 279,\n",
       " 'richmond': 280,\n",
       " 'upon': 281,\n",
       " 'wear': 282,\n",
       " 'gauteng': 283,\n",
       " 'territory': 284,\n",
       " 'global': 285,\n",
       " 'creek': 286,\n",
       " 'southern': 287,\n",
       " 'vegas': 288,\n",
       " 'coast': 289,\n",
       " 'memphis': 290,\n",
       " 'spokane': 291,\n",
       " 'milwaukee': 292,\n",
       " 'sassari': 293,\n",
       " 'sardegna': 294,\n",
       " 'richmondshire': 295,\n",
       " 'jose': 296,\n",
       " 'méxico': 297,\n",
       " 'northern': 298,\n",
       " 'heights': 299,\n",
       " 'danmark': 300,\n",
       " 'capitale': 301,\n",
       " 'leeds': 302,\n",
       " 'tulsa': 303,\n",
       " 'sverige': 304,\n",
       " 'lunenburg': 305,\n",
       " 'wyoming': 306,\n",
       " 'paris': 307,\n",
       " 'ክልል': 308,\n",
       " 'ethiopia': 309,\n",
       " 'accra': 310,\n",
       " 'imediata': 311,\n",
       " 'sudeste': 312,\n",
       " 'barber': 313,\n",
       " 'greene': 314,\n",
       " 'mills': 315,\n",
       " 'mc': 316,\n",
       " 'durham': 317,\n",
       " 'ڪراچي': 318,\n",
       " 'karachi': 319,\n",
       " 'karāchi': 320,\n",
       " 'سنڌ': 321,\n",
       " 'university': 322,\n",
       " 'phoenix': 323,\n",
       " 'grove': 324,\n",
       " 'ciudad': 325,\n",
       " 'erie': 326,\n",
       " 'et': 327,\n",
       " 'suomi': 328,\n",
       " 'kent': 329,\n",
       " 'dade': 330,\n",
       " 'state': 331,\n",
       " 'prince': 332,\n",
       " 'kommune': 333,\n",
       " 'leinster': 334,\n",
       " 'china': 335,\n",
       " 'calabarzon': 336,\n",
       " 'île': 337,\n",
       " 'centre': 338,\n",
       " 'lisboa': 339,\n",
       " 'halifax': 340,\n",
       " 'forest': 341,\n",
       " 'hill': 342,\n",
       " 'singapore': 343,\n",
       " 'województwo': 344,\n",
       " 'polska': 345,\n",
       " 'house': 346,\n",
       " 'emirates': 347,\n",
       " 'portugal': 348,\n",
       " 'essex': 349,\n",
       " 'arkansas': 350,\n",
       " 'columbus': 351,\n",
       " 'franklin': 352,\n",
       " 'fresno': 353,\n",
       " 'camden': 354,\n",
       " 'du': 355,\n",
       " 'alpes': 356,\n",
       " 'queens': 357,\n",
       " 'cleveland': 358,\n",
       " 'honolulu': 359,\n",
       " 'malaysia': 360,\n",
       " 'dakota': 361,\n",
       " 'bronx': 362,\n",
       " 'hertfordshire': 363,\n",
       " 'highlands': 364,\n",
       " 'somewhere': 365,\n",
       " 'college': 366,\n",
       " 'squamish': 367,\n",
       " 'mount': 368,\n",
       " 'barcelona': 369,\n",
       " 'tampa': 370,\n",
       " 'harcourt': 371,\n",
       " 'alaska': 372,\n",
       " 'jawa': 373,\n",
       " 'way': 374,\n",
       " 'utah': 375,\n",
       " 'palo': 376,\n",
       " 'alto': 377,\n",
       " 'jaipur': 378,\n",
       " 'ישראל': 379,\n",
       " 'holland': 380,\n",
       " 'دبي': 381,\n",
       " 'arab': 382,\n",
       " 'nebraska': 383,\n",
       " 'lancaster': 384,\n",
       " 'richland': 385,\n",
       " 'peru': 386,\n",
       " 'springs': 387,\n",
       " 'hills': 388,\n",
       " 'allegheny': 389,\n",
       " 'baltimore': 390,\n",
       " 'maine': 391,\n",
       " 'detroit': 392,\n",
       " 'le': 393,\n",
       " 'minnesota': 394,\n",
       " '香港島': 395,\n",
       " '香港': 396,\n",
       " 'montana': 397,\n",
       " 'brisbane': 398,\n",
       " 'jamaika': 399,\n",
       " 'planet': 400,\n",
       " 'sarjapura': 401,\n",
       " 'gunjur': 402,\n",
       " 'hosahalli': 403,\n",
       " 'ambedkar': 404,\n",
       " 'nagara': 405,\n",
       " 'no': 406,\n",
       " 'bristol': 407,\n",
       " 'i': 408,\n",
       " 'coventry': 409,\n",
       " 'cavite': 410,\n",
       " 'venezuela': 411,\n",
       " 'fourth': 412,\n",
       " 'municipal': 413,\n",
       " 'baton': 414,\n",
       " 'rouge': 415,\n",
       " 'tehsil': 416,\n",
       " 'mexico': 417,\n",
       " 'court': 418,\n",
       " 'mississippi': 419,\n",
       " 'mercer': 420,\n",
       " 'comuna': 421,\n",
       " 'buffalo': 422,\n",
       " '東京都': 423,\n",
       " 'riverside': 424,\n",
       " 'ירושלים': 425,\n",
       " 'kingston': 426,\n",
       " 'wake': 427,\n",
       " 'costa': 428,\n",
       " 'monroe': 429,\n",
       " 'nam': 430,\n",
       " 'okres': 431,\n",
       " 'hlavní': 432,\n",
       " 'město': 433,\n",
       " 'česká': 434,\n",
       " 'republika': 435,\n",
       " 'ya': 436,\n",
       " 'greenville': 437,\n",
       " 'roanoke': 438,\n",
       " 'midwest': 439,\n",
       " 'kommun': 440,\n",
       " 'län': 441,\n",
       " 'stockholms': 442,\n",
       " 'россия': 443,\n",
       " 'madrid': 444,\n",
       " 'somerset': 445,\n",
       " 'switzerland': 446,\n",
       " 'lillooet': 447,\n",
       " 'catalunya': 448,\n",
       " 'ປະເທດລາວ': 449,\n",
       " 'paterson': 450,\n",
       " 'passaic': 451,\n",
       " 'union': 452,\n",
       " 'cheshire': 453,\n",
       " 'ประเทศไทย': 454,\n",
       " 'municipio': 455,\n",
       " 'idaho': 456,\n",
       " 'asia': 457,\n",
       " 'ঢাকা': 458,\n",
       " 'dane': 459,\n",
       " 'manitoba': 460,\n",
       " 'bona': 461,\n",
       " 'qabelanka': 462,\n",
       " 'sidama': 463,\n",
       " 'ደቡብ': 464,\n",
       " 'ብሔሮች': 465,\n",
       " 'ብሔረሰቦችና': 466,\n",
       " 'ሕዝቦች': 467,\n",
       " 'nations': 468,\n",
       " 'nationalities': 469,\n",
       " 'peoples': 470,\n",
       " 'dundee': 471,\n",
       " 'gambier': 472,\n",
       " 'palm': 473,\n",
       " 'guilford': 474,\n",
       " 'hanover': 475,\n",
       " 'old': 476,\n",
       " 'alameda': 477,\n",
       " 'autónoma': 478,\n",
       " 'field': 479,\n",
       " 'southeast': 480,\n",
       " 'brighton': 481,\n",
       " 'al': 482,\n",
       " 'community': 483,\n",
       " 't': 484,\n",
       " 'zone': 485,\n",
       " 'ag': 486,\n",
       " 'northwest': 487,\n",
       " 'highway': 488,\n",
       " 'raleigh': 489,\n",
       " 'gotham': 490,\n",
       " 'first': 491,\n",
       " 'ghana': 492,\n",
       " 'việt': 493,\n",
       " 'j': 494,\n",
       " 'australian': 495,\n",
       " 'lawrence': 496,\n",
       " 'leicester': 497,\n",
       " 'bl': 498,\n",
       " 'polk': 499,\n",
       " 'orocovis': 500,\n",
       " 'pittsburgh': 501,\n",
       " 'norfolk': 502,\n",
       " 'colombia': 503,\n",
       " 'natrona': 504,\n",
       " 'svealand': 505,\n",
       " 'округ': 506,\n",
       " 'namsos': 507,\n",
       " 'trøndelag': 508,\n",
       " 'área': 509,\n",
       " 'saskatchewan': 510,\n",
       " 'charleston': 511,\n",
       " 'پنجاب': 512,\n",
       " 'arrondissement': 513,\n",
       " 'ab': 514,\n",
       " 'genève': 515,\n",
       " 'nottingham': 516,\n",
       " 'grande': 517,\n",
       " 'chile': 518,\n",
       " 'ng': 519,\n",
       " 'sarasota': 520,\n",
       " 'paso': 521,\n",
       " 'word': 522,\n",
       " 'god': 523,\n",
       " 'patindig': 524,\n",
       " 'araw': 525,\n",
       " 'treelane': 526,\n",
       " 'iii': 527,\n",
       " 'subd': 528,\n",
       " 'bayan': 529,\n",
       " 'luma': 530,\n",
       " 'viii': 531,\n",
       " 'imus': 532,\n",
       " 'bend': 533,\n",
       " 'región': 534,\n",
       " 'asheville': 535,\n",
       " 'buncombe': 536,\n",
       " 'place': 537,\n",
       " 'muntinlupa': 538,\n",
       " 'nr': 539,\n",
       " 'greensboro': 540,\n",
       " 'barbados': 541,\n",
       " 'federal': 542,\n",
       " 'wilmington': 543,\n",
       " 'belgië': 544,\n",
       " 'belgique': 545,\n",
       " 'belgien': 546,\n",
       " 'y': 547,\n",
       " 'salt': 548,\n",
       " 'rajasthan': 549,\n",
       " 'eagle': 550,\n",
       " 'pass': 551,\n",
       " 'ridge': 552,\n",
       " 'noord': 553,\n",
       " 'vermont': 554,\n",
       " 'subconscious': 555,\n",
       " 'wisteria': 556,\n",
       " 'pergola': 557,\n",
       " 'chewalla': 558,\n",
       " 'rock': 559,\n",
       " 'republic': 560,\n",
       " 'llano': 561,\n",
       " 'aan': 562,\n",
       " 'here': 563,\n",
       " 'seutukunta': 564,\n",
       " 'manner': 565,\n",
       " 'bu': 566,\n",
       " 'hollywood': 567,\n",
       " 'chatham': 568,\n",
       " 'southwestern': 569,\n",
       " 'campinas': 570,\n",
       " 'board': 571,\n",
       " 'מחוז': 572,\n",
       " 'limburg': 573,\n",
       " 'атбасар': 574,\n",
       " 'район': 575,\n",
       " 'hudson': 576,\n",
       " 'delaware': 577,\n",
       " 'oxford': 578,\n",
       " 'magyarország': 579,\n",
       " 'worth': 580,\n",
       " 'river': 581,\n",
       " 'william': 582,\n",
       " 'pradesh': 583,\n",
       " 'alacant': 584,\n",
       " 'alicante': 585,\n",
       " 'ottawa': 586,\n",
       " 'kp': 587,\n",
       " 's': 588,\n",
       " 'canberra': 589,\n",
       " 'volusia': 590,\n",
       " 'paul': 591,\n",
       " 'surrey': 592,\n",
       " 'paignton': 593,\n",
       " 'tq': 594,\n",
       " 'your': 595,\n",
       " 'long': 596,\n",
       " 'السعودية': 597,\n",
       " 'knoxville': 598,\n",
       " 'des': 599,\n",
       " 'moines': 600,\n",
       " 'hettinger': 601,\n",
       " '環球大廈': 602,\n",
       " 'wide': 603,\n",
       " '中環': 604,\n",
       " '西環': 605,\n",
       " 'sai': 606,\n",
       " 'wan': 607,\n",
       " '中西區': 608,\n",
       " 'lee': 609,\n",
       " 'ca': 610,\n",
       " 'santiago': 611,\n",
       " 'school': 612,\n",
       " 'jamaica': 613,\n",
       " 'spanish': 614,\n",
       " 'catherine': 615,\n",
       " 'shore': 616,\n",
       " 'bs': 617,\n",
       " 'fairfield': 618,\n",
       " 'liverpool': 619,\n",
       " 'boulder': 620,\n",
       " 'brunswick': 621,\n",
       " 'україна': 622,\n",
       " 'федеральный': 623,\n",
       " 'kolkata': 624,\n",
       " 'bengal': 625,\n",
       " 'broward': 626,\n",
       " 'henderson': 627,\n",
       " 'perth': 628,\n",
       " 'jodhpur': 629,\n",
       " 'burlington': 630,\n",
       " 'dekalb': 631,\n",
       " 'dl': 632,\n",
       " 'آباد': 633,\n",
       " 'southwest': 634,\n",
       " 'garden': 635,\n",
       " 'lower': 636,\n",
       " 'allen': 637,\n",
       " 'hartford': 638,\n",
       " 'mk': 639,\n",
       " 'af': 640,\n",
       " 'news': 641,\n",
       " 'high': 642,\n",
       " 'warri': 643,\n",
       " 'avenida': 644,\n",
       " 'lima': 645,\n",
       " 'rivers': 646,\n",
       " 'heath': 647,\n",
       " 'الرياض': 648,\n",
       " 'anchorage': 649,\n",
       " 'pueblo': 650,\n",
       " 'h': 651,\n",
       " 'timur': 652,\n",
       " 'partido': 653,\n",
       " 'i̇stanbul': 654,\n",
       " 'bakersfield': 655,\n",
       " 'kern': 656,\n",
       " 'davao': 657,\n",
       " 'around': 658,\n",
       " 'ch': 659,\n",
       " 'haiti': 660,\n",
       " 'dupage': 661,\n",
       " 'louis': 662,\n",
       " 'lubbock': 663,\n",
       " 'cochrane': 664,\n",
       " 'olympia': 665,\n",
       " 'thurston': 666,\n",
       " 'auckland': 667,\n",
       " 'glendale': 668,\n",
       " 'gold': 669,\n",
       " 'deschutes': 670,\n",
       " 'yellowknife': 671,\n",
       " 'moncton': 672,\n",
       " 'haddonfield': 673,\n",
       " 'niagara': 674,\n",
       " 'barat': 675,\n",
       " 'nassau': 676,\n",
       " 'livingston': 677,\n",
       " 'hp': 678,\n",
       " 'huntsville': 679,\n",
       " 'bern': 680,\n",
       " 'end': 681,\n",
       " 'collin': 682,\n",
       " 'pune': 683,\n",
       " 'tiranë': 684,\n",
       " 'shqipëria': 685,\n",
       " 'en': 686,\n",
       " 'mill': 687,\n",
       " 'w': 688,\n",
       " 'aurora': 689,\n",
       " 'provincia': 690,\n",
       " 'valparaíso': 691,\n",
       " 'الصومال': 692,\n",
       " 'bokaro': 693,\n",
       " 'tshwane': 694,\n",
       " 'abuja': 695,\n",
       " 'telangana': 696,\n",
       " 'bengaluru': 697,\n",
       " 'northeast': 698,\n",
       " 'kerala': 699,\n",
       " 'silver': 700,\n",
       " 'jz': 701,\n",
       " 'panamá': 702,\n",
       " 'elk': 703,\n",
       " 'shire': 704,\n",
       " 'zuid': 705,\n",
       " 'view': 706,\n",
       " 'there': 707,\n",
       " 'helsinki': 708,\n",
       " 'helsingin': 709,\n",
       " 'uusimaa': 710,\n",
       " 'plac': 711,\n",
       " 'warszawa': 712,\n",
       " 'mazowieckie': 713,\n",
       " 'خیبر': 714,\n",
       " 'پښتونخوا': 715,\n",
       " 'winnebago': 716,\n",
       " 'horst': 717,\n",
       " 'maas': 718,\n",
       " 'forsyth': 719,\n",
       " 'tucson': 720,\n",
       " 'pima': 721,\n",
       " 'dayton': 722,\n",
       " 'ward': 723,\n",
       " 'область': 724,\n",
       " 'away': 725,\n",
       " 'alachua': 726,\n",
       " 'benton': 727,\n",
       " 'spring': 728,\n",
       " 'itunes': 729,\n",
       " 'lambrama': 730,\n",
       " 'abancay': 731,\n",
       " 'apurímac': 732,\n",
       " 'lafayette': 733,\n",
       " 'jacksonville': 734,\n",
       " 'duval': 735,\n",
       " 'mountain': 736,\n",
       " 'meridian': 737,\n",
       " 'desert': 738,\n",
       " 'contra': 739,\n",
       " 'mobile': 740,\n",
       " 'rockford': 741,\n",
       " 'indian': 742,\n",
       " 'les': 743,\n",
       " 'maritimes': 744,\n",
       " 'provence': 745,\n",
       " 'côte': 746,\n",
       " \"d'azur\": 747,\n",
       " 'sandy': 748,\n",
       " 'comunitat': 749,\n",
       " 'valenciana': 750,\n",
       " 'nh': 751,\n",
       " 'jugoslávských': 752,\n",
       " 'partyzánů': 753,\n",
       " 'hendlův': 754,\n",
       " 'dvůr': 755,\n",
       " 'dejvice': 756,\n",
       " 'htx': 757,\n",
       " 'pulsen': 758,\n",
       " 'musicon': 759,\n",
       " 'syd': 760,\n",
       " 'sjælland': 761,\n",
       " 'westchester': 762,\n",
       " 'canterbury': 763,\n",
       " 'cruz': 764,\n",
       " 'vista': 765,\n",
       " 'ronkonkoma': 766,\n",
       " 'منطقة': 767,\n",
       " 'saudi': 768,\n",
       " 'arabia': 769,\n",
       " 'knox': 770,\n",
       " 'butler': 771,\n",
       " 'lh': 772,\n",
       " 'sul': 773,\n",
       " 'centro': 774,\n",
       " 'edward': 775,\n",
       " 'home': 776,\n",
       " 'auburn': 777,\n",
       " 'merrimack': 778,\n",
       " 'di': 779,\n",
       " 'cherry': 780,\n",
       " 'hampton': 781,\n",
       " 'square': 782,\n",
       " 'paradise': 783,\n",
       " 'queen': 784,\n",
       " 'annapolis': 785,\n",
       " 'atlantic': 786,\n",
       " 'heaven': 787,\n",
       " 'centrum': 788,\n",
       " 'stockholm': 789,\n",
       " 'oaks': 790,\n",
       " 'inexpressible': 791,\n",
       " 'delta': 792,\n",
       " 'littleton': 793,\n",
       " 'москва': 794,\n",
       " 'центральный': 795,\n",
       " 'by': 796,\n",
       " 'sea': 797,\n",
       " 'europa': 798,\n",
       " 'ventura': 799,\n",
       " 'islands': 800,\n",
       " 'grand': 801,\n",
       " 'চট্টগ্রাম': 802,\n",
       " 'জেলা': 803,\n",
       " 'বিভাগ': 804,\n",
       " 'bangladesh': 805,\n",
       " 'rue': 806,\n",
       " 'far': 807,\n",
       " 'at': 808,\n",
       " 'national': 809,\n",
       " 'leesburg': 810,\n",
       " 'online': 811,\n",
       " 'occitanie': 812,\n",
       " 'peel': 813,\n",
       " 'kololo': 814,\n",
       " 'aberdeenshire': 815,\n",
       " 'lp': 816,\n",
       " 'falls': 817,\n",
       " 'cornwall': 818,\n",
       " 'unknown': 819,\n",
       " 'ሶማሌ': 820,\n",
       " 'somali': 821,\n",
       " 'snohomish': 822,\n",
       " 'over': 823,\n",
       " 'munster': 824,\n",
       " 'v': 825,\n",
       " 'junction': 826,\n",
       " 'stand': 827,\n",
       " 'milton': 828,\n",
       " 'keynes': 829,\n",
       " 'nord': 830,\n",
       " 'census': 831,\n",
       " 'division': 832,\n",
       " 'berlin': 833,\n",
       " 'croydon': 834,\n",
       " 'cr': 835,\n",
       " 'station': 836,\n",
       " 'uttar': 837,\n",
       " 'clayton': 838,\n",
       " 'dorset': 839,\n",
       " 'se': 840,\n",
       " 'alexandria': 841,\n",
       " 'tamil': 842,\n",
       " 'nadu': 843,\n",
       " 'center': 844,\n",
       " 'minneapolis': 845,\n",
       " 'hennepin': 846,\n",
       " 'sk': 847,\n",
       " 'hampden': 848,\n",
       " 'montréal': 849,\n",
       " 'boise': 850,\n",
       " 'ada': 851,\n",
       " 'my': 852,\n",
       " 'cuttack': 853,\n",
       " 'whistler': 854,\n",
       " 'olympic': 855,\n",
       " 'departamento': 856,\n",
       " 'bournemouth': 857,\n",
       " 'bh': 858,\n",
       " 'δήμος': 859,\n",
       " 'περιφερειακή': 860,\n",
       " 'ενότητα': 861,\n",
       " 'ελλάδα': 862,\n",
       " 'naperville': 863,\n",
       " 'ibadan': 864,\n",
       " 'macon': 865,\n",
       " 'bibb': 866,\n",
       " 'da': 867,\n",
       " 'fe': 868,\n",
       " 'بيروت': 869,\n",
       " 'pershore': 870,\n",
       " 'druids': 871,\n",
       " 'quartier': 872,\n",
       " 'barcelonès': 873,\n",
       " 'indianapolis': 874,\n",
       " 'marion': 875,\n",
       " 'limerick': 876,\n",
       " 'muskoka': 877,\n",
       " 'rochester': 878,\n",
       " '대한민국': 879,\n",
       " 'wa': 880,\n",
       " 'anderson': 881,\n",
       " 'wood': 882,\n",
       " 'tree': 883,\n",
       " 'parroquia': 884,\n",
       " 'brentwood': 885,\n",
       " 'rhône': 886,\n",
       " 'louisville': 887,\n",
       " 'oxfordshire': 888,\n",
       " 'hell': 889,\n",
       " 'putnam': 890,\n",
       " 'manaus': 891,\n",
       " 'lancashire': 892,\n",
       " 'na': 893,\n",
       " 'fortaleza': 894,\n",
       " 'westminster': 895,\n",
       " 'tunasan': 896,\n",
       " 'sand': 897,\n",
       " 'mountains': 898,\n",
       " 'gammel': 899,\n",
       " 'srinagar': 900,\n",
       " 'plano': 901,\n",
       " 'cedar': 902,\n",
       " 'dd': 903,\n",
       " 'circle': 904,\n",
       " 'daerah': 905,\n",
       " 'khusus': 906,\n",
       " 'ibukota': 907,\n",
       " 'jakarta': 908,\n",
       " 'sw': 909,\n",
       " 'haysville': 910,\n",
       " 'sedgwick': 911,\n",
       " 'stone': 912,\n",
       " 'greenwich': 913,\n",
       " 'kraj': 914,\n",
       " 'narni': 915,\n",
       " 'terni': 916,\n",
       " 'umbria': 917,\n",
       " 'porto': 918,\n",
       " 'alegre': 919,\n",
       " 'uppsala': 920,\n",
       " 'fountain': 921,\n",
       " 'sandusky': 922,\n",
       " 'rica': 923,\n",
       " 'swift': 924,\n",
       " 'perry': 925,\n",
       " 'taylor': 926,\n",
       " 'cork': 927,\n",
       " 'bruxelles': 928,\n",
       " 'pretoria': 929,\n",
       " 'milky': 930,\n",
       " 'lorain': 931,\n",
       " 'anaheim': 932,\n",
       " 'concord': 933,\n",
       " 'neuss': 934,\n",
       " 'kreis': 935,\n",
       " 'nordrhein': 936,\n",
       " 'westfalen': 937,\n",
       " 'coastal': 938,\n",
       " 'ދިވެހިރާއްޖެ': 939,\n",
       " 'gloucestershire': 940,\n",
       " 'schweiz': 941,\n",
       " 'suisse': 942,\n",
       " 'svizzera': 943,\n",
       " 'svizra': 944,\n",
       " 'baker': 945,\n",
       " 'marysville': 946,\n",
       " 'kh': 947,\n",
       " 'hyderabad': 948,\n",
       " 'lehigh': 949,\n",
       " 'manor': 950,\n",
       " 'hinds': 951,\n",
       " 'cambridge': 952,\n",
       " 'amsterdam': 953,\n",
       " 'swindon': 954,\n",
       " 'sn': 955,\n",
       " 'larimer': 956,\n",
       " 'fayette': 957,\n",
       " 'hannover': 958,\n",
       " 'playa': 959,\n",
       " 'cuba': 960,\n",
       " 'ljubljana': 961,\n",
       " 'pierce': 962,\n",
       " 'malawi': 963,\n",
       " 'albuquerque': 964,\n",
       " 'bernalillo': 965,\n",
       " 'addison': 966,\n",
       " 'hotel': 967,\n",
       " 'middle': 968,\n",
       " 'hove': 969,\n",
       " 'bolivar': 970,\n",
       " 'κύπρος': 971,\n",
       " 'kıbrıs': 972,\n",
       " 'studio': 973,\n",
       " 'branco': 974,\n",
       " 'veneto': 975,\n",
       " 'eldoret': 976,\n",
       " 'uasin': 977,\n",
       " 'gishu': 978,\n",
       " 'salem': 979,\n",
       " 'location': 980,\n",
       " 'tucker': 981,\n",
       " 'halton': 982,\n",
       " 'аэропорт': 983,\n",
       " 'атбасарский': 984,\n",
       " 'акмолинская': 985,\n",
       " 'kazakhstan': 986,\n",
       " 'پېښور': 987,\n",
       " 'peshāwar': 988,\n",
       " 'pinellas': 989,\n",
       " 'arundel': 990,\n",
       " 'sussex': 991,\n",
       " 'maria': 992,\n",
       " 'terrace': 993,\n",
       " 'loughton': 994,\n",
       " 'ig': 995,\n",
       " 'wrexham': 996,\n",
       " 'll': 997,\n",
       " 'freeport': 998,\n",
       " 'danville': 999,\n",
       " 'castle': 1000,\n",
       " ...}"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# integer encode the documents\n",
    "encoded_docs = t.texts_to_sequences(to_vectorize['address'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1  0  0  0  0]\n",
      " [ 1  0  0  0  0]\n",
      " [ 1  0  0  0  0]\n",
      " ...\n",
      " [69 20 65 32 11]\n",
      " [ 7 34 35  2  8]\n",
      " [29  2  4  3  5]]\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "max_length = 5\n",
    "padded_docs = pad_sequences(encoded_docs, maxlen=max_length, padding='post')\n",
    "print(padded_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 400001 word vectors.\n"
     ]
    }
   ],
   "source": [
    "embeddings_index = dict()\n",
    "f = open('glove.6B.100d.txt')\n",
    "for line in f:\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    coefs = np.asarray(values[1:], dtype='float32')\n",
    "    embeddings_index[word] = coefs\n",
    "f.close()\n",
    "print('Loaded %s word vectors.' % len(embeddings_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_matrix = np.zeros((vocab_size, 100))\n",
    "for word, i in t.word_index.items():\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        embedding_matrix[i] = embedding_vector"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
