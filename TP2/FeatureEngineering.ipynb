{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     /Users/matiascano/nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/matiascano/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/matiascano/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/matiascano/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import string\n",
    "#import xgboost as xgb\n",
    "import io\n",
    "import nltk\n",
    "import matplotlib\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn import preprocessing\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "nltk.download('vader_lexicon')\n",
    "nltk.download('stopwords')\n",
    "stopwords = stopwords.words('english')\n",
    "stemmer = SnowballStemmer('english')\n",
    "\n",
    "from textblob import TextBlob\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = pd.read_csv(\"train.csv\")\n",
    "test = pd.read_csv(\"test.csv\")\n",
    "tweets['keyword'] = tweets.keyword.str.replace('%20',' ')\n",
    "test['keyword'] = test.keyword.str.replace('%20',' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 7434 entries, 0 to 7612\n",
      "Data columns (total 5 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   id        7434 non-null   int64 \n",
      " 1   keyword   7378 non-null   object\n",
      " 2   location  4982 non-null   object\n",
      " 3   text      7434 non-null   object\n",
      " 4   target    7434 non-null   int64 \n",
      "dtypes: int64(2), object(3)\n",
      "memory usage: 348.5+ KB\n"
     ]
    }
   ],
   "source": [
    "tweets.drop_duplicates(subset = 'text', keep = False, inplace = True)\n",
    "tweets.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    3243\n",
       "True       20\n",
       "Name: text, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test['text'].duplicated().value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extra Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sia = SentimentIntensityAnalyzer()\n",
    "def return_sia_compound_values(text):\n",
    "    return sia.polarity_scores(text)['compound']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopword(text):\n",
    "    new_text = []\n",
    "    for e in text:\n",
    "        if e not in stopwords and e.isalpha():\n",
    "            new_text.append(e)\n",
    "    text = new_text\n",
    "    return \" \".join(new_text)\n",
    "\n",
    "def stemm(text):\n",
    "    text = [stemmer.stem(word) for word in text.split()]\n",
    "    return \" \".join(text)\n",
    "\n",
    "def contains_punctuation(text):\n",
    "    punctuation = set(string.punctuation)\n",
    "    for character in text:\n",
    "        if character in punctuation:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "def amount_of_punctuation(text):\n",
    "    punctuation = set(string.punctuation)\n",
    "    amount = 0\n",
    "    for character in text:\n",
    "        if character in punctuation: amount += 1\n",
    "    return amount\n",
    "\n",
    "def get_adjectives(text):\n",
    "    blob = TextBlob(text)\n",
    "    return len([word for (word,tag) in blob.tags if tag.startswith(\"JJ\")])\n",
    "\n",
    "def get_nouns(text):\n",
    "    blob = TextBlob(text)\n",
    "    return len([word for (word,tag) in blob.tags if tag.startswith(\"NN\")])\n",
    "\n",
    "def get_verbs(text):\n",
    "    blob = TextBlob(text)\n",
    "    return len([word for (word,tag) in blob.tags if tag.startswith(\"VB\")])\n",
    "\n",
    "def get_adverbs(text):\n",
    "    blob = TextBlob(text)\n",
    "    return len([word for (word,tag) in blob.tags if tag.startswith(\"RB\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_metrics(df):\n",
    "    tweets_metrics = df[['id','text']]\n",
    "    tweets_metrics['text_without_stopwords'] = tweets_metrics['text'].str.split()\n",
    "    tweets_metrics['text_without_stopwords'] = tweets_metrics['text_without_stopwords'].apply(remove_stopword)\n",
    "    tweets_metrics['length'] = tweets_metrics['text'].apply(lambda x: len(x))\n",
    "    tweets_metrics['avg_word_length'] = tweets_metrics['text'].str.split().apply(lambda x: [len(y) for y in x]).transform(lambda x: np.mean(x))\n",
    "    tweets_metrics['amount_of_words'] = tweets_metrics['text'].str.split().transform(lambda x: len(x))\n",
    "    unique_words_by_tweet = tweets_metrics['text'].transform(lambda x: x.split()).transform(lambda x: pd.Series(x).unique()).transform(lambda x: len(x))\n",
    "    tweets_metrics['amount_of_unique_words'] = unique_words_by_tweet\n",
    "    tweets_metrics['sentiment'] = tweets_metrics['text'].apply(lambda x: return_sia_compound_values(x))\n",
    "    tweets_metrics['stopwords_count'] = tweets_metrics['text'].apply(lambda x: len([word for word in str(x).lower().split() if word in stopwords]))\n",
    "    tweets_metrics['punctuation_count'] = tweets_metrics['text'].apply(lambda x: amount_of_punctuation(x))\n",
    "    mentions = tweets_metrics['text'].str.findall(r'@.\\S*?(?=\\s|[:]|$)').to_frame()\n",
    "    tweets_metrics['mentions_count'] = mentions['text'].apply(lambda x: len(x))\n",
    "    hashtags = tweets_metrics['text'].str.findall(r'#[^?\\s].*?(?=\\s|$)')\n",
    "    tweets_metrics['hashtags_count'] = hashtags.apply(lambda x: len(x))\n",
    "    tweets_metrics['longest_word_length_without_stopwords'] = tweets_metrics['text_without_stopwords'].apply(lambda x: ([len(word) for word in str(x).lower().split() if not word.startswith('http')])).apply(lambda x: max(x) if len(x) > 0 else 0)\n",
    "    tweets_metrics['stopword_word_ratio'] = tweets_metrics['stopwords_count'] / tweets_metrics['amount_of_words']\n",
    "    tweets_metrics['adjectives_count'] = tweets_metrics['text'].apply(get_adjectives)\n",
    "    tweets_metrics['nouns_count'] = tweets_metrics['text'].apply(get_nouns)\n",
    "    tweets_metrics['verbs_count'] = tweets_metrics['text'].apply(get_verbs)\n",
    "    tweets_metrics['adverbs_count'] = tweets_metrics['text'].apply(get_adverbs)\n",
    "    return tweets_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matiascano/.pyenv/versions/3.7.7/lib/python3.7/site-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/Users/matiascano/.pyenv/versions/3.7.7/lib/python3.7/site-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  after removing the cwd from sys.path.\n",
      "/Users/matiascano/.pyenv/versions/3.7.7/lib/python3.7/site-packages/ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "train_metrics = get_metrics(tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matiascano/.pyenv/versions/3.7.7/lib/python3.7/site-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/Users/matiascano/.pyenv/versions/3.7.7/lib/python3.7/site-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "test_metrics = get_metrics(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run for files\n",
    "train_metrics.to_csv('train_features.csv', index=False)\n",
    "test_metrics.to_csv('test_features.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mocks real tokenizer used in glove\n",
    "import re\n",
    "\n",
    "def tokenize_input(input_text):\n",
    "    to_tokens = input_text[:]\n",
    "    token_specification = [\n",
    "        ('url', r'https?:\\/\\/\\S+\\b|www\\.(\\w+\\.)+\\S*'),\n",
    "        (' / ', r'/'),\n",
    "        ('user', r'@\\w+'),            \n",
    "        ('smile', r'[8:=;][)d]+|[)d]+[\\'`\\-]?[8:=;]'),    \n",
    "        ('lolface', r'[8:=;][\\'`\\-]?p'),      \n",
    "        ('sadface', r'[8:=;][\\'`\\-]?\\(|\\)+[8:=;][\\'`\\-]?'),          \n",
    "        ('neutralface', r'[8:=;][\\'`\\-]?[\\/|l*]'),       \n",
    "        ('heart', r'<3'),   \n",
    "        ('number', r'[-+]?[.\\d]*[\\d]+[:,.\\d]*')\n",
    "    ]\n",
    "    for replacement, regex in token_specification:\n",
    "        to_tokens = re.sub(regex, replacement, to_tokens)\n",
    "    return to_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'url hola  /  smile heart lolface sadface  number user'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check\n",
    "tokenize_input('https://regexr.com hola / :) <3 :p :(  8888 @justin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "\n",
    "tweets['text'] = tweets['text'].apply(tokenize_input)\n",
    "test['text'] = test['text'].apply(tokenize_input)\n",
    "tweets['text'] = tweets['text'].apply(lambda x: x.translate({ord(i): ' ' for i in string.punctuation}))\n",
    "test['text'] = test['text'].apply(lambda x: x.translate({ord(i): ' ' for i in string.punctuation}))\n",
    "tweets['text'] = tweets['text'].apply(lambda x: x.lower())\n",
    "test['text'] = test['text'].apply(lambda x: x.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run for files\n",
    "tweets.to_csv('processed_train.csv', index=False)\n",
    "test.to_csv('processed_test.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vector encoding\n",
    "\n",
    "#### Keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets['keyword'] = tweets['keyword'].fillna('null')\n",
    "test['keyword'] = test['keyword'].fillna('null')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "keyword_tokens = tweets.keyword.unique().tolist()\n",
    "keyword_test = test.keyword.unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in keyword_test:\n",
    "    if k not in keyword_tokens:\n",
    "        print(k) # Mismas palabras en ambos sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 400001 word vectors.\n"
     ]
    }
   ],
   "source": [
    "embeddings_index = dict()\n",
    "f = open('glove.6B.100d.txt') # Vectores entrenados de 100 dimensiones\n",
    "for line in f:\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    coefs = np.asarray(values[1:], dtype='float32')\n",
    "    embeddings_index[word] = coefs\n",
    "f.close()\n",
    "print('Loaded %s word vectors.' % len(embeddings_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectors = {}\n",
    "for keyword in keyword_tokens:\n",
    "    words = keyword.split(' ')\n",
    "    n = len(words)\n",
    "    if n == 1:\n",
    "        vectors[keyword] = embeddings_index[keyword]\n",
    "    else:\n",
    "        acum = np.zeros(100)\n",
    "        for w in words:\n",
    "            acum = np.sum([acum,embeddings_index[w]] , axis=0)\n",
    "        vectors[keyword] = acum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>...</th>\n",
       "      <th>90</th>\n",
       "      <th>91</th>\n",
       "      <th>92</th>\n",
       "      <th>93</th>\n",
       "      <th>94</th>\n",
       "      <th>95</th>\n",
       "      <th>96</th>\n",
       "      <th>97</th>\n",
       "      <th>98</th>\n",
       "      <th>99</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>null</td>\n",
       "      <td>0.079432</td>\n",
       "      <td>-0.14054</td>\n",
       "      <td>-0.104620</td>\n",
       "      <td>-0.362590</td>\n",
       "      <td>-0.22721</td>\n",
       "      <td>-0.13612</td>\n",
       "      <td>0.74755</td>\n",
       "      <td>0.328090</td>\n",
       "      <td>0.54364</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.21230</td>\n",
       "      <td>0.515730</td>\n",
       "      <td>0.16573</td>\n",
       "      <td>0.679430</td>\n",
       "      <td>0.353270</td>\n",
       "      <td>0.17672</td>\n",
       "      <td>0.258030</td>\n",
       "      <td>0.068445</td>\n",
       "      <td>-1.20160</td>\n",
       "      <td>-0.20168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ablaze</td>\n",
       "      <td>0.137010</td>\n",
       "      <td>-0.31349</td>\n",
       "      <td>-0.047427</td>\n",
       "      <td>-0.245820</td>\n",
       "      <td>0.76459</td>\n",
       "      <td>1.21330</td>\n",
       "      <td>0.25674</td>\n",
       "      <td>0.446160</td>\n",
       "      <td>1.21040</td>\n",
       "      <td>...</td>\n",
       "      <td>1.42780</td>\n",
       "      <td>-0.402050</td>\n",
       "      <td>-0.26682</td>\n",
       "      <td>-0.029039</td>\n",
       "      <td>-1.102300</td>\n",
       "      <td>0.20442</td>\n",
       "      <td>-0.064528</td>\n",
       "      <td>0.305040</td>\n",
       "      <td>0.42830</td>\n",
       "      <td>0.54531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>accident</td>\n",
       "      <td>-0.006329</td>\n",
       "      <td>-0.37913</td>\n",
       "      <td>0.409920</td>\n",
       "      <td>-0.003844</td>\n",
       "      <td>-0.81139</td>\n",
       "      <td>-0.67840</td>\n",
       "      <td>0.25995</td>\n",
       "      <td>1.090300</td>\n",
       "      <td>0.60039</td>\n",
       "      <td>...</td>\n",
       "      <td>0.49451</td>\n",
       "      <td>-0.308700</td>\n",
       "      <td>-0.18550</td>\n",
       "      <td>0.714090</td>\n",
       "      <td>0.198860</td>\n",
       "      <td>1.12760</td>\n",
       "      <td>-0.100960</td>\n",
       "      <td>-0.100000</td>\n",
       "      <td>0.21349</td>\n",
       "      <td>-1.24530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>aftershock</td>\n",
       "      <td>0.136920</td>\n",
       "      <td>1.02570</td>\n",
       "      <td>0.539610</td>\n",
       "      <td>0.275310</td>\n",
       "      <td>-0.91579</td>\n",
       "      <td>0.24287</td>\n",
       "      <td>0.77162</td>\n",
       "      <td>0.025242</td>\n",
       "      <td>0.47416</td>\n",
       "      <td>...</td>\n",
       "      <td>1.23600</td>\n",
       "      <td>0.126510</td>\n",
       "      <td>-0.93994</td>\n",
       "      <td>0.187410</td>\n",
       "      <td>0.712540</td>\n",
       "      <td>0.79876</td>\n",
       "      <td>-0.040149</td>\n",
       "      <td>-0.591220</td>\n",
       "      <td>-0.28051</td>\n",
       "      <td>-0.23293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>airplane accident</td>\n",
       "      <td>-0.175379</td>\n",
       "      <td>-0.10526</td>\n",
       "      <td>0.977860</td>\n",
       "      <td>-0.001856</td>\n",
       "      <td>-0.93397</td>\n",
       "      <td>-1.15404</td>\n",
       "      <td>0.79570</td>\n",
       "      <td>1.143708</td>\n",
       "      <td>0.94012</td>\n",
       "      <td>...</td>\n",
       "      <td>0.78136</td>\n",
       "      <td>-0.287935</td>\n",
       "      <td>0.23436</td>\n",
       "      <td>0.676289</td>\n",
       "      <td>0.262775</td>\n",
       "      <td>1.53821</td>\n",
       "      <td>-0.300710</td>\n",
       "      <td>-0.089367</td>\n",
       "      <td>0.77883</td>\n",
       "      <td>-2.21178</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 101 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               index         0        1         2         3        4        5  \\\n",
       "0               null  0.079432 -0.14054 -0.104620 -0.362590 -0.22721 -0.13612   \n",
       "1             ablaze  0.137010 -0.31349 -0.047427 -0.245820  0.76459  1.21330   \n",
       "2           accident -0.006329 -0.37913  0.409920 -0.003844 -0.81139 -0.67840   \n",
       "3         aftershock  0.136920  1.02570  0.539610  0.275310 -0.91579  0.24287   \n",
       "4  airplane accident -0.175379 -0.10526  0.977860 -0.001856 -0.93397 -1.15404   \n",
       "\n",
       "         6         7        8  ...       90        91       92        93  \\\n",
       "0  0.74755  0.328090  0.54364  ... -1.21230  0.515730  0.16573  0.679430   \n",
       "1  0.25674  0.446160  1.21040  ...  1.42780 -0.402050 -0.26682 -0.029039   \n",
       "2  0.25995  1.090300  0.60039  ...  0.49451 -0.308700 -0.18550  0.714090   \n",
       "3  0.77162  0.025242  0.47416  ...  1.23600  0.126510 -0.93994  0.187410   \n",
       "4  0.79570  1.143708  0.94012  ...  0.78136 -0.287935  0.23436  0.676289   \n",
       "\n",
       "         94       95        96        97       98       99  \n",
       "0  0.353270  0.17672  0.258030  0.068445 -1.20160 -0.20168  \n",
       "1 -1.102300  0.20442 -0.064528  0.305040  0.42830  0.54531  \n",
       "2  0.198860  1.12760 -0.100960 -0.100000  0.21349 -1.24530  \n",
       "3  0.712540  0.79876 -0.040149 -0.591220 -0.28051 -0.23293  \n",
       "4  0.262775  1.53821 -0.300710 -0.089367  0.77883 -2.21178  \n",
       "\n",
       "[5 rows x 101 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keyword_vectors = pd.DataFrame.from_dict(vectors).T.reset_index()\n",
    "keyword_vectors.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "aux = []\n",
    "aux.append('keyword')\n",
    "for i in range (0, 100):\n",
    "    name = 'k' + str(i)\n",
    "    aux.append(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>keyword</th>\n",
       "      <th>k0</th>\n",
       "      <th>k1</th>\n",
       "      <th>k2</th>\n",
       "      <th>k3</th>\n",
       "      <th>k4</th>\n",
       "      <th>k5</th>\n",
       "      <th>k6</th>\n",
       "      <th>k7</th>\n",
       "      <th>k8</th>\n",
       "      <th>...</th>\n",
       "      <th>k90</th>\n",
       "      <th>k91</th>\n",
       "      <th>k92</th>\n",
       "      <th>k93</th>\n",
       "      <th>k94</th>\n",
       "      <th>k95</th>\n",
       "      <th>k96</th>\n",
       "      <th>k97</th>\n",
       "      <th>k98</th>\n",
       "      <th>k99</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>null</td>\n",
       "      <td>0.079432</td>\n",
       "      <td>-0.14054</td>\n",
       "      <td>-0.104620</td>\n",
       "      <td>-0.362590</td>\n",
       "      <td>-0.22721</td>\n",
       "      <td>-0.13612</td>\n",
       "      <td>0.74755</td>\n",
       "      <td>0.328090</td>\n",
       "      <td>0.54364</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.21230</td>\n",
       "      <td>0.515730</td>\n",
       "      <td>0.16573</td>\n",
       "      <td>0.679430</td>\n",
       "      <td>0.353270</td>\n",
       "      <td>0.17672</td>\n",
       "      <td>0.258030</td>\n",
       "      <td>0.068445</td>\n",
       "      <td>-1.20160</td>\n",
       "      <td>-0.20168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ablaze</td>\n",
       "      <td>0.137010</td>\n",
       "      <td>-0.31349</td>\n",
       "      <td>-0.047427</td>\n",
       "      <td>-0.245820</td>\n",
       "      <td>0.76459</td>\n",
       "      <td>1.21330</td>\n",
       "      <td>0.25674</td>\n",
       "      <td>0.446160</td>\n",
       "      <td>1.21040</td>\n",
       "      <td>...</td>\n",
       "      <td>1.42780</td>\n",
       "      <td>-0.402050</td>\n",
       "      <td>-0.26682</td>\n",
       "      <td>-0.029039</td>\n",
       "      <td>-1.102300</td>\n",
       "      <td>0.20442</td>\n",
       "      <td>-0.064528</td>\n",
       "      <td>0.305040</td>\n",
       "      <td>0.42830</td>\n",
       "      <td>0.54531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>accident</td>\n",
       "      <td>-0.006329</td>\n",
       "      <td>-0.37913</td>\n",
       "      <td>0.409920</td>\n",
       "      <td>-0.003844</td>\n",
       "      <td>-0.81139</td>\n",
       "      <td>-0.67840</td>\n",
       "      <td>0.25995</td>\n",
       "      <td>1.090300</td>\n",
       "      <td>0.60039</td>\n",
       "      <td>...</td>\n",
       "      <td>0.49451</td>\n",
       "      <td>-0.308700</td>\n",
       "      <td>-0.18550</td>\n",
       "      <td>0.714090</td>\n",
       "      <td>0.198860</td>\n",
       "      <td>1.12760</td>\n",
       "      <td>-0.100960</td>\n",
       "      <td>-0.100000</td>\n",
       "      <td>0.21349</td>\n",
       "      <td>-1.24530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>aftershock</td>\n",
       "      <td>0.136920</td>\n",
       "      <td>1.02570</td>\n",
       "      <td>0.539610</td>\n",
       "      <td>0.275310</td>\n",
       "      <td>-0.91579</td>\n",
       "      <td>0.24287</td>\n",
       "      <td>0.77162</td>\n",
       "      <td>0.025242</td>\n",
       "      <td>0.47416</td>\n",
       "      <td>...</td>\n",
       "      <td>1.23600</td>\n",
       "      <td>0.126510</td>\n",
       "      <td>-0.93994</td>\n",
       "      <td>0.187410</td>\n",
       "      <td>0.712540</td>\n",
       "      <td>0.79876</td>\n",
       "      <td>-0.040149</td>\n",
       "      <td>-0.591220</td>\n",
       "      <td>-0.28051</td>\n",
       "      <td>-0.23293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>airplane accident</td>\n",
       "      <td>-0.175379</td>\n",
       "      <td>-0.10526</td>\n",
       "      <td>0.977860</td>\n",
       "      <td>-0.001856</td>\n",
       "      <td>-0.93397</td>\n",
       "      <td>-1.15404</td>\n",
       "      <td>0.79570</td>\n",
       "      <td>1.143708</td>\n",
       "      <td>0.94012</td>\n",
       "      <td>...</td>\n",
       "      <td>0.78136</td>\n",
       "      <td>-0.287935</td>\n",
       "      <td>0.23436</td>\n",
       "      <td>0.676289</td>\n",
       "      <td>0.262775</td>\n",
       "      <td>1.53821</td>\n",
       "      <td>-0.300710</td>\n",
       "      <td>-0.089367</td>\n",
       "      <td>0.77883</td>\n",
       "      <td>-2.21178</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 101 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             keyword        k0       k1        k2        k3       k4       k5  \\\n",
       "0               null  0.079432 -0.14054 -0.104620 -0.362590 -0.22721 -0.13612   \n",
       "1             ablaze  0.137010 -0.31349 -0.047427 -0.245820  0.76459  1.21330   \n",
       "2           accident -0.006329 -0.37913  0.409920 -0.003844 -0.81139 -0.67840   \n",
       "3         aftershock  0.136920  1.02570  0.539610  0.275310 -0.91579  0.24287   \n",
       "4  airplane accident -0.175379 -0.10526  0.977860 -0.001856 -0.93397 -1.15404   \n",
       "\n",
       "        k6        k7       k8  ...      k90       k91      k92       k93  \\\n",
       "0  0.74755  0.328090  0.54364  ... -1.21230  0.515730  0.16573  0.679430   \n",
       "1  0.25674  0.446160  1.21040  ...  1.42780 -0.402050 -0.26682 -0.029039   \n",
       "2  0.25995  1.090300  0.60039  ...  0.49451 -0.308700 -0.18550  0.714090   \n",
       "3  0.77162  0.025242  0.47416  ...  1.23600  0.126510 -0.93994  0.187410   \n",
       "4  0.79570  1.143708  0.94012  ...  0.78136 -0.287935  0.23436  0.676289   \n",
       "\n",
       "        k94      k95       k96       k97      k98      k99  \n",
       "0  0.353270  0.17672  0.258030  0.068445 -1.20160 -0.20168  \n",
       "1 -1.102300  0.20442 -0.064528  0.305040  0.42830  0.54531  \n",
       "2  0.198860  1.12760 -0.100960 -0.100000  0.21349 -1.24530  \n",
       "3  0.712540  0.79876 -0.040149 -0.591220 -0.28051 -0.23293  \n",
       "4  0.262775  1.53821 -0.300710 -0.089367  0.77883 -2.21178  \n",
       "\n",
       "[5 rows x 101 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keyword_vectors.columns = aux\n",
    "keyword_vectors.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "keywords_to_merge = tweets.merge(keyword_vectors, how='left').drop(columns=['keyword', 'location', 'text', 'target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run for files\n",
    "#keywords_to_merge.to_csv('keyword_features.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Keywords one hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>null</td>\n",
       "      <td>NaN</td>\n",
       "      <td>our deeds are the reason of this  earthquake m...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>null</td>\n",
       "      <td>NaN</td>\n",
       "      <td>forest fire near la ronge sask  canada</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>null</td>\n",
       "      <td>NaN</td>\n",
       "      <td>all residents asked to  shelter in place  are ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>null</td>\n",
       "      <td>NaN</td>\n",
       "      <td>number people receive  wildfires evacuation or...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>null</td>\n",
       "      <td>NaN</td>\n",
       "      <td>just got sent this photo from ruby  alaska as ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7604</th>\n",
       "      <td>10863</td>\n",
       "      <td>null</td>\n",
       "      <td>NaN</td>\n",
       "      <td>worldnews fallen powerlines on gneutralfacein...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7605</th>\n",
       "      <td>10864</td>\n",
       "      <td>null</td>\n",
       "      <td>NaN</td>\n",
       "      <td>on the flip side i m at walmart and there is a...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7606</th>\n",
       "      <td>10866</td>\n",
       "      <td>null</td>\n",
       "      <td>NaN</td>\n",
       "      <td>suicide bomber kills number in saudi security ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7608</th>\n",
       "      <td>10869</td>\n",
       "      <td>null</td>\n",
       "      <td>NaN</td>\n",
       "      <td>two giant cranes holding a bridge collapse int...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7612</th>\n",
       "      <td>10873</td>\n",
       "      <td>null</td>\n",
       "      <td>NaN</td>\n",
       "      <td>the latest  more homes razed by northern calif...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7434 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id keyword location  \\\n",
       "0         1    null      NaN   \n",
       "1         4    null      NaN   \n",
       "2         5    null      NaN   \n",
       "3         6    null      NaN   \n",
       "4         7    null      NaN   \n",
       "...     ...     ...      ...   \n",
       "7604  10863    null      NaN   \n",
       "7605  10864    null      NaN   \n",
       "7606  10866    null      NaN   \n",
       "7608  10869    null      NaN   \n",
       "7612  10873    null      NaN   \n",
       "\n",
       "                                                   text  target  \n",
       "0     our deeds are the reason of this  earthquake m...       1  \n",
       "1                forest fire near la ronge sask  canada       1  \n",
       "2     all residents asked to  shelter in place  are ...       1  \n",
       "3     number people receive  wildfires evacuation or...       1  \n",
       "4     just got sent this photo from ruby  alaska as ...       1  \n",
       "...                                                 ...     ...  \n",
       "7604   worldnews fallen powerlines on gneutralfacein...       1  \n",
       "7605  on the flip side i m at walmart and there is a...       1  \n",
       "7606  suicide bomber kills number in saudi security ...       1  \n",
       "7608  two giant cranes holding a bridge collapse int...       1  \n",
       "7612  the latest  more homes razed by northern calif...       1  \n",
       "\n",
       "[7434 rows x 5 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "disaster_list = list(tweets['keyword'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "crash = ['collide', 'collided', 'collision', 'crash', 'crashed', 'wreck', 'wreckage', 'wrecked']\n",
    "\n",
    "emergency = ['emergency', 'emergency plan']\n",
    "\n",
    "electricity = ['electrocute', 'electrocuted',]\n",
    "\n",
    "helpers = ['ambulance', 'police', 'siren', 'sirens', 'emergency services', 'first responders',\\\n",
    "           'stretcher', 'eyewitness', 'rescuers']\n",
    "\n",
    "panic = ['screamed', 'screaming', 'screams', 'panic', 'mayhem', 'riot', 'rioting', 'fear', 'panicking', 'trauma',\\\n",
    "         'trouble', 'hail', 'pandemonium']\n",
    "\n",
    "hostages = ['hostage', 'hostages', 'trapped']\n",
    "\n",
    "quarentine = ['quarantine', 'quarantined']\n",
    "\n",
    "colapse = ['bridge collapse', 'collapse', 'collapsed', 'demolish', 'demolished', 'demolition', 'structural failure']\n",
    "\n",
    "accident = ['accident', 'airplane accident', 'derail', 'derailed', 'derailment', 'oil spill']\n",
    "\n",
    "fire = ['ablaze', 'hellfire', 'smoke', 'wild fires', 'wildfire', 'buildings burning',\\\n",
    "        'buildings on fire', 'burned', 'burning', 'burning buildings', 'bush fires', 'fire',\\\n",
    "        'fire truck', 'flames', 'forest fire', 'forest fires', 'blaze', 'blazing', 'arson', 'arsonist']\n",
    "\n",
    "nuclear = ['nuclear disaster', 'nuclear reactor', 'radiation emergency', 'meltdown']\n",
    "\n",
    "explotion = ['explode', 'exploded', 'explosion', 'blown up', 'blew up', 'loud bang']\n",
    "\n",
    "survivor = ['survive', 'survived', 'rescue', 'rescued', 'survivors', 'evacuate', 'evacuated', 'evacuation', 'refugees']\n",
    "\n",
    "wounded = ['wounded', 'wounds', 'bleeding', 'bloody', 'injured', 'injuries', 'injury', 'traumatised', 'blood']\n",
    "\n",
    "bomb = ['suicide bomb', 'suicide bomber', 'suicide bombing', 'bomb', 'bombed', 'bombing', 'detonate', 'detonation']\n",
    "\n",
    "storm = ['storm', 'thunderstorm', 'thunder', 'rainstorm', 'violent storm', 'windstorm', 'lightning', 'hailstorm']\n",
    "\n",
    "water = ['flood', 'flooding', 'floods', 'inundated', 'inundation', 'sinking', 'drown', 'drowned', 'drowning', 'sunk']\n",
    "\n",
    "natural_disaster = ['heat wave','sandstorm', 'seismic' ,'avalanche', 'tsunami', 'twister',\\\n",
    "                    'typhoon',  'tornado', 'hurricane', 'natural disaster', 'cyclone', 'volcano',\\\n",
    "                    'drought', 'dust storm', 'earthquake',  'lava', 'aftershock', 'snowstorm', 'blizzard',\\\n",
    "                    'whirlwind', 'upheaval',  'landslide', 'cliff fall', 'mudslide', 'sinkhole', 'displaced',\\\n",
    "                    'epicentre']\n",
    "\n",
    "attack = ['attack', 'attacked']\n",
    "\n",
    "casualties = ['mass murder', 'mass murderer', 'massacre', 'fatal', 'fatalities', 'fatality', 'casualties',\\\n",
    "              'casualty', 'body bag', 'body bagging', 'body bags', 'dead', 'death', 'deaths',  'tragedy']\n",
    "\n",
    "terrorism = ['terrorism', 'terrorist', 'threat', 'hijack', 'hijacker', 'hijacking', 'bioterror', 'bioterrorism']\n",
    "\n",
    "destruction = ['destroyed', 'destruction', 'devastated',\\\n",
    "               'devastation', 'disaster', 'annihilated', 'annihilation', 'apocalypse',\\\n",
    "               'armageddon', 'catastrophe', 'catastrophic', 'obliterate', 'obliterated',\\\n",
    "               'obliteration', 'damage', 'destroy', 'desolate', 'desolation', 'blight',\\\n",
    "               'harm', 'hazard', 'hazardous', 'danger', 'ruin', 'engulfed', 'rubble', 'debris',\\\n",
    "               'razed', 'flattened', 'crush', 'crushed']\n",
    "\n",
    "warlike = ['war zone', 'weapon', 'weapons', 'military', 'army', 'battle', 'outbreak', 'chemical emergency', 'curfew']\n",
    "\n",
    "starvation = ['famine', 'deluge', 'deluged']\n",
    "\n",
    "\n",
    "null = ['null']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "disasters = {'crash' : crash, 'emergency' : emergency, 'electricity': electricity,\\\n",
    "             'helpers': helpers, 'panic' : panic,  'hostages' : hostages, 'quarentine' : quarentine,\\\n",
    "             'colapse' : colapse, 'accident' : accident, 'fire' : fire,\\\n",
    "             'nuclear' : nuclear, 'explotion' : explotion, 'survivor' : survivor,\\\n",
    "             'wounded' : wounded, 'bomb' : bomb, 'storm' : storm,\\\n",
    "             'water' : water, 'natural_disaster' : natural_disaster, 'attack' : attack,\\\n",
    "             'casualties' : casualties, 'terrorism' : terrorism, 'destruction' : destruction,\\\n",
    "             'warlike' : warlike, 'starvation' : starvation, 'null' : null}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_categories = len(disasters)\n",
    "n_categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_maps = {}\n",
    "count = 0\n",
    "for k in disasters.keys():\n",
    "    numeric_maps[k] = count\n",
    "    count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping = {}\n",
    "for k, v in disasters.items():\n",
    "    for w in v:\n",
    "        mapping[w] = k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping_df = pd.DataFrame.from_dict(mapping, orient='index').reset_index()\n",
    "mapping_df.columns = ['keyword', 'group']\n",
    "numeric_maps_df = pd.DataFrame.from_dict(numeric_maps, orient='index').reset_index()\n",
    "numeric_maps_df.columns = ['group', 'id']\n",
    "to_encode = mapping_df.merge(numeric_maps_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>keyword</th>\n",
       "      <th>group</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>collide</td>\n",
       "      <td>crash</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>collided</td>\n",
       "      <td>crash</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>collision</td>\n",
       "      <td>crash</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>crash</td>\n",
       "      <td>crash</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>crashed</td>\n",
       "      <td>crash</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>217</th>\n",
       "      <td>curfew</td>\n",
       "      <td>warlike</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>218</th>\n",
       "      <td>famine</td>\n",
       "      <td>starvation</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>219</th>\n",
       "      <td>deluge</td>\n",
       "      <td>starvation</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>220</th>\n",
       "      <td>deluged</td>\n",
       "      <td>starvation</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221</th>\n",
       "      <td>null</td>\n",
       "      <td>null</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>222 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       keyword       group  id\n",
       "0      collide       crash   0\n",
       "1     collided       crash   0\n",
       "2    collision       crash   0\n",
       "3        crash       crash   0\n",
       "4      crashed       crash   0\n",
       "..         ...         ...  ..\n",
       "217     curfew     warlike  22\n",
       "218     famine  starvation  23\n",
       "219     deluge  starvation  23\n",
       "220    deluged  starvation  23\n",
       "221       null        null  24\n",
       "\n",
       "[222 rows x 3 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_encode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LabelBinarizer()"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelBinarizer\n",
    "\n",
    "lb = preprocessing.LabelBinarizer()\n",
    "lb.fit(range(0, n_categories))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
       "       17, 18, 19, 20, 21, 22, 23, 24])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lb.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_encode['encode'] = list(lb.transform(to_encode['id']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "expanded = to_encode.encode.apply(pd.Series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pd.concat([to_encode, expanded], axis=1, sort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.drop(columns=['encode', 'id'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>keyword</th>\n",
       "      <th>group</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>...</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>collide</td>\n",
       "      <td>crash</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>collided</td>\n",
       "      <td>crash</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>collision</td>\n",
       "      <td>crash</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>crash</td>\n",
       "      <td>crash</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>crashed</td>\n",
       "      <td>crash</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     keyword  group  0  1  2  3  4  5  6  7  ...  15  16  17  18  19  20  21  \\\n",
       "0    collide  crash  1  0  0  0  0  0  0  0  ...   0   0   0   0   0   0   0   \n",
       "1   collided  crash  1  0  0  0  0  0  0  0  ...   0   0   0   0   0   0   0   \n",
       "2  collision  crash  1  0  0  0  0  0  0  0  ...   0   0   0   0   0   0   0   \n",
       "3      crash  crash  1  0  0  0  0  0  0  0  ...   0   0   0   0   0   0   0   \n",
       "4    crashed  crash  1  0  0  0  0  0  0  0  ...   0   0   0   0   0   0   0   \n",
       "\n",
       "   22  23  24  \n",
       "0   0   0   0  \n",
       "1   0   0   0  \n",
       "2   0   0   0  \n",
       "3   0   0   0  \n",
       "4   0   0   0  \n",
       "\n",
       "[5 rows x 27 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "keyword_exp = tweets.loc[:, ['id', 'keyword']]\n",
    "keyword_exp_test = test.loc[:, ['id', 'keyword']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_train = keyword_exp.merge(result, left_on='keyword', right_on='keyword', how='left')\n",
    "merged_test = keyword_exp_test.merge(result, left_on='keyword', right_on='keyword', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_train.drop(columns=['keyword', 'group'], inplace=True)\n",
    "merged_test.drop(columns=['keyword', 'group'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run for file\n",
    "#merged_train.to_csv('keyword_mapping.csv', index=False)\n",
    "#merged_test.to_csv('keyword_mapping_test.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>location</th>\n",
       "      <th>address</th>\n",
       "      <th>point</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>glasgow</td>\n",
       "      <td>Glasgow, Glasgow City, Scotland, G2 9SA, Unite...</td>\n",
       "      <td>(55.8609825, -4.2488787, 0.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>melbourne, australia</td>\n",
       "      <td>City of Melbourne, Victoria, Australia</td>\n",
       "      <td>(-37.8142176, 144.9631608, 0.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>news</td>\n",
       "      <td>34375, Abbotsford Centre, Abbotsford, Fraser V...</td>\n",
       "      <td>(49.04172215, -122.27255349013137, 0.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>alberta</td>\n",
       "      <td>Alberta, Canada</td>\n",
       "      <td>(55.001251, -115.002136, 0.0)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 location                                            address  \\\n",
       "0                                                                        NaN   \n",
       "1                glasgow   Glasgow, Glasgow City, Scotland, G2 9SA, Unite...   \n",
       "2    melbourne, australia             City of Melbourne, Victoria, Australia   \n",
       "3                    news  34375, Abbotsford Centre, Abbotsford, Fraser V...   \n",
       "4                 alberta                                    Alberta, Canada   \n",
       "\n",
       "                                     point  \n",
       "0                                      NaN  \n",
       "1            (55.8609825, -4.2488787, 0.0)  \n",
       "2          (-37.8142176, 144.9631608, 0.0)  \n",
       "3  (49.04172215, -122.27255349013137, 0.0)  \n",
       "4            (55.001251, -115.002136, 0.0)  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "locations = pd.read_csv(\"../TP1/locations.csv\", usecols=['location', 'address', 'point'])\n",
    "locations.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>location</th>\n",
       "      <th>address</th>\n",
       "      <th>point</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>null</td>\n",
       "      <td>null</td>\n",
       "      <td>null</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>glasgow</td>\n",
       "      <td>Glasgow, Glasgow City, Scotland, G2 9SA, Unite...</td>\n",
       "      <td>(55.8609825, -4.2488787, 0.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>melbourne, australia</td>\n",
       "      <td>City of Melbourne, Victoria, Australia</td>\n",
       "      <td>(-37.8142176, 144.9631608, 0.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>news</td>\n",
       "      <td>34375, Abbotsford Centre, Abbotsford, Fraser V...</td>\n",
       "      <td>(49.04172215, -122.27255349013137, 0.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>alberta</td>\n",
       "      <td>Alberta, Canada</td>\n",
       "      <td>(55.001251, -115.002136, 0.0)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 location                                            address  \\\n",
       "0                    null                                               null   \n",
       "1                glasgow   Glasgow, Glasgow City, Scotland, G2 9SA, Unite...   \n",
       "2    melbourne, australia             City of Melbourne, Victoria, Australia   \n",
       "3                    news  34375, Abbotsford Centre, Abbotsford, Fraser V...   \n",
       "4                 alberta                                    Alberta, Canada   \n",
       "\n",
       "                                     point  \n",
       "0                                     null  \n",
       "1            (55.8609825, -4.2488787, 0.0)  \n",
       "2          (-37.8142176, 144.9631608, 0.0)  \n",
       "3  (49.04172215, -122.27255349013137, 0.0)  \n",
       "4            (55.001251, -115.002136, 0.0)  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "locations.fillna('null', inplace=True)\n",
    "empty_loc = locations.loc[0, 'location']\n",
    "locations.replace(empty_loc, 'null', inplace=True)\n",
    "locations.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets['location'] = tweets['location'].fillna('null')\n",
    "test['location'] = test['location'].fillna('null')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def point_to_list(point):\n",
    "    if point == 'null':\n",
    "        return [300.0, 300.0] # Arbitrary large number \n",
    "    \n",
    "    coordinates = []\n",
    "    aux = point[:]\n",
    "    row = aux.strip( '()' ).split(',')\n",
    "    coordinates.append(float(row[0]))\n",
    "    coordinates.append(float(row[1]))\n",
    "    return coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "locations['point'] = locations.point.apply(point_to_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "aux = locations.point.apply(pd.Series)\n",
    "aux.columns = ['x', 'y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "locations['x'] = aux['x']\n",
    "locations['y'] = aux['y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>location</th>\n",
       "      <th>address</th>\n",
       "      <th>point</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>null</td>\n",
       "      <td>null</td>\n",
       "      <td>[300.0, 300.0]</td>\n",
       "      <td>300.000000</td>\n",
       "      <td>300.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>glasgow</td>\n",
       "      <td>Glasgow, Glasgow City, Scotland, G2 9SA, Unite...</td>\n",
       "      <td>[55.8609825, -4.2488787]</td>\n",
       "      <td>55.860982</td>\n",
       "      <td>-4.248879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>melbourne, australia</td>\n",
       "      <td>City of Melbourne, Victoria, Australia</td>\n",
       "      <td>[-37.8142176, 144.9631608]</td>\n",
       "      <td>-37.814218</td>\n",
       "      <td>144.963161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>news</td>\n",
       "      <td>34375, Abbotsford Centre, Abbotsford, Fraser V...</td>\n",
       "      <td>[49.04172215, -122.27255349013137]</td>\n",
       "      <td>49.041722</td>\n",
       "      <td>-122.272553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>alberta</td>\n",
       "      <td>Alberta, Canada</td>\n",
       "      <td>[55.001251, -115.002136]</td>\n",
       "      <td>55.001251</td>\n",
       "      <td>-115.002136</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 location                                            address  \\\n",
       "0                    null                                               null   \n",
       "1                glasgow   Glasgow, Glasgow City, Scotland, G2 9SA, Unite...   \n",
       "2    melbourne, australia             City of Melbourne, Victoria, Australia   \n",
       "3                    news  34375, Abbotsford Centre, Abbotsford, Fraser V...   \n",
       "4                 alberta                                    Alberta, Canada   \n",
       "\n",
       "                                point           x           y  \n",
       "0                      [300.0, 300.0]  300.000000  300.000000  \n",
       "1            [55.8609825, -4.2488787]   55.860982   -4.248879  \n",
       "2          [-37.8142176, 144.9631608]  -37.814218  144.963161  \n",
       "3  [49.04172215, -122.27255349013137]   49.041722 -122.272553  \n",
       "4            [55.001251, -115.002136]   55.001251 -115.002136  "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "locations.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets['location'] = tweets['location'].apply(str.lower)\n",
    "test['location'] = test['location'].apply(str.lower)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "coordinates_train = tweets.merge(locations.loc[:, ['location', 'x', 'y']], left_on='location', right_on='location', how='left').loc[:, ['id', 'x', 'y']]\n",
    "coordinates_test = test.merge(locations.loc[:, ['location', 'x', 'y']], left_on='location', right_on='location', how='left').loc[:, ['id', 'x', 'y']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run for file\n",
    "# metrics_with_xy.to_csv('coordinates_train.csv', index=False)\n",
    "# test_metrics_with_xy.to_csv('coordinates_test.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
