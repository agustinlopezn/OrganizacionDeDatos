{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split, KFold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KERAS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Character process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = pd.read_csv(\"train.csv\", usecols=['text', 'target'])\n",
    "test_text = pd.read_csv(\"test.csv\", usecols=['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 7434 entries, 0 to 7612\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   text    7434 non-null   object\n",
      " 1   target  7434 non-null   int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 174.2+ KB\n"
     ]
    }
   ],
   "source": [
    "text.drop_duplicates(subset = 'text', keep = False, inplace = True)\n",
    "text.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "text['text'] = text['text'].apply(lambda x: x.lower())\n",
    "test_text['text'] = test_text['text'].apply(lambda x: x.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>our deeds are the reason of this #earthquake m...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>forest fire near la ronge sask. canada</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>all residents asked to 'shelter in place' are ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>just got sent this photo from ruby #alaska as ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  target\n",
       "0  our deeds are the reason of this #earthquake m...       1\n",
       "1             forest fire near la ronge sask. canada       1\n",
       "2  all residents asked to 'shelter in place' are ...       1\n",
       "3  13,000 people receive #wildfires evacuation or...       1\n",
       "4  just got sent this photo from ruby #alaska as ...       1"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>just happened a terrible car crash</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>heard about #earthquake is different cities, s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>there is a forest fire at spot pond, geese are...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>apocalypse lighting. #spokane #wildfires</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>typhoon soudelor kills 28 in china and taiwan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text\n",
       "0                 just happened a terrible car crash\n",
       "1  heard about #earthquake is different cities, s...\n",
       "2  there is a forest fire at spot pond, geese are...\n",
       "3           apocalypse lighting. #spokane #wildfires\n",
       "4      typhoon soudelor kills 28 in china and taiwan"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_text.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "tk = Tokenizer(num_words=None, char_level=True, oov_token='UNK')\n",
    "tk.fit_on_texts(text['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'UNK': 1,\n",
       " ' ': 2,\n",
       " 'e': 3,\n",
       " 't': 4,\n",
       " 'a': 5,\n",
       " 'o': 6,\n",
       " 'i': 7,\n",
       " 'n': 8,\n",
       " 's': 9,\n",
       " 'r': 10,\n",
       " 'h': 11,\n",
       " 'l': 12,\n",
       " 'c': 13,\n",
       " 'd': 14,\n",
       " 'u': 15,\n",
       " 'p': 16,\n",
       " 'm': 17,\n",
       " '/': 18,\n",
       " 'g': 19,\n",
       " 'f': 20,\n",
       " 'y': 21,\n",
       " 'w': 22,\n",
       " '.': 23,\n",
       " 'b': 24,\n",
       " 'k': 25,\n",
       " 'v': 26,\n",
       " ':': 27,\n",
       " '#': 28,\n",
       " 'j': 29,\n",
       " \"'\": 30,\n",
       " '?': 31,\n",
       " 'x': 32,\n",
       " '@': 33,\n",
       " 'z': 34,\n",
       " '0': 35,\n",
       " '1': 36,\n",
       " 'q': 37,\n",
       " '-': 38,\n",
       " '2': 39,\n",
       " '5': 40,\n",
       " '3': 41,\n",
       " '4': 42,\n",
       " '7': 43,\n",
       " '9': 44,\n",
       " '6': 45,\n",
       " '!': 46,\n",
       " '8': 47,\n",
       " '\\n': 48,\n",
       " '_': 49,\n",
       " '\\x89': 50,\n",
       " 'û': 51,\n",
       " ';': 52,\n",
       " '&': 53,\n",
       " ')': 54,\n",
       " '(': 55,\n",
       " '*': 56,\n",
       " 'ª': 57,\n",
       " '|': 58,\n",
       " '[': 59,\n",
       " ']': 60,\n",
       " 'å': 61,\n",
       " '+': 62,\n",
       " 'ï': 63,\n",
       " 'ê': 64,\n",
       " '=': 65,\n",
       " '÷': 66,\n",
       " '%': 67,\n",
       " 'ò': 68,\n",
       " '$': 69,\n",
       " '\\x9d': 70,\n",
       " '~': 71,\n",
       " 'ó': 72,\n",
       " 'ì': 73,\n",
       " '©': 74,\n",
       " '¢': 75,\n",
       " '£': 76,\n",
       " '^': 77,\n",
       " '¨': 78,\n",
       " 'è': 79,\n",
       " '\\\\': 80,\n",
       " '¼': 81,\n",
       " '}': 82,\n",
       " 'ñ': 83,\n",
       " '¤': 84,\n",
       " '¡': 85,\n",
       " '`': 86,\n",
       " '{': 87,\n",
       " ',': 88,\n",
       " 'ã': 89,\n",
       " 'ü': 90,\n",
       " 'ç': 91,\n",
       " 'â': 92,\n",
       " '«': 93,\n",
       " '>': 94,\n",
       " '´': 95,\n",
       " '¬': 96}"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Caracteres muy horrendos\n",
    "tk.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "alphabet=\"abcdefghijklmnñopqrstuvwxyz0123456789,;.!?:'\\\"/\\\\|_@#$£%^&*~`+-=<>()[]{}\"\n",
    "char_dict = {}\n",
    "for i, char in enumerate(alphabet):\n",
    "    char_dict[char] = i + 1\n",
    "    \n",
    "tk.word_index = char_dict.copy() \n",
    "tk.word_index[tk.oov_token] = max(char_dict.values()) + 1 #UNK es el valor mas alto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a': 1,\n",
       " 'b': 2,\n",
       " 'c': 3,\n",
       " 'd': 4,\n",
       " 'e': 5,\n",
       " 'f': 6,\n",
       " 'g': 7,\n",
       " 'h': 8,\n",
       " 'i': 9,\n",
       " 'j': 10,\n",
       " 'k': 11,\n",
       " 'l': 12,\n",
       " 'm': 13,\n",
       " 'n': 14,\n",
       " 'ñ': 15,\n",
       " 'o': 16,\n",
       " 'p': 17,\n",
       " 'q': 18,\n",
       " 'r': 19,\n",
       " 's': 20,\n",
       " 't': 21,\n",
       " 'u': 22,\n",
       " 'v': 23,\n",
       " 'w': 24,\n",
       " 'x': 25,\n",
       " 'y': 26,\n",
       " 'z': 27,\n",
       " '0': 28,\n",
       " '1': 29,\n",
       " '2': 30,\n",
       " '3': 31,\n",
       " '4': 32,\n",
       " '5': 33,\n",
       " '6': 34,\n",
       " '7': 35,\n",
       " '8': 36,\n",
       " '9': 37,\n",
       " ',': 38,\n",
       " ';': 39,\n",
       " '.': 40,\n",
       " '!': 41,\n",
       " '?': 42,\n",
       " ':': 43,\n",
       " \"'\": 44,\n",
       " '\"': 45,\n",
       " '/': 46,\n",
       " '\\\\': 47,\n",
       " '|': 48,\n",
       " '_': 49,\n",
       " '@': 50,\n",
       " '#': 51,\n",
       " '$': 52,\n",
       " '£': 53,\n",
       " '%': 54,\n",
       " '^': 55,\n",
       " '&': 56,\n",
       " '*': 57,\n",
       " '~': 58,\n",
       " '`': 59,\n",
       " '+': 60,\n",
       " '-': 61,\n",
       " '=': 62,\n",
       " '<': 63,\n",
       " '>': 64,\n",
       " '(': 65,\n",
       " ')': 66,\n",
       " '[': 67,\n",
       " ']': 68,\n",
       " '{': 69,\n",
       " '}': 70,\n",
       " 'UNK': 71}"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tk.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ahora el texto se representa con una secuencia de caracteres\n",
    "sequences = tk.texts_to_sequences(text['text'])\n",
    "test_sequences = tk.texts_to_sequences(test_text['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[16,\n",
       " 22,\n",
       " 19,\n",
       " 71,\n",
       " 4,\n",
       " 5,\n",
       " 5,\n",
       " 4,\n",
       " 20,\n",
       " 71,\n",
       " 1,\n",
       " 19,\n",
       " 5,\n",
       " 71,\n",
       " 21,\n",
       " 8,\n",
       " 5,\n",
       " 71,\n",
       " 19,\n",
       " 5,\n",
       " 1,\n",
       " 20,\n",
       " 16,\n",
       " 14,\n",
       " 71,\n",
       " 16,\n",
       " 6,\n",
       " 71,\n",
       " 21,\n",
       " 8,\n",
       " 9,\n",
       " 20,\n",
       " 71,\n",
       " 51,\n",
       " 5,\n",
       " 1,\n",
       " 19,\n",
       " 21,\n",
       " 8,\n",
       " 18,\n",
       " 22,\n",
       " 1,\n",
       " 11,\n",
       " 5,\n",
       " 71,\n",
       " 13,\n",
       " 1,\n",
       " 26,\n",
       " 71,\n",
       " 1,\n",
       " 12,\n",
       " 12,\n",
       " 1,\n",
       " 8,\n",
       " 71,\n",
       " 6,\n",
       " 16,\n",
       " 19,\n",
       " 7,\n",
       " 9,\n",
       " 23,\n",
       " 5,\n",
       " 71,\n",
       " 22,\n",
       " 20,\n",
       " 71,\n",
       " 1,\n",
       " 12,\n",
       " 12]"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequences[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[10,\n",
       " 22,\n",
       " 20,\n",
       " 21,\n",
       " 71,\n",
       " 8,\n",
       " 1,\n",
       " 17,\n",
       " 17,\n",
       " 5,\n",
       " 14,\n",
       " 5,\n",
       " 4,\n",
       " 71,\n",
       " 1,\n",
       " 71,\n",
       " 21,\n",
       " 5,\n",
       " 19,\n",
       " 19,\n",
       " 9,\n",
       " 2,\n",
       " 12,\n",
       " 5,\n",
       " 71,\n",
       " 3,\n",
       " 1,\n",
       " 19,\n",
       " 71,\n",
       " 3,\n",
       " 19,\n",
       " 1,\n",
       " 20,\n",
       " 8]"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_sequences[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Padding de cada secuencia para que todas tengan el mismo largo\n",
    "data = pad_sequences(sequences, maxlen=1014, padding='post')\n",
    "test_data = pad_sequences(test_sequences, maxlen=1014, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7434, 1014)"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = np.array(data)\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3263, 1014)"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data = np.array(test_data)\n",
    "test_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_classes = text['target'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "71"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "size = len(tk.word_index)\n",
    "size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(72, 71)\n"
     ]
    }
   ],
   "source": [
    "embedding_weights = []\n",
    "embedding_weights.append(np.zeros(size))\n",
    "\n",
    "for char, i in tk.word_index.items():\n",
    "    row = np.zeros(size)\n",
    "    row[i-1] = 1\n",
    "    embedding_weights.append(row)\n",
    "    \n",
    "embedding_weights = np.array(embedding_weights)\n",
    "\n",
    "print(embedding_weights.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Input, Embedding, Activation, Flatten, Dense\n",
    "from keras.layers import Conv1D, MaxPooling1D, Dropout\n",
    "from keras.models import Model\n",
    "\n",
    "# Parametros\n",
    "input_size = 1014\n",
    "embedding_size = 71\n",
    "fully_connected_layers = [1024, 1024]\n",
    "num_of_classes = 1\n",
    "dropout_p = 0.5\n",
    "optimizer = 'adam'\n",
    "loss = 'binary_crossentropy'\n",
    "\n",
    "embedding_layer = Embedding(embedding_size+1, \n",
    "                            embedding_size,\n",
    "                            input_length=input_size,\n",
    "                            weights=[embedding_weights])\n",
    "\n",
    "inputs = Input(shape=(input_size,), name='input', dtype='int64')\n",
    "\n",
    "x = embedding_layer(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_126\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_88 (Embedding)     (None, 1014, 71)          5112      \n",
      "_________________________________________________________________\n",
      "conv1d_144 (Conv1D)          (None, 1012, 256)         54784     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_50 (MaxPooling (None, 253, 256)          0         \n",
      "_________________________________________________________________\n",
      "dense_186 (Dense)            (None, 253, 1024)         263168    \n",
      "_________________________________________________________________\n",
      "dense_187 (Dense)            (None, 253, 1)            1025      \n",
      "=================================================================\n",
      "Total params: 324,089\n",
      "Trainable params: 324,089\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras import layers\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "# Embedding\n",
    "model.add(embedding_layer)\n",
    "\n",
    "# Conv\n",
    "model.add(layers.Conv1D(256, 3, activation='relu'))\n",
    "model.add(layers.MaxPool1D(pool_size=4))\n",
    "\n",
    "# fully connected\n",
    "model.add(layers.Dense(1024, activation='relu'))\n",
    "\n",
    "# Output\n",
    "model.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = \\\n",
    "train_test_split(data, train_classes, test_size = 0.25, random_state = 123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "44/44 - 27s - loss: 0.5642 - accuracy: 0.6738 - val_loss: 0.8166 - val_accuracy: 0.5912\n",
      "Epoch 2/10\n",
      "44/44 - 28s - loss: 0.5642 - accuracy: 0.6749 - val_loss: 0.8169 - val_accuracy: 0.5906\n",
      "Epoch 00002: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x14743fd10>"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.callbacks import EarlyStopping\n",
    "callback = EarlyStopping(monitor = 'val_loss', patience = 1, verbose=1)\n",
    "callbacks = [callback]\n",
    "\n",
    "model1.fit(x_train, y_train,\n",
    "          validation_data=(x_test, y_test),\n",
    "          batch_size=128,\n",
    "          epochs=10,\n",
    "          verbose=2,\n",
    "          callbacks=callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(num_filters, kernel_size, vocab_size, embedding_dim, maxlen):\n",
    "    model = Sequential()\n",
    "    model.add(layers.Embedding(vocab_size, embedding_dim, input_length=maxlen, weights=[embedding_weights], trainable=True))\n",
    "    model.add(layers.Conv1D(num_filters, kernel_size, activation='relu'))\n",
    "    model.add(layers.GlobalMaxPooling1D())\n",
    "    model.add(layers.Dense(10, activation='relu'))\n",
    "    model.add(layers.Dense(1, activation='sigmoid'))\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss='binary_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 folds for each of 5 candidates, totalling 20 fits\n",
      "[CV] vocab_size=80, num_filters=128, maxlen=1014, kernel_size=7, embedding_dim=79, batch_size=65 \n",
      "Epoch 1/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "58/58 [==============================] - 9s 162ms/step - loss: 0.6624 - accuracy: 0.6119 - val_loss: 0.6445 - val_accuracy: 0.6635\n",
      "Epoch 2/15\n",
      "58/58 [==============================] - 10s 180ms/step - loss: 0.5977 - accuracy: 0.7023 - val_loss: 0.6099 - val_accuracy: 0.6492\n",
      "Epoch 3/15\n",
      "58/58 [==============================] - 13s 221ms/step - loss: 0.5454 - accuracy: 0.7392 - val_loss: 0.5790 - val_accuracy: 0.6826\n",
      "Epoch 4/15\n",
      "58/58 [==============================] - 12s 199ms/step - loss: 0.4762 - accuracy: 0.7972 - val_loss: 0.5567 - val_accuracy: 0.7160\n",
      "Epoch 5/15\n",
      "58/58 [==============================] - 14s 247ms/step - loss: 0.4166 - accuracy: 0.8307 - val_loss: 0.5500 - val_accuracy: 0.7208\n",
      "Epoch 6/15\n",
      "58/58 [==============================] - 14s 237ms/step - loss: 0.3518 - accuracy: 0.8708 - val_loss: 0.5452 - val_accuracy: 0.7470\n",
      "Epoch 7/15\n",
      "58/58 [==============================] - 14s 244ms/step - loss: 0.2987 - accuracy: 0.8955 - val_loss: 0.5580 - val_accuracy: 0.7422\n",
      "Epoch 00007: early stopping\n",
      "22/22 [==============================] - 1s 55ms/step - loss: 0.4981 - accuracy: 0.7733\n",
      "[CV]  vocab_size=80, num_filters=128, maxlen=1014, kernel_size=7, embedding_dim=79, batch_size=65, total= 1.5min\n",
      "[CV] vocab_size=80, num_filters=128, maxlen=1014, kernel_size=7, embedding_dim=79, batch_size=65 \n",
      "Epoch 1/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:  1.5min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "58/58 [==============================] - 12s 207ms/step - loss: 0.6520 - accuracy: 0.6297 - val_loss: 0.6426 - val_accuracy: 0.6778\n",
      "Epoch 2/15\n",
      "58/58 [==============================] - 12s 213ms/step - loss: 0.5913 - accuracy: 0.7169 - val_loss: 0.6070 - val_accuracy: 0.6826\n",
      "Epoch 3/15\n",
      "58/58 [==============================] - 12s 199ms/step - loss: 0.5167 - accuracy: 0.7658 - val_loss: 0.5656 - val_accuracy: 0.7088\n",
      "Epoch 4/15\n",
      "58/58 [==============================] - 12s 214ms/step - loss: 0.4473 - accuracy: 0.8142 - val_loss: 0.5438 - val_accuracy: 0.7446\n",
      "Epoch 5/15\n",
      "58/58 [==============================] - 12s 212ms/step - loss: 0.3793 - accuracy: 0.8562 - val_loss: 0.5298 - val_accuracy: 0.7518\n",
      "Epoch 6/15\n",
      "58/58 [==============================] - 12s 212ms/step - loss: 0.3213 - accuracy: 0.8830 - val_loss: 0.5231 - val_accuracy: 0.7470\n",
      "Epoch 7/15\n",
      "58/58 [==============================] - 11s 189ms/step - loss: 0.2635 - accuracy: 0.9144 - val_loss: 0.5554 - val_accuracy: 0.7112\n",
      "Epoch 00007: early stopping\n",
      "22/22 [==============================] - 1s 54ms/step - loss: 0.5268 - accuracy: 0.7253\n",
      "[CV]  vocab_size=80, num_filters=128, maxlen=1014, kernel_size=7, embedding_dim=79, batch_size=65, total= 1.5min\n",
      "[CV] vocab_size=80, num_filters=128, maxlen=1014, kernel_size=7, embedding_dim=79, batch_size=65 \n",
      "Epoch 1/15\n",
      "58/58 [==============================] - 11s 193ms/step - loss: 0.6556 - accuracy: 0.6114 - val_loss: 0.6446 - val_accuracy: 0.6158\n",
      "Epoch 2/15\n",
      "58/58 [==============================] - 11s 193ms/step - loss: 0.5988 - accuracy: 0.6869 - val_loss: 0.6164 - val_accuracy: 0.6874\n",
      "Epoch 3/15\n",
      "58/58 [==============================] - 11s 192ms/step - loss: 0.5350 - accuracy: 0.7477 - val_loss: 0.5789 - val_accuracy: 0.7041\n",
      "Epoch 4/15\n",
      "58/58 [==============================] - 11s 191ms/step - loss: 0.4575 - accuracy: 0.8068 - val_loss: 0.5434 - val_accuracy: 0.7351\n",
      "Epoch 5/15\n",
      "58/58 [==============================] - 11s 198ms/step - loss: 0.3844 - accuracy: 0.8474 - val_loss: 0.5282 - val_accuracy: 0.7446\n",
      "Epoch 6/15\n",
      "58/58 [==============================] - 11s 194ms/step - loss: 0.3201 - accuracy: 0.8822 - val_loss: 0.5178 - val_accuracy: 0.7613\n",
      "Epoch 7/15\n",
      "58/58 [==============================] - 11s 192ms/step - loss: 0.2636 - accuracy: 0.9125 - val_loss: 0.5257 - val_accuracy: 0.7399\n",
      "Epoch 00007: early stopping\n",
      "22/22 [==============================] - 1s 53ms/step - loss: 0.5265 - accuracy: 0.7633\n",
      "[CV]  vocab_size=80, num_filters=128, maxlen=1014, kernel_size=7, embedding_dim=79, batch_size=65, total= 1.4min\n",
      "[CV] vocab_size=80, num_filters=128, maxlen=1014, kernel_size=7, embedding_dim=79, batch_size=65 \n",
      "Epoch 1/15\n",
      "58/58 [==============================] - 11s 192ms/step - loss: 0.6557 - accuracy: 0.5993 - val_loss: 0.6372 - val_accuracy: 0.5919\n",
      "Epoch 2/15\n",
      "58/58 [==============================] - 11s 192ms/step - loss: 0.6076 - accuracy: 0.6694 - val_loss: 0.6144 - val_accuracy: 0.6993\n",
      "Epoch 3/15\n",
      "58/58 [==============================] - 11s 189ms/step - loss: 0.5657 - accuracy: 0.7398 - val_loss: 0.6060 - val_accuracy: 0.6683\n",
      "Epoch 4/15\n",
      "58/58 [==============================] - 11s 190ms/step - loss: 0.5220 - accuracy: 0.7826 - val_loss: 0.5855 - val_accuracy: 0.7184\n",
      "Epoch 5/15\n",
      "58/58 [==============================] - 11s 189ms/step - loss: 0.4795 - accuracy: 0.8257 - val_loss: 0.6024 - val_accuracy: 0.6945\n",
      "Epoch 00005: early stopping\n",
      "22/22 [==============================] - 1s 54ms/step - loss: 0.5734 - accuracy: 0.7301\n",
      "[CV]  vocab_size=80, num_filters=128, maxlen=1014, kernel_size=7, embedding_dim=79, batch_size=65, total=  58.2s\n",
      "[CV] vocab_size=80, num_filters=128, maxlen=1014, kernel_size=5, embedding_dim=79, batch_size=76 \n",
      "Epoch 1/15\n",
      "50/50 [==============================] - 9s 176ms/step - loss: 0.6711 - accuracy: 0.5925 - val_loss: 0.6564 - val_accuracy: 0.6253\n",
      "Epoch 2/15\n",
      "50/50 [==============================] - 9s 177ms/step - loss: 0.6219 - accuracy: 0.6842 - val_loss: 0.6342 - val_accuracy: 0.6492\n",
      "Epoch 3/15\n",
      "50/50 [==============================] - 9s 174ms/step - loss: 0.5789 - accuracy: 0.7140 - val_loss: 0.6210 - val_accuracy: 0.6826\n",
      "Epoch 4/15\n",
      "50/50 [==============================] - 9s 175ms/step - loss: 0.5258 - accuracy: 0.7573 - val_loss: 0.5763 - val_accuracy: 0.6921\n",
      "Epoch 5/15\n",
      "50/50 [==============================] - 9s 172ms/step - loss: 0.4758 - accuracy: 0.7943 - val_loss: 0.5587 - val_accuracy: 0.7327\n",
      "Epoch 6/15\n",
      "50/50 [==============================] - 9s 172ms/step - loss: 0.4251 - accuracy: 0.8264 - val_loss: 0.5485 - val_accuracy: 0.7160\n",
      "Epoch 7/15\n",
      "50/50 [==============================] - 9s 171ms/step - loss: 0.3883 - accuracy: 0.8352 - val_loss: 0.5429 - val_accuracy: 0.7232\n",
      "Epoch 8/15\n",
      "50/50 [==============================] - 9s 174ms/step - loss: 0.3369 - accuracy: 0.8780 - val_loss: 0.5398 - val_accuracy: 0.7327\n",
      "Epoch 9/15\n",
      "50/50 [==============================] - 9s 173ms/step - loss: 0.2954 - accuracy: 0.8942 - val_loss: 0.5315 - val_accuracy: 0.7232\n",
      "Epoch 10/15\n",
      "50/50 [==============================] - 9s 171ms/step - loss: 0.2508 - accuracy: 0.9224 - val_loss: 0.5370 - val_accuracy: 0.7208\n",
      "Epoch 00010: early stopping\n",
      "19/19 [==============================] - 1s 47ms/step - loss: 0.5001 - accuracy: 0.7640\n",
      "[CV]  vocab_size=80, num_filters=128, maxlen=1014, kernel_size=5, embedding_dim=79, batch_size=76, total= 1.5min\n",
      "[CV] vocab_size=80, num_filters=128, maxlen=1014, kernel_size=5, embedding_dim=79, batch_size=76 \n",
      "Epoch 1/15\n",
      "50/50 [==============================] - 9s 171ms/step - loss: 0.6615 - accuracy: 0.5994 - val_loss: 0.6482 - val_accuracy: 0.6134\n",
      "Epoch 2/15\n",
      "50/50 [==============================] - 9s 173ms/step - loss: 0.6090 - accuracy: 0.6869 - val_loss: 0.6258 - val_accuracy: 0.6301\n",
      "Epoch 3/15\n",
      "50/50 [==============================] - 9s 175ms/step - loss: 0.5714 - accuracy: 0.7145 - val_loss: 0.6022 - val_accuracy: 0.6778\n",
      "Epoch 4/15\n",
      "50/50 [==============================] - 9s 172ms/step - loss: 0.5216 - accuracy: 0.7616 - val_loss: 0.5842 - val_accuracy: 0.6945\n",
      "Epoch 5/15\n",
      "50/50 [==============================] - 9s 171ms/step - loss: 0.4684 - accuracy: 0.7945 - val_loss: 0.5646 - val_accuracy: 0.6897\n",
      "Epoch 6/15\n",
      "50/50 [==============================] - 9s 173ms/step - loss: 0.4268 - accuracy: 0.8145 - val_loss: 0.5474 - val_accuracy: 0.7255\n",
      "Epoch 7/15\n",
      "50/50 [==============================] - 9s 172ms/step - loss: 0.3747 - accuracy: 0.8495 - val_loss: 0.5371 - val_accuracy: 0.7160\n",
      "Epoch 8/15\n",
      "50/50 [==============================] - 9s 175ms/step - loss: 0.3322 - accuracy: 0.8708 - val_loss: 0.5435 - val_accuracy: 0.7422\n",
      "Epoch 00008: early stopping\n",
      "19/19 [==============================] - 1s 48ms/step - loss: 0.4747 - accuracy: 0.7862\n",
      "[CV]  vocab_size=80, num_filters=128, maxlen=1014, kernel_size=5, embedding_dim=79, batch_size=76, total= 1.2min\n",
      "[CV] vocab_size=80, num_filters=128, maxlen=1014, kernel_size=5, embedding_dim=79, batch_size=76 \n",
      "Epoch 1/15\n",
      "50/50 [==============================] - 9s 172ms/step - loss: 0.6529 - accuracy: 0.6345 - val_loss: 0.6461 - val_accuracy: 0.6587\n",
      "Epoch 2/15\n",
      "50/50 [==============================] - 9s 172ms/step - loss: 0.5926 - accuracy: 0.7047 - val_loss: 0.6126 - val_accuracy: 0.6778\n",
      "Epoch 3/15\n",
      "50/50 [==============================] - 9s 173ms/step - loss: 0.5356 - accuracy: 0.7560 - val_loss: 0.5819 - val_accuracy: 0.7041\n",
      "Epoch 4/15\n",
      "50/50 [==============================] - 9s 177ms/step - loss: 0.4728 - accuracy: 0.8054 - val_loss: 0.5689 - val_accuracy: 0.7112\n",
      "Epoch 5/15\n",
      "50/50 [==============================] - 9s 173ms/step - loss: 0.4168 - accuracy: 0.8360 - val_loss: 0.5303 - val_accuracy: 0.7446\n",
      "Epoch 6/15\n",
      "50/50 [==============================] - 9s 172ms/step - loss: 0.3677 - accuracy: 0.8607 - val_loss: 0.5258 - val_accuracy: 0.7661\n",
      "Epoch 7/15\n",
      "50/50 [==============================] - 9s 173ms/step - loss: 0.3172 - accuracy: 0.8865 - val_loss: 0.5175 - val_accuracy: 0.7685\n",
      "Epoch 8/15\n",
      "50/50 [==============================] - 9s 176ms/step - loss: 0.2719 - accuracy: 0.9128 - val_loss: 0.5367 - val_accuracy: 0.7685\n",
      "Epoch 00008: early stopping\n",
      "19/19 [==============================] - 1s 49ms/step - loss: 0.5247 - accuracy: 0.7740\n",
      "[CV]  vocab_size=80, num_filters=128, maxlen=1014, kernel_size=5, embedding_dim=79, batch_size=76, total= 1.2min\n",
      "[CV] vocab_size=80, num_filters=128, maxlen=1014, kernel_size=5, embedding_dim=79, batch_size=76 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "50/50 [==============================] - 9s 170ms/step - loss: 0.6604 - accuracy: 0.5969 - val_loss: 0.6250 - val_accuracy: 0.6468\n",
      "Epoch 2/15\n",
      "50/50 [==============================] - 9s 171ms/step - loss: 0.5989 - accuracy: 0.7029 - val_loss: 0.5957 - val_accuracy: 0.6754\n",
      "Epoch 3/15\n",
      "50/50 [==============================] - 9s 173ms/step - loss: 0.5426 - accuracy: 0.7454 - val_loss: 0.5990 - val_accuracy: 0.6611\n",
      "Epoch 00003: early stopping\n",
      "19/19 [==============================] - 1s 47ms/step - loss: 0.5968 - accuracy: 0.6655\n",
      "[CV]  vocab_size=80, num_filters=128, maxlen=1014, kernel_size=5, embedding_dim=79, batch_size=76, total=  27.9s\n",
      "[CV] vocab_size=80, num_filters=144, maxlen=1014, kernel_size=7, embedding_dim=79, batch_size=45 \n",
      "Epoch 1/15\n",
      "84/84 [==============================] - 12s 147ms/step - loss: 0.6415 - accuracy: 0.6257 - val_loss: 0.6228 - val_accuracy: 0.6539\n",
      "Epoch 2/15\n",
      "84/84 [==============================] - 12s 144ms/step - loss: 0.5516 - accuracy: 0.7337 - val_loss: 0.5764 - val_accuracy: 0.7041\n",
      "Epoch 3/15\n",
      "84/84 [==============================] - 12s 144ms/step - loss: 0.4611 - accuracy: 0.8014 - val_loss: 0.5822 - val_accuracy: 0.7232\n",
      "Epoch 00003: early stopping\n",
      "31/31 [==============================] - 1s 40ms/step - loss: 0.5157 - accuracy: 0.7626\n",
      "[CV]  vocab_size=80, num_filters=144, maxlen=1014, kernel_size=7, embedding_dim=79, batch_size=45, total=  39.0s\n",
      "[CV] vocab_size=80, num_filters=144, maxlen=1014, kernel_size=7, embedding_dim=79, batch_size=45 \n",
      "Epoch 1/15\n",
      "84/84 [==============================] - 12s 145ms/step - loss: 0.6863 - accuracy: 0.5595 - val_loss: 0.6592 - val_accuracy: 0.6158\n",
      "Epoch 2/15\n",
      "84/84 [==============================] - 12s 145ms/step - loss: 0.6270 - accuracy: 0.6505 - val_loss: 0.6406 - val_accuracy: 0.6539\n",
      "Epoch 3/15\n",
      "84/84 [==============================] - 12s 148ms/step - loss: 0.5847 - accuracy: 0.6940 - val_loss: 0.6199 - val_accuracy: 0.6659\n",
      "Epoch 4/15\n",
      "84/84 [==============================] - 12s 148ms/step - loss: 0.5316 - accuracy: 0.7337 - val_loss: 0.5827 - val_accuracy: 0.7160\n",
      "Epoch 5/15\n",
      "84/84 [==============================] - 12s 144ms/step - loss: 0.4694 - accuracy: 0.7951 - val_loss: 0.5611 - val_accuracy: 0.6969\n",
      "Epoch 6/15\n",
      "84/84 [==============================] - 12s 144ms/step - loss: 0.4074 - accuracy: 0.8304 - val_loss: 0.5637 - val_accuracy: 0.7327\n",
      "Epoch 00006: early stopping\n",
      "31/31 [==============================] - 1s 42ms/step - loss: 0.4861 - accuracy: 0.7726\n",
      "[CV]  vocab_size=80, num_filters=144, maxlen=1014, kernel_size=7, embedding_dim=79, batch_size=45, total= 1.3min\n",
      "[CV] vocab_size=80, num_filters=144, maxlen=1014, kernel_size=7, embedding_dim=79, batch_size=45 \n",
      "Epoch 1/15\n",
      "84/84 [==============================] - 12s 144ms/step - loss: 0.6484 - accuracy: 0.6207 - val_loss: 0.6482 - val_accuracy: 0.6659\n",
      "Epoch 2/15\n",
      "84/84 [==============================] - 12s 144ms/step - loss: 0.5687 - accuracy: 0.7243 - val_loss: 0.5802 - val_accuracy: 0.7041\n",
      "Epoch 3/15\n",
      "84/84 [==============================] - 12s 144ms/step - loss: 0.4720 - accuracy: 0.7913 - val_loss: 0.5480 - val_accuracy: 0.7303\n",
      "Epoch 4/15\n",
      "84/84 [==============================] - 12s 144ms/step - loss: 0.3758 - accuracy: 0.8565 - val_loss: 0.5269 - val_accuracy: 0.7399\n",
      "Epoch 5/15\n",
      "84/84 [==============================] - 12s 144ms/step - loss: 0.2955 - accuracy: 0.8982 - val_loss: 0.5090 - val_accuracy: 0.7470\n",
      "Epoch 6/15\n",
      "84/84 [==============================] - 12s 144ms/step - loss: 0.2229 - accuracy: 0.9312 - val_loss: 0.5148 - val_accuracy: 0.7613\n",
      "Epoch 00006: early stopping\n",
      "31/31 [==============================] - 1s 40ms/step - loss: 0.5181 - accuracy: 0.7611\n",
      "[CV]  vocab_size=80, num_filters=144, maxlen=1014, kernel_size=7, embedding_dim=79, batch_size=45, total= 1.3min\n",
      "[CV] vocab_size=80, num_filters=144, maxlen=1014, kernel_size=7, embedding_dim=79, batch_size=45 \n",
      "Epoch 1/15\n",
      "84/84 [==============================] - 12s 143ms/step - loss: 0.6459 - accuracy: 0.6296 - val_loss: 0.6200 - val_accuracy: 0.6563\n",
      "Epoch 2/15\n",
      "84/84 [==============================] - 12s 145ms/step - loss: 0.5697 - accuracy: 0.7180 - val_loss: 0.5737 - val_accuracy: 0.7017\n",
      "Epoch 3/15\n",
      "84/84 [==============================] - 12s 144ms/step - loss: 0.4685 - accuracy: 0.7967 - val_loss: 0.5488 - val_accuracy: 0.7327\n",
      "Epoch 4/15\n",
      "84/84 [==============================] - 12s 146ms/step - loss: 0.3829 - accuracy: 0.8451 - val_loss: 0.5521 - val_accuracy: 0.7327\n",
      "Epoch 00004: early stopping\n",
      "31/31 [==============================] - 1s 41ms/step - loss: 0.5048 - accuracy: 0.7624\n",
      "[CV]  vocab_size=80, num_filters=144, maxlen=1014, kernel_size=7, embedding_dim=79, batch_size=45, total=  51.2s\n",
      "[CV] vocab_size=80, num_filters=128, maxlen=1014, kernel_size=7, embedding_dim=79, batch_size=45 \n",
      "Epoch 1/15\n",
      "84/84 [==============================] - 11s 133ms/step - loss: 0.6517 - accuracy: 0.6220 - val_loss: 0.6553 - val_accuracy: 0.6086\n",
      "Epoch 2/15\n",
      "84/84 [==============================] - 11s 135ms/step - loss: 0.5809 - accuracy: 0.7097 - val_loss: 0.6085 - val_accuracy: 0.6659\n",
      "Epoch 3/15\n",
      "84/84 [==============================] - 11s 137ms/step - loss: 0.5030 - accuracy: 0.7788 - val_loss: 0.5726 - val_accuracy: 0.6993\n",
      "Epoch 4/15\n",
      "84/84 [==============================] - 11s 129ms/step - loss: 0.4365 - accuracy: 0.8123 - val_loss: 0.5559 - val_accuracy: 0.7446\n",
      "Epoch 5/15\n",
      "84/84 [==============================] - 11s 130ms/step - loss: 0.3573 - accuracy: 0.8668 - val_loss: 0.5647 - val_accuracy: 0.7351\n",
      "Epoch 00005: early stopping\n",
      "31/31 [==============================] - 1s 41ms/step - loss: 0.4880 - accuracy: 0.7669\n",
      "[CV]  vocab_size=80, num_filters=128, maxlen=1014, kernel_size=7, embedding_dim=79, batch_size=45, total=  58.5s\n",
      "[CV] vocab_size=80, num_filters=128, maxlen=1014, kernel_size=7, embedding_dim=79, batch_size=45 \n",
      "Epoch 1/15\n",
      "84/84 [==============================] - 11s 131ms/step - loss: 0.6494 - accuracy: 0.6249 - val_loss: 0.6329 - val_accuracy: 0.6372\n",
      "Epoch 2/15\n",
      "84/84 [==============================] - 11s 130ms/step - loss: 0.5694 - accuracy: 0.7145 - val_loss: 0.5958 - val_accuracy: 0.6850\n",
      "Epoch 3/15\n",
      "84/84 [==============================] - 11s 131ms/step - loss: 0.4940 - accuracy: 0.7799 - val_loss: 0.5601 - val_accuracy: 0.6945\n",
      "Epoch 4/15\n",
      "84/84 [==============================] - 2241s 27s/step - loss: 0.4210 - accuracy: 0.8254 - val_loss: 0.5426 - val_accuracy: 0.7088\n",
      "Epoch 5/15\n",
      "84/84 [==============================] - 39s 466ms/step - loss: 0.3580 - accuracy: 0.8570 - val_loss: 0.5307 - val_accuracy: 0.7327\n",
      "Epoch 6/15\n",
      "84/84 [==============================] - 3203s 38s/step - loss: 0.2896 - accuracy: 0.8995 - val_loss: 0.5337 - val_accuracy: 0.7327\n",
      "Epoch 00006: early stopping\n",
      "31/31 [==============================] - 1s 38ms/step - loss: 0.4673 - accuracy: 0.7912\n",
      "[CV]  vocab_size=80, num_filters=128, maxlen=1014, kernel_size=7, embedding_dim=79, batch_size=45, total=92.0min\n",
      "[CV] vocab_size=80, num_filters=128, maxlen=1014, kernel_size=7, embedding_dim=79, batch_size=45 \n",
      "Epoch 1/15\n",
      "84/84 [==============================] - 33s 392ms/step - loss: 0.6506 - accuracy: 0.6087 - val_loss: 0.6392 - val_accuracy: 0.6205\n",
      "Epoch 2/15\n",
      "84/84 [==============================] - 3191s 38s/step - loss: 0.5689 - accuracy: 0.7188 - val_loss: 0.5944 - val_accuracy: 0.6945\n",
      "Epoch 3/15\n",
      "84/84 [==============================] - 34s 403ms/step - loss: 0.4761 - accuracy: 0.7943 - val_loss: 0.5430 - val_accuracy: 0.7184\n",
      "Epoch 4/15\n",
      "84/84 [==============================] - 3190s 38s/step - loss: 0.3842 - accuracy: 0.8514 - val_loss: 0.5278 - val_accuracy: 0.7446\n",
      "Epoch 5/15\n",
      "84/84 [==============================] - 23s 275ms/step - loss: 0.3063 - accuracy: 0.8926 - val_loss: 0.5218 - val_accuracy: 0.7446\n",
      "Epoch 6/15\n",
      "84/84 [==============================] - 3222s 38s/step - loss: 0.2235 - accuracy: 0.9370 - val_loss: 0.5262 - val_accuracy: 0.7685\n",
      "Epoch 00006: early stopping\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.5174 - accuracy: 0.7762\n",
      "[CV]  vocab_size=80, num_filters=128, maxlen=1014, kernel_size=7, embedding_dim=79, batch_size=45, total=161.6min\n",
      "[CV] vocab_size=80, num_filters=128, maxlen=1014, kernel_size=7, embedding_dim=79, batch_size=45 \n",
      "Epoch 1/15\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "84/84 [==============================] - 26s 309ms/step - loss: 0.6296 - accuracy: 0.6551 - val_loss: 0.6199 - val_accuracy: 0.6516\n",
      "Epoch 2/15\n",
      "84/84 [==============================] - 38s 455ms/step - loss: 0.5252 - accuracy: 0.7582 - val_loss: 0.5635 - val_accuracy: 0.7112\n",
      "Epoch 3/15\n",
      "84/84 [==============================] - 3168s 38s/step - loss: 0.4296 - accuracy: 0.8225 - val_loss: 0.5414 - val_accuracy: 0.7351\n",
      "Epoch 4/15\n",
      "84/84 [==============================] - 36s 433ms/step - loss: 0.3444 - accuracy: 0.8754 - val_loss: 0.5558 - val_accuracy: 0.7399\n",
      "Epoch 00004: early stopping\n",
      "31/31 [==============================] - 4s 115ms/step - loss: 0.4996 - accuracy: 0.7703\n",
      "[CV]  vocab_size=80, num_filters=128, maxlen=1014, kernel_size=7, embedding_dim=79, batch_size=45, total=54.6min\n",
      "[CV] vocab_size=80, num_filters=144, maxlen=1014, kernel_size=3, embedding_dim=79, batch_size=88 \n",
      "Epoch 1/15\n",
      "43/43 [==============================] - 31s 718ms/step - loss: 0.6639 - accuracy: 0.5957 - val_loss: 0.6721 - val_accuracy: 0.5609\n",
      "Epoch 2/15\n",
      "43/43 [==============================] - 16s 376ms/step - loss: 0.6253 - accuracy: 0.6608 - val_loss: 0.6395 - val_accuracy: 0.6229\n",
      "Epoch 3/15\n",
      "43/43 [==============================] - 24s 565ms/step - loss: 0.5916 - accuracy: 0.6871 - val_loss: 0.6147 - val_accuracy: 0.6778\n",
      "Epoch 4/15\n",
      "43/43 [==============================] - 3182s 74s/step - loss: 0.5481 - accuracy: 0.7318 - val_loss: 0.6054 - val_accuracy: 0.7041\n",
      "Epoch 5/15\n",
      "43/43 [==============================] - 16s 362ms/step - loss: 0.5131 - accuracy: 0.7634 - val_loss: 0.5846 - val_accuracy: 0.6993\n",
      "Epoch 6/15\n",
      "43/43 [==============================] - 26s 593ms/step - loss: 0.4748 - accuracy: 0.7815 - val_loss: 0.5716 - val_accuracy: 0.7041\n",
      "Epoch 7/15\n",
      "43/43 [==============================] - 3181s 74s/step - loss: 0.4427 - accuracy: 0.8052 - val_loss: 0.5646 - val_accuracy: 0.7136\n",
      "Epoch 8/15\n",
      "43/43 [==============================] - 6s 149ms/step - loss: 0.4171 - accuracy: 0.8190 - val_loss: 0.5888 - val_accuracy: 0.7303\n",
      "Epoch 00008: early stopping\n",
      "16/16 [==============================] - 3s 166ms/step - loss: 0.5273 - accuracy: 0.7482\n",
      "[CV]  vocab_size=80, num_filters=144, maxlen=1014, kernel_size=3, embedding_dim=79, batch_size=88, total=161.0min\n",
      "[CV] vocab_size=80, num_filters=144, maxlen=1014, kernel_size=3, embedding_dim=79, batch_size=88 \n",
      "Epoch 1/15\n",
      "43/43 [==============================] - 22s 501ms/step - loss: 0.6635 - accuracy: 0.5843 - val_loss: 0.6633 - val_accuracy: 0.5609\n",
      "Epoch 2/15\n",
      "43/43 [==============================] - 3190s 74s/step - loss: 0.6264 - accuracy: 0.6507 - val_loss: 0.6440 - val_accuracy: 0.6444\n",
      "Epoch 3/15\n",
      "43/43 [==============================] - 7s 155ms/step - loss: 0.5923 - accuracy: 0.6980 - val_loss: 0.6174 - val_accuracy: 0.6611\n",
      "Epoch 4/15\n",
      "43/43 [==============================] - 24s 557ms/step - loss: 0.5578 - accuracy: 0.7289 - val_loss: 0.6129 - val_accuracy: 0.6802\n",
      "Epoch 5/15\n",
      "43/43 [==============================] - 3190s 74s/step - loss: 0.5252 - accuracy: 0.7515 - val_loss: 0.6001 - val_accuracy: 0.6683\n",
      "Epoch 6/15\n",
      "43/43 [==============================] - 30s 707ms/step - loss: 0.4931 - accuracy: 0.7786 - val_loss: 0.5822 - val_accuracy: 0.6850\n",
      "Epoch 7/15\n",
      "43/43 [==============================] - 22s 505ms/step - loss: 0.4639 - accuracy: 0.7900 - val_loss: 0.5713 - val_accuracy: 0.6921\n",
      "Epoch 8/15\n",
      "43/43 [==============================] - 3171s 74s/step - loss: 0.4334 - accuracy: 0.8134 - val_loss: 0.5712 - val_accuracy: 0.7017\n",
      "Epoch 9/15\n",
      "43/43 [==============================] - 30s 705ms/step - loss: 0.4052 - accuracy: 0.8280 - val_loss: 0.6001 - val_accuracy: 0.7208\n",
      "Epoch 00009: early stopping\n",
      "16/16 [==============================] - 1s 48ms/step - loss: 0.5271 - accuracy: 0.7640\n",
      "[CV]  vocab_size=80, num_filters=144, maxlen=1014, kernel_size=3, embedding_dim=79, batch_size=88, total=161.5min\n",
      "[CV] vocab_size=80, num_filters=144, maxlen=1014, kernel_size=3, embedding_dim=79, batch_size=88 \n",
      "Epoch 1/15\n",
      "43/43 [==============================] - 21s 497ms/step - loss: 0.6576 - accuracy: 0.5906 - val_loss: 0.6564 - val_accuracy: 0.5990\n",
      "Epoch 2/15\n",
      "43/43 [==============================] - 338s 8s/step - loss: 0.6232 - accuracy: 0.6619 - val_loss: 0.6442 - val_accuracy: 0.6420\n",
      "Epoch 3/15\n",
      "43/43 [==============================] - 31s 717ms/step - loss: 0.5875 - accuracy: 0.7092 - val_loss: 0.6115 - val_accuracy: 0.6778\n",
      "Epoch 4/15\n",
      "43/43 [==============================] - 8s 181ms/step - loss: 0.5485 - accuracy: 0.7326 - val_loss: 0.5903 - val_accuracy: 0.6874\n",
      "Epoch 5/15\n",
      "43/43 [==============================] - 7s 174ms/step - loss: 0.5044 - accuracy: 0.7754 - val_loss: 0.5697 - val_accuracy: 0.7041\n",
      "Epoch 6/15\n",
      "43/43 [==============================] - 7s 160ms/step - loss: 0.4630 - accuracy: 0.7982 - val_loss: 0.5610 - val_accuracy: 0.7088\n",
      "Epoch 7/15\n",
      "43/43 [==============================] - 6s 148ms/step - loss: 0.4266 - accuracy: 0.8198 - val_loss: 0.5573 - val_accuracy: 0.7208\n",
      "Epoch 8/15\n",
      "43/43 [==============================] - 7s 153ms/step - loss: 0.3975 - accuracy: 0.8413 - val_loss: 0.5501 - val_accuracy: 0.7184\n",
      "Epoch 9/15\n",
      "43/43 [==============================] - 7s 155ms/step - loss: 0.3591 - accuracy: 0.8562 - val_loss: 0.5512 - val_accuracy: 0.7232\n",
      "Epoch 00009: early stopping\n",
      "16/16 [==============================] - 1s 49ms/step - loss: 0.5256 - accuracy: 0.7367\n",
      "[CV]  vocab_size=80, num_filters=144, maxlen=1014, kernel_size=3, embedding_dim=79, batch_size=88, total= 7.3min\n",
      "[CV] vocab_size=80, num_filters=144, maxlen=1014, kernel_size=3, embedding_dim=79, batch_size=88 \n",
      "Epoch 1/15\n",
      "43/43 [==============================] - 7s 161ms/step - loss: 0.6686 - accuracy: 0.5740 - val_loss: 0.6415 - val_accuracy: 0.5871\n",
      "Epoch 2/15\n",
      "43/43 [==============================] - 7s 162ms/step - loss: 0.6298 - accuracy: 0.6269 - val_loss: 0.6253 - val_accuracy: 0.6563\n",
      "Epoch 3/15\n",
      "43/43 [==============================] - 7s 159ms/step - loss: 0.6088 - accuracy: 0.6888 - val_loss: 0.6178 - val_accuracy: 0.6635\n",
      "Epoch 4/15\n",
      "43/43 [==============================] - 7s 162ms/step - loss: 0.5833 - accuracy: 0.7143 - val_loss: 0.6073 - val_accuracy: 0.6802\n",
      "Epoch 5/15\n",
      "43/43 [==============================] - 7s 163ms/step - loss: 0.5595 - accuracy: 0.7454 - val_loss: 0.6041 - val_accuracy: 0.6826\n",
      "Epoch 6/15\n",
      "43/43 [==============================] - 7s 162ms/step - loss: 0.5329 - accuracy: 0.7701 - val_loss: 0.5900 - val_accuracy: 0.7112\n",
      "Epoch 7/15\n",
      "43/43 [==============================] - 8s 176ms/step - loss: 0.5076 - accuracy: 0.8057 - val_loss: 0.5967 - val_accuracy: 0.6993\n",
      "Epoch 00007: early stopping\n",
      "16/16 [==============================] - 1s 63ms/step - loss: 0.5731 - accuracy: 0.7308\n",
      "[CV]  vocab_size=80, num_filters=144, maxlen=1014, kernel_size=3, embedding_dim=79, batch_size=88, total=  52.1s\n",
      "Epoch 1/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  20 out of  20 | elapsed: 653.6min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "112/112 [==============================] - 16s 141ms/step - loss: 0.6544 - accuracy: 0.6024 - val_loss: 0.6679 - val_accuracy: 0.5914\n",
      "Epoch 2/15\n",
      "112/112 [==============================] - 15s 131ms/step - loss: 0.5813 - accuracy: 0.6909 - val_loss: 0.5941 - val_accuracy: 0.6738\n",
      "Epoch 3/15\n",
      "112/112 [==============================] - 15s 131ms/step - loss: 0.4976 - accuracy: 0.7768 - val_loss: 0.5635 - val_accuracy: 0.7097\n",
      "Epoch 4/15\n",
      "112/112 [==============================] - 14s 129ms/step - loss: 0.4317 - accuracy: 0.8126 - val_loss: 0.5411 - val_accuracy: 0.6989\n",
      "Epoch 5/15\n",
      "112/112 [==============================] - 15s 130ms/step - loss: 0.3631 - accuracy: 0.8545 - val_loss: 0.5171 - val_accuracy: 0.7509\n",
      "Epoch 6/15\n",
      "112/112 [==============================] - 14s 129ms/step - loss: 0.3016 - accuracy: 0.8914 - val_loss: 0.5139 - val_accuracy: 0.7599\n",
      "Epoch 7/15\n",
      "112/112 [==============================] - 15s 132ms/step - loss: 0.2385 - accuracy: 0.9266 - val_loss: 0.5233 - val_accuracy: 0.7581\n",
      "Epoch 00007: early stopping\n",
      "Best Accuracy : 0.7761\n",
      "{'vocab_size': 80, 'num_filters': 128, 'maxlen': 1014, 'kernel_size': 7, 'embedding_dim': 79, 'batch_size': 45}\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "param_grid = dict(num_filters=[128, 144, 256],\n",
    "                      kernel_size=[3, 5, 7],\n",
    "                      vocab_size=[80],\n",
    "                      embedding_dim=[79],\n",
    "                      maxlen=[1014],\n",
    "                      batch_size = [45,65,76,88])\n",
    "\n",
    "model = KerasClassifier(build_fn=create_model,\n",
    "                            epochs=15, validation_split=0.1,\n",
    "                            verbose=1)\n",
    "\n",
    "grid = RandomizedSearchCV(estimator=model, param_distributions=param_grid,\n",
    "                              cv=4, verbose=2, n_iter=5, n_jobs=1)\n",
    "\n",
    "grid_result = grid.fit(x_train, y_train, callbacks=[callback])\n",
    "\n",
    "# Evaluate testing set\n",
    "#test_accuracy = grid.score(x_test, y_test)\n",
    "\n",
    "# Save and evaluate results\n",
    "s = ('Best Accuracy : {:.4f}\\n{}\\n\\n\\n')\n",
    "output_string = s.format(\n",
    "            grid_result.best_score_,\n",
    "            grid_result.best_params_)\n",
    "            \n",
    "print(output_string)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
