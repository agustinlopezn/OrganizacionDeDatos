{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 75.06/95.58 Organización de Datos: Trabajo Práctico 1 ###\n",
    "#### Primer Cuatrimestre de 2020 ####\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from gensim.parsing.preprocessing import STOPWORDS\n",
    "import string\n",
    "%matplotlib inline\n",
    "\n",
    "tweets = pd.read_csv('train.csv') \n",
    "tweets.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets['text'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets['location'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets['keyword'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "duplicados = tweets.duplicated(subset = 'text', keep = False)\n",
    "duplicados.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets.drop_duplicates(subset = 'text', keep = False, inplace = True)\n",
    "tweets.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similaridad de textos falsos entre  si y reales entre si"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = tweets.groupby(\"target\").get_group(0)\n",
    "v = tweets.groupby(\"target\").get_group(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasketch import MinHash,MinHashLSH\n",
    "import re\n",
    "\n",
    "def preprocess(text):\n",
    "    text = re.sub(r'[^\\w\\s]','',text)\n",
    "    tokens = text.lower()\n",
    "    tokens = tokens.split()\n",
    "    return tokens\n",
    "\n",
    "def get_minhash(data):\n",
    "    minhash = []\n",
    "    for row in data.iterrows():\n",
    "        text = row[1][3]\n",
    "        id = row[1][0]\n",
    "        tokens = preprocess(text)\n",
    "        m = MinHash(num_perm=512)\n",
    "        for s in tokens:\n",
    "            m.update(s.encode('utf8'))\n",
    "        minhash.append([id,m])\n",
    "    return minhash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [],
   "source": [
    "minhashs_f = get_minhash(f)\n",
    "minhashs_v = get_minhash(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [],
   "source": [
    "def calcular_cercania(minhashs):\n",
    "    final = []\n",
    "    for i in range(1,100):\n",
    "\n",
    "        lsh = MinHashLSH(threshold=i/100, num_perm=512)\n",
    "        for minhash in minhashs:\n",
    "            lsh.insert(minhash[0],minhash[1])\n",
    "\n",
    "        values = []\n",
    "        for minhash in minhashs:\n",
    "            values.append(len(lsh.query(minhash[1])))\n",
    "        final.append(values)\n",
    "    return final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend"
    ]
   },
   "outputs": [],
   "source": [
    "cerca_segun_treshold_f = calcular_cercania(minhashs_f)\n",
    "cerca_segun_treshold_v = calcular_cercania(minhashs_v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [],
   "source": [
    "real_avg = []\n",
    "fake_avg = []\n",
    "indx = []\n",
    "\n",
    "for i in range(1,99): \n",
    "    real_avg.append(sum(cerca_segun_treshold_v[i])//len(cerca_segun_treshold_v[i]))\n",
    "    fake_avg.append(sum(cerca_segun_treshold_f[i])//len(cerca_segun_treshold_f[i]))\n",
    "    indx.append(i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_and_fake = pd.DataFrame(real_avg,index = indx)\n",
    "real_and_fake.columns = [\"AVG Match Real\"]\n",
    "real_and_fake[\"AVG Match Fake\"] = fake_avg\n",
    "real_and_fake.reset_index(inplace=True)\n",
    "real_and_fake = real_and_fake.head(40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = real_and_fake.plot.scatter(x=\"AVG Match Real\",y=\"index\",color=\"r\",label=\"Reales\",figsize=(12,10))\n",
    "real_and_fake.plot.scatter(x=\"AVG Match Fake\",y=\"index\",color=\"b\",label=\"Falsos\",ax=ax)\n",
    "real_and_fake.plot(x=\"AVG Match Fake\",y=\"index\",color=\"b\",label=\"\",ax=ax)\n",
    "real_and_fake.plot(x=\"AVG Match Real\",y=\"index\",color=\"r\",label=\"\",ax=ax)\n",
    "plt.legend(loc='best')\n",
    "\n",
    "ax.set_xlabel(\"Promedio de tweets similares\")\n",
    "ax.set_ylabel(\"Minimo porcentaje de similitud\")\n",
    "ax.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TOP 50 DESASTRES COMENTADOS EN LOS TWEETS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "desastres = tweets.groupby(\"keyword\").agg({\"target\":[\"count\",\"mean\"]})\n",
    "level0 = desastres.columns.get_level_values(0)\n",
    "level1 = desastres.columns.get_level_values(1)\n",
    "desastres.columns = level0 + \"_\" + level1\n",
    "desastres.sort_values(by=\"target_count\",ascending = False,inplace = True)\n",
    "desastres = desastres.head(50) #TOP 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(20,20))\n",
    "grafico = sns.barplot(data = desastres,x = \"target_count\",y = desastres.index)\n",
    "grafico.set_title(\"Top 50 desastres comentados en tweets\",fontsize = 14)\n",
    "grafico.set_xlabel(\"Cantidad de veces mencionado\",fontsize = 14)\n",
    "grafico.set_ylabel(\"Desastre\",fontsize = 14)\n",
    "grafico.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TOP PALABRAS EN LOS TWEETS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def by_word_count(dataframe):\n",
    "    word_list = dataframe[\"text\"].str.split()\n",
    "    all_stopwords_gensim = STOPWORDS.union(set(string.punctuation))\n",
    "    filtered = [word.lower() for word in np.concatenate(word_list.values) if not word in all_stopwords_gensim]\n",
    "    words = pd.DataFrame(filtered,columns = [\"word\"])\n",
    "    words[\"amount\"] = 1\n",
    "    by_count = words.groupby([\"word\"]).agg({\"amount\":[\"count\"]})\n",
    "    level0 = by_count.columns.get_level_values(0)\n",
    "    level1 = by_count.columns.get_level_values(1)\n",
    "    by_count.columns = level0 + \"_\" + level1\n",
    "    by_count.sort_values(by=\"amount_count\",ascending = False,inplace = True)\n",
    "    return by_count.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true = tweets[\"target\"] == 1\n",
    "true = by_word_count(tweets[true])\n",
    "\n",
    "false = tweets[\"target\"] == 0\n",
    "false = by_word_count(tweets[false])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(20,20))\n",
    "grafico = sns.barplot(data = true,x = \"amount_count\",y=true.index)\n",
    "grafico.set_title(\"Top 10 palabras usadas en tweets verdaderos\",fontsize = 14)\n",
    "grafico.set_xlabel(\"Cantidad de veces\",fontsize = 14)\n",
    "grafico.set_ylabel(\"Palabra\",fontsize = 14)\n",
    "grafico.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(20,20))\n",
    "grafico = sns.barplot(data = false,x = \"amount_count\",y=false.index)\n",
    "grafico.set_title(\"Top 10 palabras usadas en tweets falsos\",fontsize = 14)\n",
    "grafico.set_xlabel(\"Cantidad de veces\",fontsize = 14)\n",
    "grafico.set_ylabel(\"Palabra\",fontsize = 14)\n",
    "grafico.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hashtags más usados en tweets reales y falsos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_with_ht = tweets.loc[tweets['text'].str.contains('#')]\n",
    "tweets_with_ht['hashtags'] = tweets_with_ht['text'].str.findall(r'#[^?\\s].*?(?=\\s|$)')\n",
    "tweets_hashtags = tweets_with_ht.explode('hashtags')\n",
    "tweets_hashtags.dropna(subset = [\"hashtags\"],inplace = True)\n",
    "tweets_hashtags[\"hashtags\"] = tweets_hashtags[\"hashtags\"].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_by_hashtags = tweets_hashtags.groupby(\"target\").get_group(1)\n",
    "false_by_hashtags = tweets_hashtags.groupby(\"target\").get_group(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_hashtags = ' '.join(true_by_hashtags[\"hashtags\"].str.lower())\n",
    "fake_hashtags = ' '.join(false_by_hashtags[\"hashtags\"].str.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from wordcloud import WordCloud, ImageColorGenerator\n",
    "import imageio\n",
    "\n",
    "twitter_coloring = imageio.imread(\"img/twitter.png\",pilmode='RGB')\n",
    "wc = WordCloud(width = 1920,height = 1080,background_color = \"black\",mask=twitter_coloring)\n",
    "image_colors = ImageColorGenerator(twitter_coloring)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wc.generate(fake_hashtags)\n",
    "fig, ax = plt.subplots(figsize=(17,17))\n",
    "ax.imshow(wc, interpolation=\"bilinear\")\n",
    "ax.set_axis_off()\n",
    "plt.tight_layout(pad=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wc.generate(true_hashtags)\n",
    "fig, ax = plt.subplots(figsize=(17,17))\n",
    "ax.imshow(wc, interpolation=\"bilinear\")\n",
    "ax.set_axis_off()\n",
    "plt.tight_layout(pad=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_real_hashtags = true_by_hashtags.groupby('hashtags').agg({'target':'count'}).nlargest(50, columns='target')\n",
    "top_real_hashtags.columns = [\"real\"]\n",
    "top_fake_hashtags = false_by_hashtags.groupby('hashtags').agg({'target':'count'}).nlargest(50, columns=\"target\")\n",
    "top_fake_hashtags.columns = [\"fake\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_hashtags = pd.concat([top_real_hashtags,top_fake_hashtags],join=\"outer\",axis=1)\n",
    "all_hashtags.fillna(0,inplace=True)\n",
    "all_hashtags['total'] = all_hashtags['real'] + all_hashtags['fake']\n",
    "top_20_hashtags = all_hashtags.nlargest(20, \"total\")\n",
    "ax = top_20_hashtags.sort_values(by='total').loc[:, ['real', 'fake']].plot(kind='barh', figsize=(10, 10))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.9 64-bit",
   "language": "python",
   "name": "python36964bit38ccc5bc3d5e4426874a12e6d50badf7"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}